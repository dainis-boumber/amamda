Abstract

Discovering the structure inherent in a set of patterns is a fundamental aim
of statistical inference or learning. One fruitful approach is to build a parame-
terised stochastic generative model, independent draws from which are likely
to produce the patterns. For all but the simplest generative models, each pat-
tern can be generated in exponentially many ways. It is thus intractable to ad-
just the parameters to maximize the probability of the observed patterns, We
describe a way of nessing this combinatorial explosion by maximising an eas-
ily computed lower bound on the probability of the observations. Our method
can be viewed as a form of hierarchical self-supervised learning that may re-
late to the function of bottom-up and top-down cortical processing pathways.

1 Introduction

Following Helmholtz, we view the human perceptual system as a statistical infer-
ence engine whose function is to infer the probable causes of sensory input. We
show that a device of this kind can learn how to perform these inferences without
requiring a teacher to label each sensory input vector with its underlying causes.
A recognition model is used to infer a probability distribution over the underly-
ing causes from the sensory input, and a separate generative model, which is also
learned, is used to train the recognition model (Zemel, 1994; Hinton & Zemel, 1994;
Zemel & Hinton, 1994).

As an example of the generative models in which we are interested, consider the
shift patterns in Figure 1, which are on four 1  8 rows of binary pixels. These
were produced by a two-level stochastic hierarchical generative process described
in the gure caption. The task of learning is to take a set of examples generated by

1

such a process and induce the model. Note that underlying any pattern there are
multiple simultaneous causes. We call each possible set of causes an explanation of
the pattern. For this particular example, it is possible to infer a unique set of causes
for most patterns, but this need not always be the case.

For general generative models, the causes need not be immediately evident from
the surface form of patterns. Worse still, there can be an exponential number of
possible explanations underlying each pattern. The computational cost of consid-
ering all of these explanations makes standard maximum likelihood approaches
such as the ExpectationMaximisation algorithm (Dempster et al, 1977) intractable.
In this paper we describe a tractable approximation to maximum likelihood learn-
ing implemented in a layered hierarchical connectionist network.

2 The Recognition Distribution

The log probability of generating a particular example, d, from a model with pa-
rameters (cid:18) is

g dj(cid:18) = g X(cid:11)

(cid:11)j(cid:18)dj(cid:11); (cid:18)!

where the (cid:11) are explanations. If we view the alternative explanations of an ex-
ample as alternative congurations of a physical system there is a precise analogy
with statistical physics. We dene the energy of explanation (cid:11) to be

E(cid:11)(cid:18); d =  g (cid:11)j(cid:18)dj(cid:11); (cid:18)

(2)

The posterior probability of an explanation given d and (cid:18) is related to its energy by
the equilibrium or Boltzmann distribution, which at a temperature of 1 gives:

(1)

(3)

(cid:11)(cid:18); d =

(cid:11)

(cid:11)j(cid:18)dj(cid:11); (cid:18)
0 (cid:11)0j(cid:18)dj(cid:11)0; (cid:18)

=

eE(cid:11)
0 eE(cid:11)

0

(cid:11)

where indices (cid:18) and d in the last expression have been omitted for clarity. Using E(cid:11)
and (cid:11) equation 1 can be rewritten in terms of the Helmholtz free energy, which is
the difference between the expected energy of an explanation and the entropy of
the probability distribution across explanations.

g dj(cid:18) = "X(cid:11)

(cid:11)E(cid:11)  X(cid:11)

(cid:11) g (cid:11)!#

(4)

So far, we have not gained anything in terms of computational tractability because
we still need to compute expectations under the posterior distribution  which, in

2

general, has exponentially many terms and cannot be factored into a product of
simpler distributions. However, we know (Thompson, 1988) that any probability
distribution over the explanations will have at least as high a free energy as the
Boltzmann distribution (equation 3). Therefore we can restrict ourselves to some
class of tractable distributions and still have a lower bound on the log probability
of the data.
Instead of using the true posterior probability distribution,  , for
averaging over explanations, we use a more convenient probability distribution,
. The log probability of the data can then be written as

g dj(cid:18) = (cid:11) 	(cid:11)E(cid:11) (cid:11) 	(cid:11) g 	(cid:11) (cid:11) 	(cid:11) g[	(cid:11)=(cid:11)]
(cid:11) 	(cid:11) g[	(cid:11)=(cid:11)]

F d; (cid:18); 	

=

(5)

where F is the free energy based on the incorrect or non-equilibrium posterior 	.

Making the dependencies explicit, the last term in equation 5 is the Kullback-
Leibler divergence between 	d and the posterior distribution,  (cid:18); d (Kullback,
1959). This term cannot be negative, so by ignoring it we get a lower bound on the
log probability of the data given the model.

In our work, distribution 	 is produced by a separate recognition model that
has its own parameters, (cid:30). These parameters are optimized at the same time as
the parameters of the generative model, (cid:18), to maximise the overall t function
F d; (cid:18); (cid:30) = F d; (cid:18); 	(cid:30). Figure 2 shows graphically the nature of the approx-
imation we are making and the relationship between our procedure and the EM
algorithm. From equation 5, maximising F is equivalent to maximising the log
probability of the data minus the Kullback-Leibler divergence, showing that this
divergence acts like a penalty on the traditional log probability. The recognition
model is thus encouraged to be a good approximation to the true posterior dis-
tribution  . However, the same penalty also encourages the generative model to
change so that the true posterior distributions will be close to distributions that can
be represented by the recognition model.

3 The Deterministic Helmholtz Machine

A Helmholtz Machine (gure 3) is a simple implementation of these principles. It is
a connectionist system with multiple layers of neuron-like binary stochastic pro-
cessing units connected hierarchically by two sets of weights. Top-down connec-
tions (cid:18) implement the generative model. Bottom-up connections (cid:30) implement the
recognition model.

The key simplifying assumption is that the recognition distribution for a particular
example d, 	(cid:30); d, is factorial (separable) in each layer. If there are h stochastic

3

binary units in a layer , the portion of the distribution  (cid:18); d due to that layer
is determined by 2h  1 probabilities. However, 	(cid:30); d makes the assumption
that the actual activity of any one unit in layer  is independent of the activities
of all the other units in that layer, given the activities of all the units in the lower
layer,   1, so the recognition model needs only specify h probabilities rather than
2h  1. The independence assumption allows F d; (cid:18); (cid:30) to be evaluated efciently,
but this computational tractability is bought at a price, since the true posterior is
unlikely to be factorial: the log probability of the data will be underestimated by an
amount equal to the Kullback-Leibler divergence between the true posterior and
the recognition distribution.

The generative model is taken to be factorial in the same way, although one should
note that factorial generative models rarely have recognition distributions that are
themselves exactly factorial.

Recognition for input example d entails using the bottom-up connections (cid:30) to de-
j = 1. The
termine the probability 
recognition model is inherently stochastic  these probabilities are functions of the
0; 1 activities 1

j(cid:30); d that the jth unit in layer  has activity 

of the units in layer   1. We use:

i


j(cid:30); 

1 = (cid:27)Xi

i (cid:30)1;
1
;j

i

(6)

where (cid:27)x = 1=1  exx is the conventional sigmoid function, and 1 is
the vector of activities of the units in layer   1. All units have recognition biases
as one element of the sums, all the activities at layer  are calculated after all the
activities at layer   1, and 1
i are the activities of the input units. It is essential that
there are no feedback connections in the recognition model.

In the terms of the previous section, (cid:11) is a complete assignment of 
j for all the
units in all the layers other than the input layer (for which  = 1). The multi-
plicative contributions to the probability of choosing that assignment using the
recognition weights are 

j for units that are on and 1  

j for units that are off:

(cid:11)(cid:30); d = Y>1Yj (cid:16)

j(cid:30); 

1(cid:17)

j (cid:16)1  

j(cid:30); 

j

1(cid:17)1

(7)

The Helmholtz free energy F depends on the generative model through E(cid:11)(cid:18); d in
equation 2. The top-down connections (cid:18) use the activities 1 of the units in layer
  1 to determine the factorial generative probabilities 
j(cid:18); 1 over the activities
of the units in layer . The obvious rule to use is the sigmoid:

k (cid:18)1;
1

;j:

k

(8)


j(cid:18); 

1 = (cid:27)Xi

4

including a generative bias (which is the only contribution to units in the topmost
layer). Unfortunately this rule did not work well in practice for the sorts of inputs
we tried. Appendix A discusses the more complicated method that we actually
used to determine 
j(cid:18); 1. Given this, the overall generative probability of (cid:11) is:

(cid:11)j(cid:18) = Y>1Yj (cid:16)

j(cid:18); 

1(cid:17)

j (cid:16)1  

j(cid:18); 

1(cid:17)1

j :

(9)

We extend the factorial assumption to the input layer  = 1. The activities 
layer 2 determine the probabilities 1

2 in
2 of the activities in the input layer. Thus

j (cid:18); 

dj(cid:11); (cid:18) = Yj (cid:16)1

j (cid:18); 

2(cid:17)

j (cid:16)1  1

1

j (cid:18); 

1

j ;

2(cid:17)1

Combining equations 2, 9 and 10, and omitting dependencies for clarity,

E(cid:11)(cid:18); d =  g (cid:11)j(cid:18)dj(cid:11); (cid:18)

= X(cid:21)1Xj


j g 

j (cid:16)1  

j(cid:17) g(cid:16)1  
j(cid:17)

(10)

(11)
(12)

Putting together the two components of F, an unbiased estimate of the value of
F d; (cid:18); (cid:30) based on an explanation (cid:11) drawn from 	(cid:11) is:

F(cid:11)d; (cid:18); (cid:30) = E(cid:11)  g	(cid:11)

= X Xj


j g



j



j

(cid:16)1  

j(cid:17) g

1  

j

1  

j

(13)

(14)

One could perform stochastic gradient ascent in the negative free energy across all

the data F (cid:18); (cid:30) = d F d; (cid:18); (cid:30) using equation 14 and a form of REINFORCE

algorithm (Barto & Anandan, 1986; Williams, 1992; Dayan et al, in preparation).
However, for the simulations in this paper, we made a number of mean-eld in-
spired approximations, in that we replaced the stochastic binary activities 
j by
their mean values under the recognition model 

j. We took:


j(cid:30); 

1 = (cid:27)Xi

i (cid:30)1;
1

;j ;

i

(15)

j which we discuss in appendix A, and we
we made a similar approximation for 
then averaged the expression in equation 14 over (cid:11) to give the overall free energy:

F (cid:18); (cid:30) = Xd X Xj

KL[

j(cid:30); 

1; 

j(cid:18); 

1]

(16)

5

where the innermost term in the sum is the Kullback-Leibler divergence between
generative and recognition distributions for unit j in layer  for example d:

KL[; ] =  g




 1   g

1  
1  

:

Weights (cid:18) and (cid:30) are trained by following the derivatives of F (cid:18); (cid:30) in equation 16.
Since the generative weights (cid:18) do not affect the actual activities of the units, there
are no cycles, and so the derivatives can be calculated in closed form using the
chain rule. Appendix B gives the appropriate recursive formul.

Note that this deterministic version introduces a further approximation by ignor-
ing correlations arising from the fact that under the real recognition model, the
actual activities at layer   1 are a function of the actual activities at layer  rather
than their mean values.

Figure 4 demonstrates the performance of the Helmholtz Machine in a hierarchical
learning task (Becker & Hinton, 1992), showing that it is capable of extracting the
structure underlying a complicated generative model. The example shows clearly
the difference between the generative ((cid:18)) and the recognition ((cid:30)) weights, since
the latter often include negative side-lobes around their favoured shifts, which are
needed to prevent incorrect recognition.

4 The Stochastic Helmholtz Machine

The derivatives required for learning in the deterministic Helmholtz machine are
quite complicated because they have to take into account the effects that changes
in an activity at one layer will have on activities in higher layers. However, by bor-
rowing an idea from the Boltzmann machine (Hinton & Sejnowski, 1986; Ackley,
Hinton & Sejnowski, 1985), we get a very simple learning scheme for layered net-
works of stochastic binary units that approximates the correct derivatives (Hinton
et al, in preparation).

Learning in this scheme is separated into two phases. During the wake phase,
data d from the world are presented at the lowest layer and binary activations of
units at successively higher layers are picked according to the recognition proba-
j(cid:30); 1, determined by the bottom-up weights. The top-down genera-
bilities, 
tive weights from layer   1 to layer  are then altered to reduce the Kullback-
Leibler divergence between the actual activations and the generative probabilities
j(cid:18); 1. In the sleep phase, the recognition weights are turned off and the top-

down weights are used to activate the units. Starting at the top layer, activities are
generated at successively lower layers based on the current top-down weights (cid:18).

6

The network thus generates a random instance from its generative model. Since
it has generated the instance, it knows the true underlying causes, and therefore
has available the target values for the hidden units that are required to train the
bottom-up weights. If the bottom-up and the top-down activation functions are
both sigmoid (equations 6 and 8), then both phases use exactly the same learning
rule, the purely local delta rule (Widrow & Stearns, 1985).

Unfortunately, there is no single cost function that is reduced by these two proce-
dures. This is partly because the sleep phase trains the recognition model to invert
the generative model for input vectors that are distributed according to the gen-
erative model rather than according to the real data and partly because the sleep
phase learning does not follow the correct gradient. Nevertheless, 	(cid:11) = (cid:11) at the
optimal end point, if it can be reached. Preliminary results by Brendan Frey (per-
sonal communication) show that this algorithm works well on some non-trivial
tasks.

5 Discussion

The Helmholtz machine can be viewed as a hierarchical generalization of the type
of learning procedure described by Zemel (1994) and Hinton and Zemel (1994). In-
stead of using a xed independent prior distribution for each of the hidden units
in a layer, the Helmholtz machine makes this prior more exible by deriving it
from the bottom-up activities of units in the layer above. In related work, Zemel
and Hinton (1994) show that a system can learn a redundant population code in a
layer of hidden units, provided the activities of the hidden units are represented by
a point in a multidimensional constraint space with pre-specied dimensionality.
The role of their constraint space is to capture statistical dependencies among the
hidden unit activities and this can again be achieved in a more uniform way by us-
ing a second hidden layer in a hierarchical generative model of the type described
here.

The old idea of analysis-by-synthesis assumes that the cortex contains a gener-
ative model of the world and that recognition involves inverting the generative
model in real time. This has been attempted for non-probabilistic generative mod-
els (MacKay, 1956; Pece, 1992). However, for stochastic ones it typically involves
Markov chain Monte Carlo methods (Neal, 1992). These can be computationally
unattractive, and their requirement for repeated sampling renders them unlikely
to be employed by the cortex. In addition to making learning tractable, its sepa-
rate recognition model allows a Helmholtz machine to recognise without iterative
sampling, and makes it much easier to see how generative models could be im-
plemented in the cortex without running into serious time constraints. During

7

recognition, the generative model is superuous, since the recognition model con-
tains all the information that is required. Nevertheless, the generative model plays
an essential role in dening the objective function F that allows the parameters (cid:30)
of the recognition model to be learned.

The Helmholtz machine is closely related to other schemes for self-supervised
learning that use feedback as well as feedforward weights (Carpenter & Gross-
berg, 1987; Luttrell, 1992; 1994; Ullman, 1994; Kawato et al, 1993; Mumford, 1994).
By contrast with Adaptive Resonance Theory (Carpenter & Grossberg, 1987) and
the Counter-Streams model (Ullman, 1994), the Helmholtz machine treats self-
supervised learning as a statistical problem  one of ascertaining a generative
model which accurately captures the structure in the input examples. Luttrell
(1992; 1994) discusses multilayer self-supervised learning aimed at faithful vec-
tor quantisation in the face of noise, rather than our aim of maximising the like-
lihood. The outputs of his separate low level coding networks are combined at
higher levels, and thus their optimal coding choices become mutually dependent.
These networks can be given a coding interpretation that is very similar to that of
the Helmholtz machine. However, we are interested in distributed rather than lo-
cal representations at each level (multiple cause rather than single cause models),
forcing the approximations that we use. Kawato et al (1993) consider forward (gen-
erative) and inverse (recognition) models (Jordan & Rumelhart, 1992) in a similar
fashion to the Helmholtz machine, but without this probabilistic perspective. The
recognition weights between two layers do not just invert the generation weights
between those layers, but also take into account the prior activities in the upper
layer. The Helmholtz machine ts comfortably within the framework of Grenan-
ders Pattern Theory (Grenander, 1976) in the form of Mumfords (1994) proposals
for the mapping onto the brain.

As described, the recognition process in the Helmholtz machine is purely bottom-
up  the top-down generative model plays no direct role and there is no interac-
tion between units in a single layer. However, such effects are important in real
perception and can be implemented using iterative recognition, in which the gen-
erative and recognition activations interact to produce the nal activity of a unit.
This can introduce substantial theoretical complications in ensuring that the acti-
vation process is stable and converges adequately quickly, and in determining how
the weights should change so as to capture input examples more accurately. An in-
teresting rst step towards towards interaction within layers would be to organize
their units into small clusters with local excitation and longer-range inhibition, as
is seen in the columnar structure of the brain. Iteration would be conned within
layers, easing the complications.

8

Acknowledgements

We are very grateful to Drew van Camp, Brendan Frey, Geoff Goodhill, Mike Jor-
dan, David MacKay, Mike Revow, Virginia de Sa, Nici Schraudolph, Terry Se-
jnowski and Chris Williams for helpful discussions and comments, and particu-
larly to Mike Jordan for extensive criticism of an earlier version of this paper. This
work was supported by NSERC and IRIS. GEH is the Noranda Fellow of the Cana-
dian Institute for Advanced Research. The current address for RSZ is Baker Hall
330, Department of Psychology, Carnegie Mellon University, Pittsburgh, PA 15213

9

Appendices

A The Imaging Model

The sigmoid activation function given in equation 8 turned out not to work well
for the generative model for the input examples we tried, such as the shifter prob-
lem (gure 1). Learning almost invariably got caught in one of a variety of local
minima. In the context of a one layer generative model and without a recognition
model, Saund (1994a;b) discussed why this might happen in terms of the under-
lying imaging model  which is responsible for turning binary activities in what
we call layer 2 into probabilities of activation of the units in the input layer. He
suggested using a noisy-or imaging model (Pearl, 1986), for which the weights
k = 1, and are
0 (cid:20) (cid:18)1;
combined as:

j = 1 if unit 1

;j (cid:20) 1 are interpreted as probabilities that 
1 = 1 Yk (cid:16)1  1

;j(cid:17) :
k (cid:18)1;

The noisy-or imaging model worked somewhat better than the sigmoid model of
equation 8, but it was still prone to fall into local minima. Dayan & Zemel (1994)
suggested a yet more competitive rule based on the Integrated Segmentation and
Recognition architecture of Keeler et al (1991). In this, the weights 0 (cid:20) (cid:18)1;
;j are
interpreted as the odds that 

k = 1, and are combined as:

j = 1 if unit 1


j(cid:18); 

(17)

k

k

k


j(cid:18); 

1 = 1 

1
k (cid:18)1;

;j

k

1 k 1

(18)

For the deterministic Helmholtz machine, we need a version of this activation rule
that uses the probabilities 1 rather than the binary samples 1. This is some-
;j turns out
not to work. In the end (Dayan & Zemel, 1994) we used a product of this term and
the deterministic version of the noisy-or:

what complicated, since the obvious expression 1  1=1 k 1

(cid:18)1;

k

k


j(cid:18); 

1 = 0

1

@1 

1 k 1

k

(cid:18)1;

;j

k

1
A

0
@1 Yk

1  1

k

(cid:18)1;

;j

k

1  (cid:18)1;

;j

k

1
A

(19)

Appendix B gives the derivatives of this. We used the exact expected value of
equation 18 if there were only three units in layer 1 because it is computationally
inexpensive to work it out.

For convenience, we used the same imaging model (equations 18 and 19) for all
the generative connections. In general one could use different types of connections
between different levels.

10

B The Derivatives

Write F d; (cid:18); (cid:30) for the contribution to the overall error in equation 16 for input
example d, including the input layer:

F d; (cid:18); (cid:30) = X Xj



j g 

j (cid:16)1  

j(cid:17) g(cid:16)1  

j(cid:17)  

j g 

j (cid:16)1  

j(cid:17) g(cid:16)1  
j(cid:17)

Then the total derivative for input example d with respect to the activation of a
unit in layer  is:

@F d; (cid:18); (cid:30)

@

j

= g

1  

j

1  

j



j



j

Xi

X}>Xk

@F d; (cid:18); (cid:30)

@}

k

k

@}
@

j

1
i  1

i

1

i

(cid:16)1  1
i (cid:17)

i

@1
@

j

(20)

j affects the generative priors at layer   1, and the recognition
since changing 
activities at all layers higher than . These derivatives can be calculated in a single
backward propagation pass through the network, accumulating @F d; (cid:18); (cid:30)=@}
as it goes. The use of standard sigmoid units in the recognition direction makes
@}

j completely conventional. Using equation 19 makes:

k =@

k

i

@1
@

j

=

(cid:18);1

j ;i

(cid:17)2 0
@1 Ya
1
A

a;i

a

0
@1  
j ;i Ya6=j

a(cid:18) ;1

1  (cid:18);1

(cid:18);1

j ;i

1

a(cid:18) ;1

a;i

(cid:16)1 a 
0
@1 

1 a 

(cid:18) ;1

a;i

1  (cid:18) ;1

a;i

0
@1  

a

1
1
A 
A

(cid:18) ;1

a;i

1  (cid:18) ;1

a;i

(21)

1
A

One also needs the derivative:

i

@1
@(cid:18);1

j ;i

=

j


a(cid:18) ;1

a;i

(cid:16)1 a 
0
@1 

1 a 

1

(cid:18) ;1

a;i

1  (cid:18) ;1

a

(cid:17)2 0
@1 Ya
1
A

0
@1  
j ;i (cid:17)2 Ya6=j
(cid:16)1  (cid:18);1



j

a;i

1
A
0
@1  

a

a(cid:18) ;1

a;i

1
A 

(cid:18) ;1

a;i

1  (cid:18) ;1

a;i

(22)

1
A

This is exactly what we used for the imaging model in equation 19. However, it is
j(cid:18); 1 should really be a function of the stochas-
important to bear in mind that 
tic choices of the units in layer   1. The contribution to the expected cost F is a
i indicates aver-

function of Dg 
aging over the recognition distribution. These are not the same as gD
and g(cid:16)1 D

j(cid:18); 1E and Dg(cid:16)1  
j(cid:18); 1E
j(cid:18); 1E(cid:17), which is what the deterministic machine uses. For other

imaging models, it is possible to take this into account.

j(cid:18); 1(cid:17)E, where h

11

