Abstract

Color has been widely used for hand segmentation. How-
ever, many approaches rely on predened skin color models.
It is very difcult to predene a color model in a mobile
application where the light condition may change dramati-
cally over time. In this paper, we propose a novel statistical
approach to hand segmentation based on Bayes decision
theory. The proposed method requires no predened skin
color model. Instead it generates a hand color model and a
background color model for a given image, and uses these
models to classify each pixel in the image as either a hand
pixel or a background pixel. Models are generated using a
Gaussian mixture model with the restricted EM algorithm.
Our method is capable of segmenting hands of arbitrary
color in a complex scene. It performs well even when there
is a signicant overlap between hand and background col-
ors, or when the user wears gloves. We show that the Bayes
decision method is superior to a commonly used method by
comparing their upper bound performance. Experimental
results demonstrate the feasibility of the proposed method.

dynamic construction of hand and background color mod-
els using Gaussian mixture models and the restricted EM
algorithm. The proposed method is capable of segmenting
hands of arbitrary color in a complex scene. Another contri-
bution of this paper is the study of upper bound performance
for color-based hand segmentation. The study indicates the
limit for the color-based approaches. We demonstrate that
the proposed method is superior to a commonly used thresh-
old method.

The rest of the paper is organized as follows. Section
2 describes a motivating application where hand segmenta-
tion approaches based on predened color models are chal-
lenged. Section 3 presents the new method and algorithms.
Section 4 investigates the performance of the new method,
and compares it to the threshold method. Section 5 ad-
dresses the limitations of the proposed method and possible
improvements.

2. A Motivating Application

Finger

Men

u

for

W

earable

Computers

1. Introduction

Hand segmentation is a prerequisite for many gesture
recognition tasks [1]. A popular feature for hand segmenta-
tion is skin color. Many approaches rely on predened skin
color models, which work well in constrained environments.
In this paper, we investigate a hand segmentation problem
for a wearable computer application. We show that it is
very difcult to predene a color model in this case because
the light condition may change dramatically over time. To
solve the problem, we propose a novel statistical approach
to hand segmentation based on Bayes decision theory. The
new method still relies on color information, but requires
no predened skin color model. The key innovation is the

Recent technological advances have made wearable com-
puters available for many different applications. However,
how to efciently interact with a wearable computer is still
an open question. A gesture interface is certainly a good
solution to the problem. Finger can been used as pointers
for menu selection [2]. In a wearable environment a head-
mounted see-through display may jitter due to involuntarily
head motion. In this case it may be hard to point a nger at a
menu item, because the item is displayed at a xed position
on the head-mounted display and moves around with the
head.

We propose a new menu selection paradigm for wear-
able computers, namely the "nger menu". It works on a
wearable computer with a head-mounted see-through dis-
play and a head-mounted video camera. Unlike traditional


.

.
There are numerous publications on hand segmentation.
Two common methods are background subtraction and skin
color segmentation. Obviously background subtraction is
infeasible since there is no constant background. Color
segmentation [3] [4] [5] [6] [7] [8] [9] [10] is more suitable
in our case. Nevertheless, previous methods often use one
static skin color model, which is inadequate for us. In the
rest of this paper, we present a new way of segmenting hands
with color information.

Problem

F

orm

ulation

We formulate the hand segmentation problem as follows:
The hand is known to be in an image. The hand color is
unknown in advance (different environments may result in
different hand colors),but is assumed to be largely consistent
within the image. In addition, we are concerned with initial
hand segmentation, not subsequent hand tracking. Thus we
limit ourselves to a single image. Under these conditions,
we want to segment the hand from the background, i.e. for
each pixel in the image, we want to classify it as either a
hand pixel or a background pixel.

The

Data

Set

To facilitate the discussion, we introduce our hand image
data set. A user recorded image sequences of his hand with
a head-mounted camera while performing the various nger
menu actions. The actions were performed at typical places
where a wearable computer is used including: ofce, home,
vehicles, parks, and streets etc., with various backgrounds
and light conditions. Some sequences were taken while the
user was wearing gloves, which is a reasonable situation
for working in the eld. From the sequences, 326 images
were selected randomly and the hands in these images were
manually segmented. Each image is 80  60, 24 bit color.
The 326 images were randomly divided into two halves,
with 163 images as training data and the other 163 images
as test data. Figure 2 shows random samples of the training
data set.

GUIs that display menu items at xed positions on the
screen, our method associates menu items onto the users
ve ngers. It works as follows:

1. The user sees through the head-mounted screen. The
head-mount camera also monitors the same scene.
Since the users hand is not in the scene, no menu is
displayed. (Figure 1a).

2. The menu system is activated when the user moves
his hand, widely opened, into the scene. The system
detects the hand with the camera, and displays ve
menu items at appropriate positions so that they ap-
pear on the ngertips through the head-mount display.
(Figure 1b).

3. The menu items oat. When the hand moves, they
move accordingly so that they stay on the ngertips.
Thus there is no need for the user to move the hand
to a specic place to make a menu selection. (Figure
1c)

4. By bending a nger as if it is a virtual click, the user
can select the menu item on that ngertip (Figure 1d).

5. The menu system is de-activated when the user moves

his hand out of the view.

Figure

Finger

menu

demo

The advantages of this paradigm include:

intuitive in-
teraction, a user can operate the device with little or no
training; efcient operation, there is no need to move a n-
ger to a specic place to make a selection, which could be
a hard head-hand coordination task; and no need for special
pointing hardware.

In order to implement the nger menu system, we need
to recognize hands from images taken by the head-mounted
camera. Hand segmentation is an essential preprocessing
step. However it is a hard problem for the following reasons:

 There are no restrictions on the background.

 The camera moves with the users head.

Figure

Some

images

in

the

training

data

set

 The light conditions may change dramatically. This
includes changing shadow and varying light colors,
e.g. under a sodium-vapor lamp.

In this work we use the HSV color space [11] instead
of the RGB color space. Moreover, we use only Hue and


.

.

.

.

.

.
Saturation and ignore V (brightness) in order to minimize
the inuence of shadow and uneven lighting. We plot Hue-
Saturation histograms for analysis. Since the images are
manually segmented, we are able to plot the color histograms
for the overall image, the hand portion, and the background
portion respectively, as shown in Figure 3. Two observations
arise after investigating some images:

 The peak of hand color is not xed at a certain position
on the H-S plane (compare Figure 3b with 3d). This
means we cannot build a static hand color model for
all images.
Instead, we will build a different hand
color model for different image.

 The hand color may partially overlap with the back-
ground color, as shown in Figure 3d. This means
some hand pixels and background pixels have the
same color. Thus misclassication is inevitable in
color segmentation. However we want to minimize
the error.

(a) An example image, its hand and background portion

(b) Overall, hand and background histograms of (a)

(c) Another example image

(d) Histograms of (c)

Figure

Example

colo

r

histograms

Hand

Segmen

tation

with

Ba

y

es

Deci-

sion

Theory

Given the color c and coordinates x

, y of a pixel, we want

to classify it as a hand pixel if

P

hand

j

c;

x;

y

P

back g r ound

j

c;

x;

y

(1)

Applying the conditional version of Bayes rule, we get

P

hand

j

c;

x;

y

P

c

j

x;

y

P

c

j

hand;

x;

y

P

hand

j

x;

y

We assume c
i.e. P

hand;

c

j

x;

y

is conditionallyindependent of x, y given hand,

P

c

j

hand

 . Thus

P

hand

j

c;

x;

y

P

c

j

x;

y

P

c

j

hand

P

hand

j

x;

y

And

similarly for

P

back g r ound

j

c;

x;

y

P

hand

j

x;

y

P

back g r ound

j

x;

y

becomes

 .

Note
1, therefore (1)

P

c

j

hand

P

hand

j

x;

y

P

c

j

back g r ound

 1 (cid:0)

P

hand

j

x;

y

(2)

(2) is our Bayes decision criterion, which will be used to
classify the pixels in an image.

j

c

j

c

P

hand

back g r ound

We need three models to compute (2). The rst one,
 , is the hand color model of an image. The second
one, P
 , is the background color model of
the image. These two models need to be built for each
image dynamically, as discussed in Section 3.2. The third
 , describes the spatial distributionof hand
one, P
pixels, i.e. how likely the pixel 
is a hand pixel. We
can estimate it from the training data set as follows:

hand

j

x;

y

x;

y

P

hand

j

x;

y

P

i

tr aining

imag es

P

i

tr aining

imag es

x;

y

i

1

(3)

y

x;

y

x;

i

1 if 

where 
is a hand pixel in image i ,
0 otherwise. Figure 4 is the P
 distribution of
our training data set. The highest region corresponds to the
palm. Since the user tends to place the hand at the center of
the view, this distribution is reasonable.

hand

j

x;

y

3. A Novel Color Segmentation Method

Obtaining

Color

Mo dels

from

Gaussian

Mixture

Mo dels

In this section, we rst introduce a Bayes decision theory
framework for segmentation. The framework needs a hand
color model and a background color model to work. We
then present an approach to build the models dynamically
for any given image using Gaussian mixture models and the
restricted EM algorithm, which is the key innovation of this
paper.

We need to estimate the hand color model P

c

j

hand

j

c

back g r ound

and the background color model P
 for any
given image. Since hand color may change from image
to image, and the hand color may partly overlap with the
background color (as in Figure 3), this is not a trivial task.
One observation is that hand color is largely consistent
within an image. This means hand pixels tend to concentrate


.

.

.







=









=



=










+


=


















=







=



.

.



Figure

a

GMM

of

Figure

a

b

y

standa

rd

EM.

b-f

The

w

eighted

comp onent

Gaussians

w

N

i

i

i s and S

c

P

c

i s, 

i s, such that P

parameters w
 .
Figure 5 is the GMM trained with random starting param-
eters for the image in Figure 3a. Note how well the GMM
approximates the actual overall color distribution in Figure
3b. Also note how well w
1 (Figure 5b) resembles the
actual hand color distributionin Figure 3b. Since we assume
the hand color can be modeled with a Gaussian distribution,
1 can be used as the hand color model.
it is natural to think N
An immediate question follows: Can we guarantee that N
1
approximates the actual hand color distribution well enough
for any image? If the answer is yes, then by the denition
of GMM:

1 

N

Figure

P

hand

j

x;

y

of

the

training

data

and form a single peak in a hand color histogram. Intuitively
it suggests to model the hand color P
 with a Gaus-
sian distribution. This leads to the following method.

hand

c

j

Given an image, we can easily compute its overall color
 by normalizing the color histogram of the

c

distribution P
whole image:

P

c

w

1 

N

1 

c

w

N

c

i

i

(5)

K

X

= 2

i

And comparing (4) with (5), we would have the following
parametric forms to solve the problem:

C

ount

pixel s

w ith

col or

c

P

c

C

ount

al l

pixel s

P

hand

P

c

j

hand

It has the following relationship with the (yet unknown)
hand color model and background color model:

P

c

j

back g r ound

w

N

1

1 

c

1

K

X

1 (cid:0)

w

1

= 2

i

(6)

(7)

w

N

c

i

i

P

c

P

hand

P

c

j

hand

 1 (cid:0)

P

hand

P

c

j

back g r ound

(4)

hand

where P
is the percentage of hand pixels in the
image, or the relative hand size (not to be confused with
in the previous section, which is a pixel level

hand

j

x;

y

P

value).

We can approximate P

Model (GMM) P
K Gaussian distributions N

c

 with a Gaussian Mixture
 [12]. The GMM is a weighted sum of

c

1 ;

N

K

:

K

X

K

X

P

c

w

N

c

w her e

w

i

i

i

= 1

i

= 1

i

1

K

i , S

is determined empirically. We found K

5 is sufcient.
Let 
i s mean and covariance matrix respec-
tively. With the Expectation Maximization (EM) algorithm
[13] [14], we can train the GMM, that is to nd a set of

i denote N

Unfortunately, in most cases the answer is no if we use the
standard EM algorithm. In fact, the standard EM algorithm
only guarantees the overall tting of the whole distribution,
but has virtually no control over the individual component
Gaussians. There is no guarantee that any of the K Gaussian
components will be a reasonable approximation to the actual
hand color distribution. Better starting parameter heuristics
will not help either. Figures 6(a-d) show an example image
and its histograms. Figures 6(f-j) are the Gaussian compo-
nents obtained using the standard EM algorithm. Obviously
none of the Gaussian components resembles the actual hand
color distribution (Figure 6c).

However, we will show that with certain modications
1, the rst
to the standard EM algorithm, we can enforce N
Gaussian component of a GMM, to be a good approximation
of the hand color distribution such that we can use (6)(7).
This is the key innovation of our method.


.



.






=






=





+













:
:
:
;



=



;
=
=








=

+





=


=



=



Figure

a

An

image

sho

wing

the

deciency

of

standa

rd

EM.

b,c,d

The

overall,

hand

and

background

colo

r

histogram.

e

The

GMM

b

y

standa

rd

EM.

f-j

The

w

eighted

comp onent

Gaussians.

The

Restricted

EM

Algorithm

Estimating

the

Restrictions

During the Maximization step of the standard EM al-
gorithm, the mean, covariance and weight of each Gaussian
component can be adjusted freely. However we can x some
parameters to certain values, or limit their ranges during EM
training. We call it the restricted EM algorithm. It will still
converge to a local maximum in terms of likelihood [15].
More specically, in this paper we will x  1 =
 1 and limit
 . The meaning and value
of  1 , w
will be discussed in next section.
By restricting these two parameters, we can enforce N
1 to
approximate the hand color distribution. The restricted EM
algorithm is:

1 to be within range 

, and w

hig h

hig h

low

low

w

w

w

Initialization:

Let  1 =
Set other parameters randomly.

 1, w

1 =

hig h

low

w

w

= 2.

During the E-step:

Collect counts as in standard EM algorithm.

During the M-step:

as in standard EM,

K

5. Similarly for the w

1 

w

low

case.

Iterating the E-step and M-step until converge.

Figure 7 shows the effect of the restricted EM algorithm.
Figure 7a is the GMM obtained with the restricted EM al-
gorithm on the same image of Figure 6a. Note the rst
Gaussian component (Figure 7b) now approximates the ac-
tual hand color histogram (Figure 6c).

leave  1 unchanged.

1. Adjust only  2 ;
2. Adjust S 1 ;
3. Adjust w
4. If 
1 

1 ;

hig h

w

w

w

 Then
1 (cid:0)

w

 1 +

w

w

i

i

w

1 =

w

hig h

as in standard EM
as in standard EM

K

K

w

hig h

w

1

i

2 ;

K

1 (cid:0)

tion.
lows. Consider three random variables C

 1 is the estimated mean of the hand color distribu-
It needs to be estimated for each image as fol-
and
has
has distribution
 . We

, C
which take value of possible colors. C

is the color of pixel 

distribution P

 , and C

 .

C

back g r ound

P

c

back g r ound

back g r ound

hand

hand

hand

xy

xy

c

j

j

C

x;

y

assume the following generative random process:

C

P

hand

j

x;

y

C

xy

hand

 1 (cid:0)

P

hand

j

x;

y

C

back g r ound

y

x;

That is, pixel 
 s color is generated in such a way:
Firstly the identity of this pixel is chosen to be hand with
probability P
 and background with probabil-
ity 1 (cid:0)
distribution). Secondly, if it is hand a color is randomly
picked for the pixel according to P
 , otherwise the
color is picked according to P

(see Figure 4 for the P

 .

back g r ound

hand

hand

hand

hand

j

x;

y

P

j

x;

y

j

x;

y

c

j

c

j

Now consider a set of pixels in an image with hand proba-
is a xed value between 0
g .

bility P
and 1. Denote this set as S
The expectation of the previous equation over this set is

p , where p

hand

hand

j

x;

y

p

f

x;

y

x;

y

p

j

P

j

x;

y

S

p

: E

By denition E

C

hand

C

p

E

C

xy

P

hand

 1 (cid:0)

p

E

C

back g r ound

 1. And for 

x;

y

S

p :

E

C

xy

k

S

k

p

x;y

S

p

col or

of

x;

y

Av er ag e

col or

of

pixel s

S

p

Therefore we get
1

 1

Av er ag e

col or

of

pixel s

p

S

p


.

.

.
;

+

:
:
:
;

:
:
:
;
S
:
:
:
;
=


;
=
:
:
:
;

.

.


=



+













=
=




=





=



+






=




=





=

=



(cid:0)
Figure

a

GMM

of

Figure

a

b

y

restricted

EM.

b-f

The

w

eighted

comp onent

Gaussians

w

N

i

i

1 (cid:0)

p

p

E

C

back g r ound

(8)

4. Performance Analysis

where E
 can be estimated from the training
data. In particular, if we can nd some p close to 1 such that

back g r ound

C

is large enough, we can use the approximation

k

S

k

p

 1 

Av er ag e

col or

of

pixel s

S

p

, w

The restrictions w

low

1, which can be
 , the relative hand size. They are es-

interpreted as P
timated from the training data. The distribution of P
in the training data is plotted in Figure 8. We compute the

control w

hig h

hand

hand

Figure

P

hand

in

training

data

mean  and standard deviation  of this distribution. Since
we expect the hand size in a new image to be comparable to
those in the training data, we let

The

P

erformance

on

T

est

Data

We tested the proposed method on the 163 test images.
We achieved an average false positive (background misclas-
sied as hand) rate of 4.0%, false negative rate of 7.5%,
and total error rate of 11.5%. The decoding takes about 0.1
second for each image on a PC.

Figure 9 shows some segmentation results. Since our
method is a pure pixel-wise statistical classier, no ltering
is applied. Therefore some segmented hands have holes
or background dots. Figure 9g, 9h show the user wearing
gloves. Since the gloves have consistent color, they are eas-
ily recognized. Figure 9k is an example where the hand
Gaussian mistakenly grabs a nearby background color
peak during restricted EM training. Figure 9l shows an-
other case where our method fails. This is because the hand
color in this image is not consistent: the image was taken
inside a car, the thumb and part of the palm was rendered
bluish under the windshield. Therefore a single Gaussian
can no longer model the hand color, which leads to the fail-
ure. Nonetheless, given the difculty of the test set, we
consider our method to be promising.

The

Upp er

Bound

P

erformance

of

Our

w

low

2 

w

hig h

2 

(9)

Metho d

We are interested in the upper bound performance of
the proposed method. That is the performance when we
have perfect hand and background color models. Since
the test data are also manually segmented, we are able to
build a perfect hand color model for each test image by
normalizing its hand color histogram:

The

Complete

Algorithm

The complete algorithm is as follows.

During training:

Build P
Estimate the weight restrictions w

 with (3)

hand

j

x;

y

During decoding:

, w

hig h

low

with (9)

P

c

j

hand

C

ount

hand

pixel s

w ith

col or

c

C

ount

hand

pixel s

Estimate the mean restriction  1 with (8)
Run the restricted EM algorithm in Section 3.3
Generate the hand color model with (6)
Generate the background color model with (7)
Classify each pixel with (2)

and similarly a perfect background color model. Then
we use these perfect models to classify pixels in the same
image. The performance is considered the upper bound of
our method, because the models obtained by (6) and (7) are
approximations to these perfect models.


.












.


=

(cid:0)
;
=

+

.

.


.

.

.

.



=




Figure

Segmentation

results

The

Upp er

Bound

P

erformance

of

A

Simple

Threshold

Metho d

False Neg.

False Pos.

Error
11.6%

4.0%

We compare the Bayesian method with a simple skin
color segmentation method that is frequently (but often im-
plicitly) used. The simple method builds a hand color model

P

c

j

hand

 and classies a pixel as a hand pixel if

P

col or

of

the

pixel

j

hand

T

for some threshold T
ground pixel.

, otherwise it classies it as a back-

We are interested in the upper bound performance of this
method. As in Section 4.2 we build a perfect hand color
model for each image, and classify the pixels in the same im-
age with the simple method. We repeat the experiment with
different thresholds T
. Figure 10a shows the performance
curve with different T
. The lowest error rate is 18.3% with
T =0.015. Figures 10b and 10c show how false negative and
false positive rates change with respect to T
in the method.
(the color distributionsare mapped to one dimension). Since
the two distributions are intrinsically overlapping, a small T
will generate less false negative but more false positive, and
vise versa.

Table 1 summarizes the performances of different meth-
ods. Obviously the Bayes decision method is better than the
simple threshold method.

5. Conclusions

We proposed a new way of color segmentation for hand
recognition in a wearable environment. The method builds

Bayes Method
(Actual)
Bayes Method
(Upper Bound)
Simple Method
(Upper Bound)

7.5%

3.1%

6.4%

3.6%

6.7%

11.9%

18.3%

T

able

P

erfo

rmance

compa

rison

statistical hand and background color models for each image
using GMM and the restricted EM algorithm, and classies
pixels with Bayes decision criterion. The performance of
the proposed method is promising.

The success of this method relies on the assumption that
hand color in a given image is consistent, and hence can
be modeled by a Gaussian distribution. Another important
prerequisite is that there need to be a few positions where
hand tends to occur with high probability, so that the aver-
age hand color in a given image can be estimated reliably.
The wearable computer application mentioned in Section 2
satises these requirements.

Many things can be done for further improvement. For
example, some conventional image processing methods such
as ltering and region growing will denitely help. More
over, currently each pixel is processed individually, whereas
it might be benecial to consider interactions between pixels.
In addition, we only considered color information. As the
upper bound performance reveals, there is a limit on how


.

.

.





.
Figure

The

average

upp er

b ound

p erfo

rmance

of

a

simple

metho d

and

its

analysis

well we can do with color. Adding different information,
such as shape, would be helpful. We are investigating some
of them, and are applying the proposed method to create a
gesture based wearable computer interface.

[6] Y. Raja, S. J. McKenna, S. G. Gong. Tracking and Seg-
menting People in Varying Lighting Conditions using
Colour. Proc. 3rd Intl Conf. On Automatic Face and
Gesture Recognition, pp 228-233, 1998

6. Acknowledgement

The authors would like to thank Larry Wasserman, Roni
Rosenfeld, Hua Yu, Pan Yue, Ke Yang, Iain Matthews,
William Kunz and all members in the Interactive Systems
Labs for their inspiring suggestions and help. This research
is partially supported by the Defense Advanced Research
Projects Agency under contract number DAAD17-99-C-
0061. Xiaojin Zhus research is supported in part by the
National Science Fundation under grant SBR-9720374.

