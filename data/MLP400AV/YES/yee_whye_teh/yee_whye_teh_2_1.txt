Bayesian Nonparametric Models
Peter Orbanz, Cambridge University
Yee Whye Teh, University College London
Related keywords: Bayesian Methods, Prior Probabilities, Dirichlet Process,
Gaussian Processes.
Defnition
A Bayesian nonparametric model is a Bayesian model on an infnite-dimensional
parameter space. The parameter space is typically chosen as the set of all possi-
ble solutions for a given learning problem. For example, in a regression problem
the parameter space can be the set of continuous functions, and in a density esti-
mation problem the space can consist of all densities. A Bayesian nonparametric
model uses only a fnite subset of the available parameter dimensions to explain
a fnite sample of observations, with the set of dimensions chosen depending on
the sample, such that the efective complexity of the model (as measured by the
number of dimensions used) adapts to the data. Classical adaptive problems,
such as nonparametric estimation and model selection, can thus be formulated
as Bayesian inference problems. Popular examples of Bayesian nonparametric
models include Gaussian process regression, in which the correlation structure
is refned with growing sample size, and Dirichlet process mixture models for
clustering, which adapt the number of clusters to the complexity of the data.
Bayesian nonparametric models have recently been applied to a variety of ma-
chine learning problems, including regression, classifcation, clustering, latent
variable modeling, sequential modeling, image segmentation, source separation
and grammar induction.
Motivation and Background
Most of machine learning is concerned with learning an appropriate set of pa-
rameters within a model class from training data. The meta level problems
of determining appropriate model classes are referred to as model selection or
model adaptation. These constitute important concerns for machine learning
practitioners, chiefy for avoidance of over-ftting and under-ftting, but also for
discovery of the causes and structures underlying data. Examples of model se-
lection and adaptation include: selecting the number of clusters in a clustering
problem, the number of hidden states in a hidden Markov model, the number
1
 of latent variables in a latent variable model, or the complexity of features used
in nonlinear regression.
Nonparametric models constitute an approach to model selection and adap-
tation, where the sizes of models are allowed to grow with data size. This is
as opposed to parametric models which uses a fxed number of parameters. For
example, a parametric approach to density estimation would be to ft a Gaus-
sian or a mixture of a fxed number of Gaussians by maximum likelihood. A
nonparametric approach would be a Parzen window estimator, which centers a
Gaussian at each observation (and hence uses one mean parameter per observa-
tion). Another example is the support vector machine with a Gaussian kernel.
The representer theorem shows that the decision function is a linear combina-
tion of Gaussian radial basis functions centered at every input vector, and thus
has a complexity that grows with more observations. Nonparametric methods
have long been popular in classical (non-Bayesian) statistics [1]. They often per-
form impressively in applications and, though theoretical results for such models
are typically harder to prove than for parametric models, appealing theoretical
properties have been established for a wide range of models.
Bayesian nonparametric methods provide a Bayesian framework for model
selection and adaptation using nonparametric models. A Bayesian formulation
of nonparametric problems is nontrivial, since a Bayesian model defnes prior
and posterior distributions on a single fxed parameter space, but the dimen-
sion of the parameter space in a nonparametric approach should change with
sample size. The Bayesian nonparametric solution to this problem is to use
an infnite-dimensional parameter space, and to invoke only a fnite subset of
the available parameters on any given fnite data set. This subset generally
grows with the data set.
In the context of Bayesian nonparametric models,
infinite-dimensionalcan therefore be interpreted as of fnite but unbounded
dimension. More precisely, a Bayesian nonparametric model is a model that
(1) constitutes a Bayesian model on an infnite-dimensional parameter space
and (2) can be evaluated on a fnite sample in a manner that uses only a fnite
subset of the available parameters to explain the sample.
We make the above description more concrete in the next section when we
describe a number of standard machine learning problems and the correspond-
ing Bayesian nonparametric solutions. As we will see, the parameter space in
(1) typically consists of functions or of measures, while (2) is usually achieved
by marginalizing out surplus dimensions over the prior. Random functions and
measures, and more generally probability distributions on infnite-dimensional
random objects, are called stochastic processes; examples we will encounter
include Gaussian processes, Dirichlet processes and beta processes. Bayesian
nonparametric models are often named after the stochastic processes they con-
tain. The examples are then followed by theoretical considerations, including
formal constructions and representations of the stochastic processes used in
Bayesian nonparametric models, exchangeability, and issues of consistency and
convergence rate. We conclude this article with future directions and a reading
list.
2
 Examples
density function over data items x of the form p(x) =(cid:80)K
p(x) =(cid:82) p(x|)G()d, where G =(cid:80)K
Clustering with mixture models. Bayesian nonparametric generalizations
of fnite mixture models provide an approach for estimating both the number
of components in a mixture model and the parameters of the individual mix-
ture components simultaneously from data. Finite mixture models defne a
k=1 kp(x|k), where
k is the mixing proportion and k are parameters associated with compo-
nent k. The density can be written in a non-standard manner as an integral:
k=1 kHk is a discrete mixing distribution
encapsulating all the parameters of the mixture model and H is a Dirac dis-
tribution (atom) centered at . Bayesian nonparametric mixtures use mixing
distributions consisting of a countably infnite number of atoms instead:
(cid:88)
G =
kHk .
(1)
k=1
This gives rise to mixture models with an infnite number of components. When
applied to a fnite training set, only a fnite (but varying) number of components
will be used to model the data, since each data item is associated with exactly
one component but each component can be associated with multiple data items.
Inference in the model then automatically recovers both the number of compo-
nents to use and the parameters of the components. Being Bayesian, we need
a prior over the mixing distribution G, and the most common prior to use is a
Dirichlet process (DP). The resulting mixture model is called a DP mixture.
Formally, a Dirichlet process DP(, H) parametrized by a concentration
paramter > 0 and a base distribution H is a prior over distributions (probabil-
ity measures) G such that, for any fnite partition A1, . . . , Am of the parameter
space, the induced random vector (G(A1), . . . , G(Am)) is Dirichlet distributed
with parameters (H(A1), . . . , H(Am)) (see the theory section for a discussion
of subtleties involved in this defnition). It can be shown that draws from a DP
will be discrete distributions as given in (1). The DP also induces a distribution
over partitions of integers called the Chinese restaurant process (CRP), which
directly describes the prior over how data items are clustered under the DP
mixture. For more details on the DP and the CRP, see DP entry [f].
Nonlinear regression. The aim of regression is to infer a continuous function
from a training set consisting of input-output pairs {(ti, xi)}n
i=1. Parametric
approaches parametrize the function using a fnite number of parameters and
attempt to infer these parameters from data. The prototypical Bayesian non-
parametric approach to this problem is to defne a prior distribution over con-
tinuous functions directly by means of a Gaussian process (GP). As explained in
GP entry [f], a GP is a distribution on an infnite collection of random variables
Xt, such that the joint distribution of each fnite subset Xt1 , . . . , Xtm is a mul-
tivariate Gaussian. A value xt taken by the variable Xt can be regarded as the
value of a continuous function f at t, that is, f(t) = xt. Given the training set,
the Gaussian process posterior is again a distribution on functions, conditional
3
 on these functions taking values f(t1) = x1, . . . , f(tn) = xn.
Latent feature models. Latent feature models represent a set of objects in
terms of a set of latent features, each of which represents an independent degree
of variation exhibited by the data. Such a representation of data is sometimes
referred to as a distributed representation. In analogy to nonparametric mix-
ture models with an unknown number of clusters, a Bayesian nonparametric
approach to latent feature modeling allows for an unknown number of latent
features. The stochastic processes involved here are known as the Indian bufet
process (IBP) and the beta process (BP). Draws from BPs are random discrete
measures, where each of an infnite number of atoms has a mass in (0, 1) but
the masses of atoms need not sum to 1. Each atom corresponds to a feature,
with the mass corresponding to the probability that the feature is present for
an object. We can visualize the occurrences of features among objects using a
binary matrix, where the (i, k) entry is 1 if object i has feature k and 0 oth-
erwise. The distribution over binary matrices induced by the BP is called the
IBP.
Hidden Markov models. Hidden Markov models (HMMs) are popular mod-
els for sequential or temporal data, where each time step is associate with a
state, with state transitions dependent on the previous state. An infnite HMM
is a Bayesian nonparametric approach to HMMs, where the number of states is
unbounded and allowed to grow with the sequence length. It is defned using
one DP prior for the transition probabilities going out from each state. To en-
sure that the set of states reachable from each outgoing state is the same, the
base distributions of the DPs are shared and given a DP prior recursively. The
construction is called a hierarchical Dirichlet process (HDP); see below.
Density estimation. A nonparametric Bayesian approach to density estima-
tion requires a prior on densities or distributions. However, the DP is not useful
in this context, since it generates discrete distributions. A useful density estima-
tor should smooth the empirical density (such as a Parzen window estimator),
which requires a prior that can generate smooth distributions. Priors applicable
in density estimation problems include DP mixture models and Polya trees.
DP mixture models: Since the mixing distribution in the DP mixture is
random, the induced density p(x) is random thus the DP mixture can be used
as a prior over densities. Despite the fact that these are now primarily used in
machine learning as clustering models, they were in fact originally proposed for
density estimation.
Polya Trees are priors on probability distributions that can generate both
discrete and piecewise continuous distributions, depending on the choice of pa-
rameters. Polya trees are defned by a recursive infnitely deep binary subdi-
vision of the domain of the generated random measure. Each subdivision is
associated with a beta random variable which describes the relative amount of
mass on each side of the subdivision. The DP is a special case of a Polya tree
corresponding to a particular parametrization. For other parametrizations the
resulting random distribution can be smooth so is suitable for density estima-
tion.
Power-law Phenomena. Many naturally occurring phenomena exhibit power-
4
 law behavior. Examples include natural languages, images and social and ge-
netic networks. An interesting generalization of the DP, called the Pitman-Yor
process, PYP(, d, H), has recently been successfully used as models of such
power-law data. The Pitman-Yor process augments the DP by a third parame-
ter d [0, 1). When d = 0 the PYP is a DP(, H), while when = 0 it is a so
called normalized stable process.
Sequential modeling. HMMs model sequential data using latent variables
representing the underlying state of the system, and assuming that each state
only depends on the previous state (the so called Markov property). In some
applications, for example language modeling and text compression, we are inter-
ested in directly modeling sequences without using latent variables, and without
making any Markov assumptions, i.e. modeling each observation conditional on
all previous observations in the sequence. Since the set of potential sequences
of previous observations is unbounded, this calls for nonparametric models. A
hierarchical Pitman-Yor process can be used to construct a Bayesian nonpara-
metric solution whereby the conditional probabilities are coupled hierarchically.
Dependent and hierarchical models. Most of the Bayesian nonparametric
models described above are applied in settings where observations are homo-
geneous or exchangeable.
In many real world settings observations are often
not homogeneous, in fact they are often structured in interesting ways. For
example, the data generating process might change over time thus observations
at diferent times are not exchangeable, or observations might come in distinct
groups with those in the same group being more similar than across groups.
Signifcant recent eforts in Bayesian nonparametrics research have been
placed in developing extensions that can handle these non-homogeneous set-
tings. Dependent Dirichlet processes are stochastic processes, typically over a
spatial or temporal domain, which defne a Dirichlet process (or a related ran-
dom measure) at each point with neighboring DPs being more dependent. These
are used for spatial modeling, nonparametric regression, as well as for modeling
temporal changes. Alternatively, hierarchical Bayesian nonparametric models
like the hierarchical DP aim to couple multiple Bayesian nonparametric mod-
els within a hierarchical Bayesian framework. The idea is to allow sharing of
statistical strength across multiple groups of observations. Among other appli-
cations, these have been used in the infnite HMM, topic modeling, language
modeling, word segmentation, image segmentation and grammar induction. For
an overview of various dependent Bayesian nonparametric models and their ap-
plications in biostatistics please consult [2].
[3] is an overview of hierarchical
Bayesian nonparametric models as well as a variety of applications in machine
learning.
Theory
As we saw in the preceding examples, Bayesian nonparametric models often
make use of priors over functions and measures. Because these spaces typically
have an uncountable number of dimensions, extra care has to be taken to defne
5
 the priors properly and to study the asymptotic properties of estimation in the
resulting models.
In this section we give an overview of the basic concepts
involved in the theory of Bayesian nonparametric models. We start with a
discussion of the importance of exchangeability in Bayesian parametric and
nonparametric statistics. This is followed by representations of the priors and
issues of convergence.
Exchangeability
The underlying assumption of all Bayesian methods is that the parameter spec-
ifying the observation model is a random variable. This assumption is subject
to much criticism, and at the heart of the Bayesian versus non-Bayesian debate
that has long divided the statistics community. However, there is a very general
type of observations for which the existence of such a random variable can be
derived mathematically: For so-called exchangeable observations, the Bayesian
assumption that a randomly distributed parameter exists is not a modeling
assumption, but a mathematical consequence of the datas properties.
Formally, a sequence of variables X1, X2, . . . , Xn over the same probability
space (X , f) is exchangeable if their joint distribution is invariant to permuting
the variables. That is, if P is the joint distribution and any permutation of
{1, . . . , n}, then
P (X1 = x1, X2 = x2 . . . Xn = xn) = P (X1 = x(1), X2 = x(2) . . . Xn = x(n)) (2)
An infnite sequence X1, X2, . . . is infnitely exchangeable if X1, . . . , Xn is ex-
changeable for every n 1. In this paper we will mean infnite exchangeability
whenever we write exchangeability. Exchangeability refects the assumption
that the variables do not depend on their indices although they may be depen-
dent among themselves. This is typically a reasonable assumption in machine
learning and statistical applications, even if the variables are not themselves iid
(independently and identically distributed). Exchangeability is a much weaker
assumption than iid; iid variables are automatically exchangeable.
If parametrizes the underlying distribution, and one assumes a prior dis-
tribution over , then the resulting marginal distribution over X1, X2, . . . with
 marginalized out will still be exchangeable. A fundamental result credited
to de Finetti [4] states that the converse is also true. That is, if X1, X2, . . . is
(infnitely) exchangeable, then there is a random such that:
(cid:90)
n(cid:89)
P (X1, . . . , Xn) =
P ()
P (Xi|)d
(3)
i=1
for every n 1. In other words, the seemingly innocuous assumption of ex-
changeability automatically implies the existence of a hierarchical Bayesian
model with being the random latent parameter. This the crux of the fun-
damental importance of exchangeability to Bayesian statistics.
In de Finettis Theorem it is important to stress that can be infnite dimen-
sional (it is typically a random measure), thus the hierarchical Bayesian model
6
 (3) is typically a nonparametric one. For example, the Blackwell-MacQueen
urn scheme (related to the CRP) is exchangeable thus implicitly defnes a ran-
dom measure, namely the DP (see the DP entry [f] for more details). In this
sense, we will see below that de Finettis Theorem is an alternative route to Kol-
mogorovs Extension Theorem, which implicitly defnes the stochastic processes
underlying Bayesian nonparametric models.
Model Representations
In fnite dimensions, a probability model is usually defned by a density function
or probability mass function. In infnite-dimensional spaces, this approach is
not generally feasible, for reasons explained below. To defne or work with
a Bayesian nonparametric model, we have to choose alternative mathematical
representations.
Weak Distributions. A weak distribution is a representation for the dis-
tribution of a stochastic process, that is, for a probability distribution on an
infnite-dimensional sample space.
If we assume that the dimensions of the
space are indexed by t T , the stochastic process can be regarded as the joint
distribution P of an infnite set of random variables {Xt}tT . For any fnite
subset S f T of dimensions, the joint distribution PS of the corresponding
subset {Xt}tS of random variables is a fnite-dimensional marginal of P . The
weak distribution of a stochastic process is the set of all its fnite-dimensional
marginals, that is, the set {PS : S f T,|S| < }. For example, the customary
defnition of the Gaussian process as an infnite collection of random variables,
each fnite subset of which has a joint Gaussian distribution, is an example of
a weak distribution representation. In contrast to the explicit representations
to be described below, this representation is generally not generative, because
it represents the distribution rather than a random draw, but is more widely
applicable.
Apparently, just defning a weak distribution in this manner need not im-
ply that it is a valid representation of a stochastic process. A given collection
of fnite-dimensional distributions represents a stochastic process only (1) if a
process with these distributions as its marginals actually exists, and (2) if it is
uniquely defned by the marginals. The mathematical result which guarantees
that weak distribution representations are valid is the Kolmogorov Extension
Theorem (also known as the Daniell-Kolmogorov theorem or the Kolmogorov
Consistency Theorem). Suppose that a collection {PS : S f T,|S| < } of
distributions is given. If all distributions in the collection are marginals of each
other, that is, if PS1 is a marginal of PS2 whenever S1 f S2, the set of distribu-
tions is called a projective family. The Kolmogorov Extension Theorem states
that, if the set T is countable, and if the distributions PS form a projective
family, then there exists a uniquely defned stochastic process with the collec-
tion {PS} as its marginal distributions. In other words, any projective family
for a countable set T of dimensions is the weak distribution of a stochastic pro-
cess. Conversely, any stochastic process can be represented in this manner, by
computing its set of fnite-dimensional marginals.
7
 The weak distribution representation assumes that all individual random
variable Xt of the stochastic process take values in the same sample space f.
The stochastic process P defned by the weak distribution is then a probability
distribution on the sample space fT , which can be interpreted as the set of all
function f : T f. For example, to construct a GP we might choose T = Q
and f = R to obtain real-valued functions on the countable space of rational
numbers. Since Q is dense in R, the function f can then be extended to all of
R by continuity. To defne the DP as a distribution over probability measures
on R, we note that a probability measure is a set function that maps random
events, i.e. elements of the Borel -algebra B(R) of R, into probabilities in
[0, 1]. We could therefore choose a weak distribution consisting of Dirichlet
distributions, and set T = B(R) and f = [0, 1]. However, this approach raises a
new problem because the set B(R) is not countable. As in the GP, we can frst
defne the DP on a countable base for B(R) then extend to all random events
by continuity of measures. More precise descriptions are unfortunately beyond
the scope of this entry.
Explicit Representations. Explicit representations directly describe a ran-
dom draw from a stochastic process, rather than describing its distribution. A
prominent example of an explicit representation is the so-called stick-breaking
representation of the Dirichlet process.The discrete random measure G in (1)
is completely determined by the two infnite sequences {k}kN and {k}kN.
(cid:81)kf1
The stick-breaking representation of the DP generates these two sequences by
drawing k H iid and vk Beta(1, ) for k = 1, 2, . . . . The coefcients k are
j=1 (1 f vk). The measure G so obtained can be
then computed as k = vk
shown to be distributed according to a DP(, G0). Similar representations can
be derived for the Pitman-Yor process and the beta process as well. Explicit
representations, if they exist for a given model, are typically of great practical
importance for the derivation of algorithms.
Implicit Representations. A third representation of infnite dimensional
models is based on de Finettis Theorem. Any exchangeable sequence X1, . . . , Xn
uniquely defnes a stochastic process , called the de Finetti measure, making
the Xis iid. If the Xis are sufcient to defne the rest of the model and their
conditional distributions are easily specifed, then it is sufcient to work directly
with the Xis and have the underlying stochastic process implicitly defned. Ex-
amples include the Chinese restaurant process (an exchangeable distribution
over partitions) with the DP as the de Finetti measure, and the Indian bufet
process (an exchangeable distribution over binary matrices) with the BP being
the corresponding de Finetti measure. These implicit representations are useful
in practice as they can lead to simple and efcient inference algorithms.
Finite Representations. A fourth representation of Bayesian nonparametric
models is as the infnite limit of fnite (parametric) Bayesian models. For exam-
ple, DP mixtures can be derived as the infnite limit of fnite mixture models
with particular Dirichlet priors on mixing proportions, GPs can be derived as
the infnite limit of particular Bayesian regression models with Gaussian priors,
while BPs can be derived as from the limit of an infnite number of indepen-
8
 dent beta variables. These representations are sometimes more intuitive for
practitioners familiar with parametric models. However not all Bayesian non-
parametric models can be expressed in this fashion, and they do not necessarily
make clear the mathematical subtleties involved.
Consistency and Convergence Rates
Recent work in mathematical statistics examines the convergence properties of
Bayesian nonparametric models, and in particular the questions of consistency
and convergence rates.
Intuitively, a consistent estimation procedure is a method that will result
in a correct estimate if it has access to an infnite amount of data, that is,
a procedure that will be accurate unless it is hampered by insufcient sample
size. In Bayesian statistics, an estimate is a distribution over possible parameter
values (the posterior), and hence consistency in Bayesian models is defned by
demanding that the posterior converges to a delta peak at the true parameter.
A classic theorem by J. L. Doob shows that for any Bayesian model, the set
of all possible true parameter values for which the model will be consistent has
probability one under the prior.
In other words, if the true parameter (and
hence the data distribution) is chosen at random from the prior, we will always
end up with a consistent model, and a Bayesian who is certain about the prior
need not worry about inconsistency. This result does not hold anymore if the
true parameter value is not in the domain of the prior. In nonparametric mod-
els, which have to spread out their probability mass over an infnite-dimensional
space, this can result in seemingly unreasonable behavior of the model. For ex-
ample, the Dirichlet process may be used as a prior in density estimation. Its
support consists of the discrete distributions, which means that if the data is
drawn from any smooth distribution, the true model is not in the support of the
prior (so Doobs theorem does not apply). As shown by Diaconis and Freedman
[5], the posterior will not necessarily concentrate in a region close to the true
model. Intuitively, the implication is that we cannot generally assume in non-
parametric models that the efect of the prior will eventually become negligible
if only we see enough data. However, this does not mean that nonparametric
Bayesian models are generally inconsistent: A large and growing literature in
mathematical statistics shows that consistency can be guaranteed by proper
choice of an adequate nonparametric model [6].
Recent results, notably by van der Vaart and Ghosal, apply modern meth-
ods of mathematical statistics to study the convergence properties of Bayesian
nonparametric models (see [6] for further references). Consistency has been es-
tablished for a number of models, including Gaussian processes and Dirichlet
process mixtures. A particularly interesting aspect of this line of work are re-
sults on convergence rates, which specify how rapidly the posterior concentrates
with growing sample size, depending on the complexity of the model and on how
much probability mass the prior places around the true solution. To make such
results quantitative requires a measure for the complexity of a Bayesian non-
parametric model. This is done by means of complexity measures developed in
9
 empirical process theory and statistical learning theory, such as metric entropies,
covering numbers and bracketing, some of which are well-known in theoretical
machine learning. Examples of such results include the consistency of Dirichlet
process mixture models for density estimation if both the target density and the
parametric mixture components are smooth, and a range of consistency results
for regression and density estimation with Gaussian processes. For all of these
results, convergence rates can be specifed as well (references are given in [6]).
A large class of infnite-dimensional models which do behave well even if the
true parameter is not in the domain of the prior is identifed in [7]. In this case,
the posterior will concentrate in the region of the prior support which is closest
to the true parameter in a Kullback-Leibler sense.
Inference
There are two aspects to inference in Bayesian nonparametric models: the ana-
lytic tractability of posteriors for the stochastic processes embedded in Bayesian
nonparametric models, and practical inference algorithms for the overall mod-
els. Bayesian nonparametric models typically include stochastic processes such
as the Gaussian process and the Dirichlet process. These processes have an
infnite number of dimensions thus nafve algorithmic approaches to computing
posteriors is generally infeasible. Fortunately, these processes typically have
analytically tractable posteriors, so all but fnitely many of the dimensions can
be analytically integrated out efciently. The remaining dimensions, along with
the parametric parts of the models, can then be handled by the usual infer-
ence techniques employed in parametric Bayesian modeling, including Markov
chain Monte Carlo, sequential Monte Carlo, variational inference, and message-
passing algorithms like expectation propagation. The precise choice of approx-
imations to use will depend on the specifc models under consideration, with
speed/accuracy trade-ofs between diferent techniques generally following those
for parametric models. In the following, we will given two examples to illus-
trate the above points, and discuss a few theoretical issues associated with the
analytic tractability of stochastic processes.
Examples
In Gaussian process regression, we model the relationship between an input x
and an output y using a function f, so that y f(x) + where is iid Gaussian
noise. Given a GP prior over f and a fnite training data set {(xi, yi)}n
i=1 we
wish to compute the posterior over f. Here we can use the weak representation
of f and note that {f(xi)}n
i=1 is simply a fnite-dimensional Gaussian with
mean and covariance given by the mean and covariance functions of the GP.
Inference for {f(xi)}n
i=1 is then straightforward. The approach can be thought
of equivalently as marginalizing out the whole function except its values on the
training inputs. Note that although we only have the posterior over {f(xi)}n
i=1,
this is sufcient to reconstruct the function evaluated at any other point x0 (say
10
 i=1 given {f(xi)}n
the test input), since f(x0) is Gaussian and independent of the training data
{(xi, yi)}n
i=1. In GP regression the posterior over {f(xi)}n
i=1
can be computed exactly. In GP classifcation or other regression settings with
nonlinear likelihood functions, the typical approach is to use sparse methods
based on variational approximations or expectation propagation; see GP entry
[f] for details.
Our second example involves Dirichlet process mixture models. Recall that
the DP induces a clustering structure on the data items.
If our training set
consists of n data items, since each item can only belong to one cluster, there
are at most n clusters represented in the training set. Even though the DP
mixture itself has an infnite number of potential clusters, all but fnitely many
of these are not associated with data, thus the associated variables need not
be explicitly represented at all. This can be understood either as marginalizing
out these variables, or as an implicit representation which can be made explicit
whenever required by sampling from the prior. This idea is applicable for DP
mixtures using both the Chinese restaurant process and the stick-breaking rep-
resentations. In the CRP representation, each data item xi is associated with a
cluster index zi, and each cluster k with a parameter f
k (these parameters can
be marginalized out if H is conjugate to F ), and these are the only latent vari-
ables that need be represented in memory. In the stick-breaking representation,
clusters are ordered by decreasing prior expected size, with cluster k associated
with a parameter f
k and a size k. Each data item is again associated with
a cluster index zi, and only the clusters up to K = max(z1, . . . , zn) need be
represented. All clusters with index > K need not be represented since their
posterior conditioning on {(xi, zi)}n
i=1 is just the prior.
On Bayes Equations and Conjugacy
It is worth noting that the posterior of a Bayesian model is, in abstract terms,
defned as the conditional distribution of the parameter given the data and
the hyperparameters, and this defnition does not require the existence of a
Bayes equation.
If a Bayes equation exists for the model, the posterior can
equivalently be defned as the left-hand side of the Bayes equation. However for
some stochastic processes, notably the DP on an uncountable space such as R,
it is not possible to defne a Bayes equation even though the posterior is still
a well-defned mathematical object. Technically speaking, existence of a Bayes
equation requires the family of all possible posteriors to be dominated by the
prior, but this is not the case for the DP. That posteriors of these stochastic
processes can be evaluated at all is solely due to the fact that they admit an
analytic representation.
The particular form of tractability exhibited by many stochastic processes in
the literature is that of a conjugate posterior, that is, the posterior belongs to the
same model family as the prior, and the posterior parameters can be computed
as a function of the prior hyperparameters and the observed data. For example,
the posterior of a DP(, G0) under observations 1, . . . , n is again a Dirichlet
process, DP( + n,
+n(G0 +(cid:80) Hi)). Similarly the posterior of a GP under
1
11
 observations of f(x1), . . . , f(xn) is still a GP. It is this conjugacy that allows
practical inference in the examples above. A Bayesian nonparametric model
is conjugate if and only if the elements of its weak distribution, i.e. its fnite-
dimensional marginals, have a conjugate structure as well [8]. In particular, this
characterizes a class of conjugate Bayesian nonparametric models whose weak
distributions consist of exponential family models. Note however that lack of
conjugacy do not imply intractable posteriors. An example is given by the
Pitman-Yor process, where the posterior is given by a sum of a fnite number of
atoms and a Pitman-Yor process independent from the atoms.
Future Directions
Since MCMC sampling algorithms for Dirichlet process mixtures became avail-
able in the 1990s and made latent variable models with nonparametric Bayesian
components applicable to practical problems, the development of Bayesian non-
parametrics has experienced explosive growth [9, 10]. Arguably, though, the
results available so far have only scratched the surface. The repertoire of avail-
able models is still mostly limited to using the Gaussian process, the Dirichlet
process, the beta process, and generalizations derived from those.
In princi-
ple, Bayesian nonparametric models may be defned on any infnite-dimensional
mathematical object of possible interest to machine learning and statistics. Pos-
sible examples are kernels, infnite graphs, special classes of functions (e.g. piece-
wise continuous or Sobolev functions), and permutations.
Aside from the obvious modeling questions, two major future directions are
to make Bayesian nonparametric methods available to a larger audience of re-
searchers and practitioners through the development of software packages, and
to understand and quantify the theoretical properties of available methods.
General-Purpose Software Package
There is currently signicant growth in the application of Bayesian nonparamet-
ric models across a variety of application domains both in machine learning and
in statistics. However signifcant hurdles still exist, especially the expense and
expertise needed to develop computer programs for inference in these complex
models. One future direction is thus the development of software packages that
can compile ecient inference algorithms automatically given model specica-
tions, thus allowing a much wider range of modeler to make use of these models.
Current developments include the R DPpackage1, the hierarchical Bayesian com-
piler2, adaptor grammars3, the MIT-Church project4, as well as eforts to add
Bayesian nonparametric models to the repertoire of current Bayesian modeling
1http://cran.r-project.org/web/packages/DPpackage
2http://www.cs.utah.edu/ hal/HBC
3http://www.cog.brown.edu/ mj/Software.htm
4http://projects.csail.mit.edu/church/wiki/Church
12
environments like OpenBugs5 and infer.NET6.
Statistical Properties of Models
Recent work in mathematical statistics provides some insight into the quan-
titative behavior of Bayesian nonparametric models (cf theory section). The
elegant, methodical approach underlying these results, which quantifes model
complexity by means of empirical process theory and then derives convergence
rates as a function of the complexity, should be applicable to a wide range of
models. So far, however, only results for Gaussian processes and Dirichlet pro-
cess mixtures have been proven, and it will be of great interest to establish
properties for other priors. Some models developed in machine learning, such
as the infnite HMM, may pose new challenges to theoretical methodology, since
their study will probably have to draw on both the theory of algorithms and
mathematical statistics. Once a wider range of results is available, they may in
turn serve to guide the development of new models, if it is possible to establish
how diferent methods of model construction afect the statistical properties of
the constructed model.