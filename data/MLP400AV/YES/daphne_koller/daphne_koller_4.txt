Abstract

Game theory provides a theoretical basis for defining ratio-
nal behavior in multi-agent scenarios. However, the compu-
tational complexity of finding equilibria in large games has
limited game theorys practical applications. In this paper,
we explore the application of structured probabilistic models
to multi-agent scenarios. We define multi-agent influence di-
agrams (MAIDs), which represent games in  a way that  allows
us to  take advantage of  independence relationships  among
variables. This representation allows us to define a notion
of strategic relevance: D is  strategically relevant to D if,  to
optimize the decision rule at  D, the decision maker needs to
know the decision rule at  D. We provide a sound and com-
plete graphical criterion for determining strategic relevance.
We then show how strategic relevance, which is  made explicit
by the  MAID structure,  can be exploited in  algorithms for
computing equilibria to obtain exponential savings in certain
classes of games.

Introduction

Game theory  (Fudenberg & Tirole  1991)  provides  a math-
ematical  framework for  determining  what behavior  is  ra-
tional  for  agents interacting  with each other in  a partially
observable  environment.  However, the  computational  com-
plexity  of  finding equilibria  in  games has  hindered the  ap-
plication  of  game theory to  real-world problems. Most algo-
rithms for  finding equilibria  operate on the  strategic  form of
a game, whose size is  typically exponential in the  size of the
game tree  (McKelvey & McLennan 1996).  Even algorithms
that  operate directly  on the  game tree  (Romanovskii 1962;
Koller,  Megiddo, &von Stengel 1994) are  not a solution,  as
for  games involving  many decisions,  the  game tree  can  be
prohibitively large.  As an extreme case,  if  the  game tree  is
symmetric (i.e.,  all  paths to  leaves have the  same sequence
of  decisions),  the number of  leaf  nodes is  exponential in  the
number of  decisions.

This problem of  state  space explosion also  occurs in  deci-
sion trees,  the  single-agent versions of game trees.  Influence
diagrams (IDs)  (Howard & Matheson 1984)  allow  single-
agent decision  problems to  be represented and solved with-
out this  exponential blow-up. Like Bayesian networks (Pearl

*Now at  Google Inc.

Copyright  2001, American Association for Artificial  Intelli-
gence (www.aaai.org). All rights reserved.

1988), influence  diagrams represent  the  conditional  inde-
pendencies  among variables.  These  formalisms  allow  us
to  take advantage of  the  structure  in  real-world problems to
solve them more efficiently.  In  this  paper, we present an ex-
tension of influence diagrams to  the multi-agent setting,  with
the  goal  of  providing compact representations  and more ef-
ficient  solution  algorithms for  game-theoretic problems.

Multi-agent  influence  diagrams (MAIDs) represent  deci-
sion problems involving multiple agents in  a structured  way.
We show that  MAIDs allow us  to  exploit  not  only the  depen-
dencies between the  probabilistic  attributes
in  the  domain
(as  in  Bayesian networks),  but  also  the  dependencies be-
tween strategic  variables.  We define  a  notion of  strategic
relevance: a decision variable  D strategically  relies  on an-
other  decision  variable  Dt  when, to  optimize the  decision
rule  in  D, the  decision-making agent needs to  know the  de-
cision  rule  in  Dt.  We provide a graph-based criterion,  which
we call  s-reachability,  for  strategic  relevance, and show that
it  is  sound and complete in  the  same sense that  d-separation
is  sound and complete for  probabilistic  dependence.  We
also  provide a polynomial time algorithm for  computing s-
reachability.

The notion of  strategic  relevance allows us to  define a data
structure  we call  the  relevance graph --  a  directed  graph
that  indicates  when one decision variable  in  the  MAID relies
on another.  We then  show that  this  data  structure  can be
exploited  to  provide more efficient  algorithms for  computing
equilibria:  it  allows a large game to be broken up into several
smaller games, whose equilibria  can be combined to  obtain
a global equilibrium.

Multi-Agent

Influence

Diagrams

(MAIDs)

We will  introduce  MAIDs using  a  simple  two-agent  sce-
nario:

Example I  Alice  is  considering building  a patio  behind her
house, and the  patio  would be more valuable to  her  if  she
could get  a  clear  view of  the  ocean.  Unfortunately,  there
is  a tree  in  her neighbor Bobs yard that  blocks her  view.
Being  somewhat unscrupulous,  Alice  considers  poisoning
Bob   s  tree,  which might cause it  to  become sick.  Bob cannot
tell  whether Alice has poisoned his tree,  but he can tell  if  the
tree is  getting sick,  and he has the option of  calling in a tree
doctor (at  some cost).  The attention of  a tree doctor reduces

45

the  chance that  the  tree  will  die  during the  coming winter.
Meanwhile, Alice  must make a  decision  about building  her
patio  before the  weather gets  too cold.  When she makes this
decision,  she knows whether a tree  doctor has come, but she
cannot observe the  health  of  the  tree  directly.  A MAID for
this  scenario is  shown in  Figure 1.

Figure  l:  MAID for  the  Tree Killer  example. Alices  deci-
sion and utility  variables are in  dark gray and Bobs in  light
gray.

To define a MAID more formally, we begin with a set  .A of
agents.  The world in  which the  agents act  is  represented by
the  set  C of chance variables, and a set  79a of decision vari-
ables  for  each agent  a E A. Chance variables  correspond
to  moves by nature,  and are  represented  in  the  diagram as
ovals.  The decision variables for  agent a are  variables whose
values a gets to  choose, and are  represented as  rectangles in
the  diagram.  We use  D to  denote Ua6at 79a,  and 1)  to  de-
note C tO 79. Each variable  V E 12 has a finite  set  dom(V) of
possible values,  called its  domain. The agents utility  func-
tions  are  specified  using utility  variables: For each agent
a 6 .A,  we have a set/./a  of  utility  variables,  represented
as  diamonds in  the  diagram,  that  take  on real  numbers as
values.

A MAID defines  a directed  acyclic  graph with its  vari-
ables as  the  nodes, where each variable  X is  associated with
a set  of  parents  Pa(X) C 12.  Note that  utility  variables
cannot be parents of  other variables.  For each chance vari-
able  X 6 C,  the  MAID specifies  a  conditional  probability
distribution  (CPD): a distribution  Pr(X I  pa) for  each in-
stantiation  pa of  Pa(X). For a  decision  variable  D 6  79a,
Pa(D) is  the  set  of  variables  whose values agent  a  knows
when he  chooses  a  value  for  D.  Thus,  the  choice  agent
a makes for  D can be contingent  only  on these  variables.
The value of a utility  variable U is  a deterministic function
of  the  values of  Pa(U); we use  U(pa) to  denote the  util-
ity  value  for  node U when Pa(U) = pa.  For  each  utility
variable  U E H, f  specifies,  for  each instantiation  pa of
Pa(U), the  corresponding utility  value  f[U](pa),  which
abbreviate using U(pa). The total  utility  that  an agent a de-
rives from an instantiation  of 12 is  the  sum of  the  utilities
specified by the utility  variables in Ha for this  instantiation.
Thus, by breaking an agents  utility  function  into  several

46

variables,  we are  simply defining  an additive  decomposition
of  the  agents  utility
function  (Howard & Matheson 1984;
Keeney & Raiffa  1976).

The behavior of  the  agents is  defined by a set  of  decision

rules.
Definition  1 A decision  rule  for  a decision variable  D is  a
function that maps each instantiation  pa of  Pa( D )  to  a prob-
ability  distribution  over dom( D ).  An assignment of  decision
rules to  every decision D E 79a for a particular agent a E .A
is called a strategy.
An assignment a of  decision  rules  to  every decision  D 6 79
is  called a strategy profile.  A partial  strategy profile  ac is
an assignment of  decision rules  to  a subset E of  79. We will
also  use (re  to  denote the restriction  of  a to  E, and cr-E to
denote the restriction  of a to variables not in  E.

Note that  a  decision  rule  has  exactly  the  same form as  a
CPD. Thus, if  we have a MAID .At,  then  a  partial  strategy
profile  a that  assigns decision rules  to  a set  E of  decision
variables  induces a  new MAID .A4 [tr]  where the  elements
of  E have  become chance variables.  That  is,  each  D E g
corresponds to a chance variable in  .A4 [or]  with tr(D) as  its
CPD. When a assigns a  decision rule  to  every decision  vari-
able  in  .A4,  the  induced MAID is  simply  a  BN: it  has  no
more decision variables.  This BN defines a joint  probability
distribution  P~ over all  the  variables in .A4.

With this  probability  distribution,  we can now write  an
that  agent a expects to receive in  a

equation for the  utility
MAID

.A4 if  the agents play a given strategy profile  tr:

EUa  (a)  =  ~  ~  U(pa)P~-M(pa)

(1)

UEL/. pa6 x Pa(U)

where x  Pa(U) is  the  joint  domain of  Pa(U).

In  the  game-theoretic framework, we typically  consider a
strategy profile to  represent rational behavior if  it  is  a Nash
equilibrium (Nash 1950). Intuitively,  a strategy profile  is
Nash equilibrium if  no agent has an incentive to deviate from
the  strategy  specified for  him by the  profile,  as long as  the
other agents do not deviate from their  specified strategies.
Definition 2 A strategy  profile  cr  is  a Nash equilibrium for
a MAID .A4 if  for  all  agents a E ,4 and all  strategies  a "
Ella (o)  EUa (( 0_9 o")).
~  "Da

--

MAIDs  and  Games

A MAID provides  a  compact representation  of  a  scenario
that  can also  be represented  as  a game in  strategic  or  ex-
tensive  form. In  this  section,  we discuss  how to  convert  a
MAID into  an  extensive-form  game.  We also  show how,
once we have found an equilibrium  strategy  profile  for  a
MAID, we can convert it  into  a behavior strategy  profile  for
the  extensive  form game. The word "node" in  this  section
refers  solely to a node in the  tree,  as  distinguished from the
nodes in  the  MAID.

We use  a  straightforward  extension  of  a  construction
of  (Pearl  1988) for  converting an influence  diagram into
decision tree.  The basic idea is  to  construct a tree with splits
for  decision  and chance nodes  in  the  MAID. We need  to
split  on a chance variable  before its  value is  observed by

some decision  node;  we need only  split  on  chance vari-
ables  that  are  observed at  some point in  the  process.  More
precisely,  the  set  of  variables  included in  our game tree  is
G = 7:)  U UD~V Pa(D).

We begin by defining  a total  ordering -~  over G that  is
consistent  with the  topological  order of  the  MAID: if  there
is  a  directed  path  from X to  Y, then  X -g  Y. Our tree  7"
is  a symmetric tree,  with each path  containing splits  over
all  the  variables in  G in  the  order defined by --~.  Each node
is  labeled with a partial  instantiation  inst  (N) of  G, in  the
obvious  way. For  each  agent  a,  the  nodes corresponding
to  variables  D E D, are  decision  nodes for  a;  the  other
nodes are  all  chance nodes. To define the  information sets,
consider  two decision  nodes M and M~ that  correspond to  a
variable  D. We place  M and M into  the  same information
set  if  and only if  inst  (M) and inst  (M) assign  the  same
values  to  Pa(D).

To determine the  probabilities  for  the  chance nodes, we
must do probabilistic  inference.  It  turns  out  that  we can
choose an arbitrary  fully  mixed strategy  profile  a  for  our
MAID .hi  (one  where no  decision  has  probability  zero),
and do inference  in  the  BN 34 [a]  induced by this  strat-
egy profile.  Consider  a  chance node N corresponding  to
a  chance  variable  C.  For  each  value  e  E dom(C),  let
Nc be the  child  of  N corresponding  to  the  choice  C = c.
Then we define  the  probability  of  going from N to  Nc as
P~a(inst(Nc) ]  inst(N)).  Note that  if  we split  on a deci-
sion variable  D before G, then the  decision rule  aD does not
affect  this  computation because inst  (N) includes values for
D and all  its  parents.  If  we split  on D after  C, then D can-
not  be an ancestor  of  C in  the  MAID, and inst  (N)  cannot
specify evidence on D or  any of  its  descendants. Therefore,
aD cannot affect  the  computation. Hence, the  probabilities
of  the  chance nodes are  well-defined.

We define the  payoffs at  the leaves by computing a distri-
bution over the  parents of the  utility  nodes, given an instan-
tiation  of G. For a leaf  N, the payoff for agent a is:

~  U(pa)P~

(pa

l

inst(N))

UED/,, paE x  Pa(U)

The mapping between MAIDs and trees  also  induces  an
obvious mapping between strategy  profiles  in  the  different
representations.  A MAID strategy  profile  specifies  a proba-
bility  distribution  over dom(D) for  each pair  (D, pa),  where
pa is  an instantiation  of  Pa(D). The information  sets  in
the  game tree  correspond one-to-one with these pairs,  and a
behavior strategy  in  the  game tree  is  a mapping from infor-
mation sets  to  probability distributions.  Clearly the two are
equivalent.

Based on this  construction,  we can now state  the  follow-

ing  equivalence lemma:
Lemma 1  Let  34  be  a  MAID and  7"  be its  corresponding
game tree.  Then for  any strategy  profile  a,  the  payoff vector
for a in  34 is  the  same as the  payoff vector for  a in T.

The number of  nodes in  7"  is  exponential  in  the  number
of  decision variables,  and in  the  number of  chance variables
that  are  observed during the  course of  the  game. While this
blowup is  unavoidable in a tree  representation, it  can be quite

47

significant  in  certain  games. Thus, a MAID can be exponen-
tially  smaller than the extensive game it  corresponds to.
Example 2  Suppose  a  road is  being  built
from  north  to
south  through undeveloped land,  and n  agents  have  pur-
chased plots  of  land along the  road.  As the  road reaches
each agents plot,  the  agent needs to  choose what to  build
on his  land.  His utility  depends on what he builds,  on some
private information about the  suitability  of  his  land for  var-
ious purposes, and on what is  built  north,  south,  and across
the  road from  his  land.  The agent  can observe  what has
already been built  immediately to  the  north of  his  land (on
both sides of  the  road), but he cannot observe further north;
nor can he observe what will  be built  across from his  land
or south of it.

The  MAID representation

is  very  compact.  There  are
n chance nodes,  corresponding to  the  private  information
about each agents land,  and n decision  variables.  Each de-
cision variable has at  most three parents: the agents private
inform, ation,  and the  two decisions regarding the  two plots
to  the  north of  the  agents land.  Thus, the  size  of  the  MAID
is  linear  in  n.  Conversely, any game tree  for  this  situation
must split  on each of  the  n chance nodes and each of  the  n
decisions, leading to  a representation that  is  exponential in
n.

A MAID representation

is  not  always more compact.  If
the  game tree  is  naturally  asymmetric, a  naive MAID repre-
sentation can be exponentially larger  than the tree.  We return
to  this  problem in  Section .

Strategic  Relevance

To take  advantage of  the  independence structure  in  a MAID,
we would like  to  find  a global equilibrium through a series
of  relatively simple local computations. The difficulty  is  that
in  order  to  determine the  optimal decision  rule  for  a sin-
gle  decision  variable,  we usually  need to  know the  decision
rules  for  some other variables.  In  Example 1,  when Alice is
deciding whether to  poison the  tree,  she  needs to  compare
the  expected utilities  of  her two alternatives.  However, the
probability  of  the  tree  dying depends on the  probability  of
Bob calling a tree  doctor if  he observes that  the tree  is  sick.
Thus, we need to  know the  decision  rule  for  CallTreeDoctor
to  determine the  optimal decision  rule  for  PoisonTree. In
such situations,  we will  say that  PoisonTree (strategically)
relies  on CallTreeDoctor, or  that  CallTreeDoctor is  rel-
evant  to  PoisonTree.  On the  other  hand,  CallTreeDoctor
does  not  rely  on PoisonTree. Bob gets  to  observe  whether
the  tree  is  sick,  and TreeDead is  conditionally  indepen-
dent of  PoisonTree given TreeSick, so the  decision  rule  for
PoisonTree is  not relevant  to Bobs decision.

We will  now formalize this  intuitive  discussion of  strate-

gic  relevance.  Suppose we have a strategy  profile,  and we
would like  to find  a decision rule  for a single decision vari-
able  D E 79~ that  maximizes as  expected utility,  assuming
the rest  of the strategy profile remains fixed.
Definition  3 Let ~ be a decision  rule  for  a variable  D in  a
MAID 34. Then ~ is  optimal for a strategy profile  a if,  in  the
induced MAID Ad [a-D] (where the  only  remaining decision
node is  D), the strategy profile  (~)  is  a Nash equilibrium.

Given this  definition of  optimality for a strategy profile,

we can now define strategic  relevance.
Definition 4 A decision variable D strategically  relies  on a
decision  variable  D in  a MAID 34 if  there are  two strategy
profiles  a and a~ such that  a and tr ~ differ  only at  D~,  but
~.
some decision rule for  D is  optimal for  cr  and not for a

If  D does not rely  on D~,  then a  decision rule  for  D that
is  optimal for  a  strategy  profile  a is  also  optimal for  any
.
strategy profile a  that  differs  from a only at  D

It  turns out that  strategic  relevance corresponds to  a sim-
ple  graph-theoretic  property in  a MAID. To begin with,  sup-
pose we have a strategy  profile  a for  a MAID 34,  and con-
sider  finding  an optimal decision  rule  for  D in  34 [a-o],
where D is  the  only decision  node. The optimality  of  the
decision rule  at  D depends only on the  utility  nodes/1o that
are  descendants of  D in  the  MAID. The other  utility  nodes
are  irrelevant,  because the  decision  at  D cannot influence
them. Now, based on the  independence properties  implied
by the  graph structure,  we can prove the  following lemma:

Lemma 2  Let  6 be a  decision  rule  for  a decision  variable
D E 79a in  a MAID 34,  and let  a be a strategy  profile  for
34. Then ~ is  optimal for  a if  and only if  for  every instanti-
ation  paD of  Pa(D) where pM (PaD) > O, the  probability
distribution ~( D [  pa) is:

argmax

Z

p*

Z

UEUD pa U  E  x  Pa(  U)

U(Pau)"

Z  P*(d)pM(Pau

dpaD)

(2)

dEdom( D

So to be optimal for a strategy profile  a,  a decision rule

just  has to  satisfy  Equation 2. If  the  expression being maxi-
mized in  Equation 2 is  independent of  the  decision rule  that
a  assigns  to  another decision  variable  D~,  then  D does not
rely  on D. Thus, we would like  a graphical criterion  for  de-
tecting  when this  expression is  independent of  the  decision
rule  for  some node. The appropriate formal notion turns  out
to  be that  of a requisite probability node.

~

Definition  5  Let  2(  and y be sets  of  variables  in  the  di-
rected  acyclic  graph defined by a BN or MAID. Then a node
Z is  a requisite  probability  node for  the  query P(X I  Y)
there  exist  two functions  P1 and Pz that  assign CPDs to  all
the  nodes in  the  graph, such that P1 and P2 differ  only at Z,
butPl(XlY)  P2(X I  Y)
Intuitively,  the decision rule at  D~ is  only relevant to D if  D
(viewed as  a chance node) is  a relevant  probability  node for
P(UD I  D,  Pa(D)).

Geiger et  al.  (1990) provide a graphical criterion  for  test-
ing whether a node Z is  a requisite  probability  node for  a
query  P(X I  Y).  We add  to  Z  a  new "dummy" parent  2
whose values correspond to  CPDs for  Z, selected  from some
set  of  possible CPDs. Then Z is  a requisite  probability  node
for  P(X I  Y) if  and only if  Z can influence X given y.  This
condition can easily  be checked using the  standard notion of
active  paths in  the  BN. Thus, Z is  a  requisite  probability

48

node for  P(X I  3;)  if  and only if  there  would be an active
path from a new parent  of  Z to  X, given y.

Based on this  analysis,  we can define  s-reachability,  a
graphical  criterion  for  detecting  strategic  relevance.  Note
that  unlike d-separation in  Bayesian networks, s-reachability
is  not necessarily a symmetric relation.
Definition  6 A node D~ is  s-reachable  from a  node D in  a
MAID if  there  is  some utility  node U E UD such that  if  a
new parent  D~ were added to  D~,  there  would be an active
path  from  D~ to  Pa(U) given  Pa(D) U {D}.

As we now show, s-reachability

is  sound and complete
for strategic  relevance in the  same sense that  d-separation is
sound and complete for  independence in  Bayesian networks.
Theorem 1  (Soundness)  If  D and  D~ are  two  decision
nodes  in  a  MAID and D is  not  s-reachable  from D in  the
MAID, then  D does not  rely  on D.
Theorem 2  (Completeness) If  a  node D is  s-reachable
from  a  node D in  a  MAID, then  there  is  some MAID with
~.
the  same graph structure  in  which D relies  on D

As for  BNs, the  completeness result  is  somewhat weaker:
s-reachability  does not  imply relevance  in  every MAID. We
can choose the  probabilities  and utilities
in  the  MAID in
such a way that  the  influence  of  one decision  rule  on an-
other does not manifest itself.  However, s-reachability  is  the
most precise graphical criterion  we can use" it  will  not iden-
tify  a strategic relevance unless that  relevance actually exists
in  some MAID that  has  the  given graph structure.  Our proof
of  this  theorem involves constructing an appropriate assign-
ment of  CPDs and utility
functions  to  the  MAID, and de-
pends on the  completeness proof in  (Geiger,  Verma, & Pearl
1990).

Since strategic  relevance is  a binary relation,  we can rep-
resent  it  as  a directed  graph.  As we show below, this  graph
turns  out to be extremely useful.
Definition  7 The relevance  graph for  a  MAID 34 is  a  graph
whose nodes are  the  decision  nodes of.M,  and whose edges
are the  pairs of  nodes (D,  D~) such that  D relies  on D

~.

To construct

the  graph  for  a  given  MAID, we need  to
~
determine,  for  each decision  node D, the  set  of  nodes D
that  are  s-reachable  from D. Using an algorithm  such  as
Shachters Bayes-Ball (Shachter 1998), we can find  this  set
for  any given D in  time linear  in  the  number of  nodes in  the
MAID. By repeating  the  algorithm  for  each  D, we can  de-
rive  the  relevance graph in  time quadratic  in  the  number of
MAID nodes.

It  is  interesting  to consider the relevance graphs of  various
simple games. In  the  examples in  Figure 2,  the  decision node
 D belongs  to  agent a,  and D  belongs  to  agent  b.  Example
(a)  represents a perfect-information game. Since agent b can
observe the  value of  D, he does not  need to  know the  deci-
~
sion rule  for  D in  order  to  evaluate  his  options.  Thus, D
does not  rely  on D. On the  other  hand, agent a  cannot ob-
serve  D~ when she  makes decision  D, and D~ is  relevant  to
as  utility,  so D relies  on Dq Example (b)  represents a game
where the  agents do not  have perfect  information:  agent b
cannot  observe  D when making decision  D.  However, the

The algorithm is  a generalization of  existing backward in-
duction algorithms for decision trees  and perfect  information
games (Zermelo 1913) and for  influence  diagrams (Jensen,
Jensen,  & Dittmer 1994). The basic  idea  is  as  follows:  in
order  to  optimize the  decision  rule  for  D, we need to  know
the  decision rule  for  all  decisions D~ that  are  relevant  for
D. For example, the  relevance graph for  the  Troo Killor  ex-
ample (Figure  3(a))  shows that  to  optimize PoisonTree, we
must first  decide on the  decision  rules  for  BuildPatio and
TreeDoctor.  However, we can  optimize  TreeDoctor with-
out  knowing the  decision  rules  for  either  of  the  other  de-
cision  variables.  Having decided on the  decision  rule  for
TreeDoctor, we can  now optimize  BuildPatio  and then  fi-
nally  PoisonTree.

(a)

(b)

Figure 3:  Relevance graphs for  (a)  the  Tree Killor  example;
(b)  the  Road example with  n  =

In this  simple case,  the relevance graph is  acyclic,  allow-
ing us  to  process the  variables  one at  a  time.  In  general,
however, we might have cycles in  the  relevance graph; e.g.,
Figure 3(b) contains  the  relevance graph for  the  Road exam-
ple  with n = 6.  Here, we cannot sequentially  optimize in-
dividual decisions, because at  various points in  the  process,
there  is  no decision  node that  only relies  on decisions  for
which we have already  obtained  a decision  rule.  However,
we can perform a  backward induction  process  over subsets
of  nodes:
Definition  8  A set  S  of  nodes  in  a  directed  graph is  a
strongly  connected component (SCC) if  for  every  pair
nodes  D ~  D E S,  there  exists  a  directed  path  from  D
to  D~.  A maximal SCC is  an SCC that  is  not  a strict  subset
of  any other  SCC.

The maximal SCCs are  outlined  in  Figure  3(b).  We can
find  the  maximal SCCs of  a graph in  linear  time,  construct-
ing  a  component graph whose nodes are  the  maximal SCCs
of  the  relevance  graph.  There is  an edge from component
C to  component C~ in  the  component graph if  and only  if
there  is  an edge from some element of  C to  some element of
C~ in  the  relevance  graph.  The component graph is  always
acyclic  (Cormen, Leiserson,  & Rivest  1990).  Thus, we can
define  an  ordering  C1,...
,Cm over  the  maximal SCCs of
the  relevance  graph,  such that  whenever i  < j,  no element
of  Cj relies  on any element of Ci.

(a)

(b)

co)

(d)

(e)

Figure  2:  Five  simple  MAIDs (top),  and their  relevance
graphs (bottom).  A two-color diamond represents  a  pair
utility  nodes, one for  each agent,  with the  same parents.

information is  "perfect  enough": the  utility  for  b does not
depend on D directly,  but only on the  chance node, which b
can observe.  Hence D~ does not rely  on D.

Examples (c)  and (d)  represent scenarios where the  agents
move simultaneously,  and thus  neither  can  observe  the
others move. In (c),  each agents utility  node is  influenced
by both  decisions,  so  D relies  on D~ and D~ relies  on D.
Thus, the relevance graph is  cyclic.  In  (d),  however, the  rel-
evance graph is  acyclic despite  the fact  that  the agents move
simultaneously. The difference here is  that  agent a no longer
cares what agent b does, because her utility  is  not influenced
by bs  decision.  In  graphical terms, there  is  no active  path
from D~ to  as  utility  node given D.
One might conclude that  a decision  node D~ never relies
on  a  decision  node D when D is  observed  by D~,  but  the
situation  is  more subtle.  Consider example (e),  which rep-
resents  a  simple card  game: agent a  observes a  card,  and
decides whether to  bet  (D); agent b observes only agent as
bet,  and decides whether to  bet (D~); the  utility  of  both de-
pends on their  bets  and the  value of  the  card.  Even though
agent b observes the  actual  decision  in  D, he needs to  know
the  decision  rule  for  D in  order  to  know what the  value of
D tells  him about the  chance node.  Thus, D~ relies  on D;
indeed,  when D is  observed, there  is  an active  path  from D
that  runs through the  chance node to  the  utility  node.

Computing  Equilibria

using  Divide  &

Conquer

The computation of  a  Nash equilibrium  for  a  game is  ar-
guably the  key computational task  in  game theory.  In  this
section,  we show how the  structure  of  the  MAID can be ex-
ploited to provide substantially faster  algorithms for finding
equilibria.

The key insight  behind our  algorithm is  the  use  of  the
relevance graph to  break up the  task  of  finding  an equilib-
rium into  a  series  of  subtasks,  each  over a  much smaller
game. Since  algorithms  for  finding  equilibria
in  general
games have complexity that  is  superlinear
in  the  number
of  levels  in  the  game tree,  breaking the  game into  smaller
games will  significantly  improve the  complexity of  finding
a global equilibrium.

49

Based on this  definition,  we can now provide a divide-
in

and-conquer algorithm  for  computing Nash equilibria
MAIDs.
1 Let ~r  be an arbitrary fully  mixed strategy profile
2
3

Let 7-  be a partial  strategy profile for C(m-0 that is

Fori  =  0  throughm-  1:

Nash equilibrium in .halL/cri--c(m-i)
J

r

TM
Let  cr

4
5 Output ~rr~  as  an equilibrium of.M

=  (O"  (70n_i))

7-)

/

The algorithm iterates  backwards over the  SCCs, finding

an equilibrium  strategy  profile  for  each SCC in  the  MAID
induced by the  previously selected  decision rules  (with  ar-
bitrary  decision rules for  some decisions that  are  not rele-
vant for  this  SCC). Finding the  equilibrium in  this  induced
MAID requires  the  use of  a subroutine for  finding  equilib-
ria  in  games. We simply  convert  the  induced MAID into  a
game tree,  as  described in  Section, and use a standard game-
solving  algorithm  (McKelvey & McLennan 1996).

If  the  relevance graph is  acyclic,  each SCC consists  of  a
single node, so each decision is  optimized by itself.  In  this
case,  the  algorithm is  very similar  to  the  standard backward
induction  algorithm in  perfect  information games. However,
we obtain acyclic  relevance graphs in  a wider range of  situ-
ations.  For example, the  relevance graph of  the  Treo Killer
example is  acyclic,  although the  game does not have perfect
information.

The proof that  this  algorithm is  correct  requires  a se-
quence of  lemmas. So far  we have considered strategic  rel-
evance only as  a  binary relation  between nodes. Suppose 61
is  a decision rule for D1 that is  optimal for a strategy profile
a,  and D1 relies  on neither  D2 nor  D3. Then changing ~z at
either  D2 or  D3 does not affect  the  optimality of  6.  But one
might worry that  changing (r  at  both D2 and D3 might cause
6 to  lose  optimality.  The following lemma shows that  such
a  thing  cannot happen: if  we have a  set  of  decisions  none
of  which are individually relevant, then the  entire  set  is  not
relevant.
Lemma 3 Let ~r  be a strategy  profile,  D be a decbion node,
and 6 be a decision rule for D that is  optimal for ~r. If  ~rr  is
another strategy profile such that cr( D) --  or (  D) whenever
D relies  on Dr,  then 6 is  also optimal for ~r

r.

t,

Proof: We proceed by induction  on the  number k  of  nodes
where ~r and cr~ differ.  For the base case, k = 0 and cr = cr
so it  is  obvious that 6 is  also optimal for crr.  Now as an induc-
r
tive  hypothesis,  assume the  lemma holds whenever ~z and a
differ  on exactly  k nodes. Then suppose cr  and ar  differ  on
k + 1 nodes. Select any node D such that  ~r(D) ~ cr(D).
By the  conditions of  the  lemma, this  means D does not  rely
on Dr.  Now construct a strategy  profile  6.  that  agrees with
~r on all  nodes but Dr,  and agrees with ~rr  on Dr.  Because ~r
and # differ  only on D, 6 must also  be optimal for  6.;  oth-
erwise D would rely  on Dr.  But 6" and crr  differ  on only k
nodes, so by the inductive hypothesis, 6 is  optimal for ar  as
well.

Thus, we can change the  decision  rules  for  a whole set  of
nodes that  are  irrelevant  for  D without affecting the optimal-

50

ity  of  a decision  rule  for  D. But in  our  divide and conquer
algorithm,  we are  concerned with the  optimality  of  a  par-
tial  strategy profile 7-  for an entire  set  C of decision nodes.
Clearly,  if  none of  the  decision  nodes in  C rely  on a node
D~ ~ C,  then  changing the  decision  rule  for  D would not
give .any agent an incentive to  deviate at  a single  decision
node in  C. But might an agent  want to  deviate  at  several
decision  nodes simultaneously?

We can answer this  question in  the  negative if  we make the
standard assumption of  perfect  recall:  agents never forget
their  previous actions  or  observations.  More formally:

Definition  9  An agent a has perfect  recall  with  respect  to
a  total  order -4  over 79a if  for  all  D)Dr  E 79,,  D --4  D
implies

that  D E Pa(D)  and  Pa(D) C Pa(D).

r

Note that  if  D and its  parents are parents of D~,  then there
cannot be an active  path  from a  new parent/3  of  D to  any
descendant  of  D,  given  Dr  and Pa(Dr).  Thus,  by  Theo-
rem 1,  Dr  does not  rely  on D. This observation leads to  the
following  lemma:

Lemma 4  If  an agent  has perfect  recall  with  respect  to  a
total  order -~,  and 19 -.< D~, then D~ does not rely on D.

We can now show that  if  a single  agent  has no incentive
to  deviate at  a single  decision node, then he has no incentive
to  deviate at  any group of nodes.

Lemma 5  Let  .A4  be  a  MAID with  a  single  agent  a,  who
has perfect recall  Let ~r be a strategy for a in .hd such that
for  every D E 79, ~r(D) is  optimal for  cr.  Then crb a  Nash
equillbrium in .h4.1

Proof:  To show that  cr  is  a  Nash equilibrium,  we must
show that for all  other strategies ~#:

We proceed  by  induction  on the  number k  of  decisions
where a  and ar  differ.
If  k  = 0,  then  cr  = a,  so  obvi-
ously  EUa (~r)  = EU~ (crY).  As an inductive  hypothesis,
suppose that  whenever ~rr  differs  from cr  on k or  fewer nodes,
EUo _>

Now suppose (7  differs  from er  on k  + 1 nodes.  Since
has perfect recall,  Lemma 4 tells  us there is  a total  order -.<
over  79 such  that  whenever D -4  Dr,  D does  not  rely  on
D. Let D* be the  last  decision  in  this  ordering  such that
(rr(D*)  7~ (r(D*).  That is,  if  crr(D)    ~r(D),  then
D = D* or  D -4  D*. In  either  case,  D* does  not  rely  on
D.  Let  6  =  a(D),  and  6  = at(D).  We are  given  that
is  optimal for  cr.  But since ar  differs  from cr  only at  nodes
that  D* does  not  rely  on,  we know by Lemma 3  that  6  is
also optimal for  ~rr.  In  particular,  6 yields at  least  as much
expected utility  as  6r  in .M  [0"%.].  So:

EUa (C/_D,,6)  >_ EUa (a)

tThe notion of  Nash equilibrium in the single agent case re-
duces to the simpler notion of the agent acting optimally under
uncertainty.

But the strategy (fit_D.,  6)  differs  from a at  only k decision
nodes, so by the  inductive hypothesis:

EUa ((7)  > EUa (a_o.,  6)

So by transitivity:

EUa (a)  _> EUa t)

Given this  result,  we can show that  changing the  decision
rules  for  nodes that  are  not relevant  to  any node in  a set  C
does not affect the optimality of a partial  strategy profile over
C.
Lemma 6 Let  a be a strategy  profile  for  a MAID .All  where
every agent has perfect recall,  and let  r be a partial  strategy
profile  for  a  set  8 of  decision  nodes in  .M.  Suppose T is
a  Nash equilibrium in  .M [a-c],  and E is  a set  of  decision
nodes in  M (disjoint  from C) such that  no node in  C relies
on any node in  8. Then if  a  is  another strategy profile  that
differs  from a  only  on 8,  T is  also  a Nash equilibrium  in
M [a~_c].

Proof: For each agent a,  let  Ca = C fq 79a. If  Ca # 0,  let  Ta
be the restriction of r  to Ca, and 7-_a be the restriction of T to
t7  \  Ca. By the definition of a Nash equilibrium, it  suffices to
show that  in  the  induced MAID .M [a~_c], no agent a has  an
incentive to  deviate from ra  to another strategy ra,  assuming
the  other  agents adhere to  T.  In  other  words, we must show
that  Ta is  a Nash equilibrium in the  induced single-agent in-
fluence diagram .M [al_c,  T-a].

~

Consider  an  arbitrary  decision  D E Ca.  We are  given
that  r  is  an equilibrium in  .M [a-c],  so the  decision  rule
ra(D) is  optimal  for  (a-c,r).  We are  also  given  that  (r
differs  from a only at  nodes that  are  irrelevant  for  D. So
by Lemma 3,  ~-a(D) is  also  optimal  for  (a~_c,T).  This  is
equivalent to  saying that  Ta(D) is  optimal for  the  strategy
Ta in  .M [a~_c,~-_a]. Since every Ta(D) is  optimal for  Ta,
Lemma 5 implies that  Ta is  a Nash equilibrium.


Recall that  our algorithm produces a strategy  profile  aTM.

Lemma 6 implies that  for  each SCC C in  the  relevance graph,
the  partial  strategy profile  that  am specifies  for C is  a Nash
equilibrium in  .M Jam_c]. Thus, no agent has an incentive to
deviate  from am on  the  nodes  within  any single  SCC. We
now prove a  lemma that  generalizes  Lemma 5,  showing that
in  fact,  no agent has an incentive to  deviate from am on any
group of  nodes.
Lemma 7  Let  .h4  be a MAID where every  agent  has perfect
recall,  and let  C1,...  ,  Cm be sets  of  decision nodes in  .M
such that  whenever i  < j,  no element of  Cd  relies  on any
element of  Ci. lf  a is  a strategy profile  for jt4  such that for
each i  E [1,  m], ac, is  a Nash equilibrium in  .AA [a-c,],  then
a is  a Nash equilibrium for  M.

Proof:  We must show that  for  any agent  a and any alter-
native  strategy  tr~  for  I)a,  EUa (a)  _> EUa (a-a,  a~).
proceed by induction on the  number of  sets  Ci where aa and
  differ.  The base case is  where they differ  on zero sets;
O"a
then  aa  = aa
  and EUa (a)  EUa (a,  a~a).  As an inductive

=

51

hypothesis,  suppose that  whenever a
a
or  fewer sets,  EUa (a)  _> EUa (a-a,  a).

  differs  from aa on k

Now suppose  aa

  differs  from aa on k + 1  sets.  For each
set Ci, let  Ci,a = CifqT)a. Let Cj be the last  set in the ordering
where the partial  strategy profiles aa (Cj,a) and er~ (Cj,a) are
different.  Let  "ca = aa(Cj,a),  and r~  = a~(Cj,a).  Since
a(Cj)  is  an equilibrium  in  .M [a_cj],  we know that  ra  is
an equilibrium  in  .M [a-a,  (aa)-cj].  But a~ differs  from
aa only  on sets  Ci where i  < j,  and no node in  Cj relies
on any node in  these  sets.  So by Lemma 6,  "Ca is  also  an
equilibrium in  .M [a-a,  (  a)-Cj].  In particular,  ra yields  at
least  as  much expected utility  as  q-~ in  .M [a-a,  (a~)-c~].
So:

0"

EUx~ (a-a,  (a~)-c~,  ~-a)  > EUA4 (a-a,

But ((aa)_SOOj, dif fers fro m aa on only k s ets. So  by
the inductive hypothesis:

EUM (a)  > EUM (a-a,

(  a)-Scc~,

Ol

So by transitivity:

EUA4 (a)  > EU~ (a-a,  cr~).

Using this  lemma, we can finally  prove the  correctness  of

our algorithm.
Theorem 3  If  .M is  a  MAID where every  agent  has  perfect
recall,  then the  strategy profile  crm derived by the algorithm
above is  a Nash equilibrium for  .&t.

(7i

Proof:  Consider  any  SCC C(m-i),  where < i  < m.By
construction,  ai+~ assigns to  C(m-i) a partial  strategy  pro-
file  T that  is  a Nash equilibrium in  A// [  _c(~_o]. Because
(m -  i)  decreases as  i  increases  from one iteration  of  the
algorithm  to  the  next,  am differs  from ai  only  on SCCs
Cj where j  < (m -  i).  Because the  ordering  of  SCCs
a  topological  ordering  in  the  relevance  graph,  no node in
C(m-i) relies  on any node in  Cj where j  < (m -  i).  There-
fore  am agrees with ai  on all  nodes that  are relevant  for  any
node in  C(m-i).  So by Lemma 6,  T is  a Nash equilibrium in
.M [  ._c(m_,)].  Since this  is  true  for  every SCC, Lemma 7
implies  that  am is  a  Nash equilibrium  in  .M.


o-m

Experimental  Results

To demonstrate the  potential  savings resulting  from our al-
gorithm,  we tried  it  on the  Road example. As shown in  the
relevance graph in  Figure 3(b),  the  decision for  a given plot
relies  on the  decisions about the  plot across from it  and the
plot  directly  to  the  south.  However, it  does not rely  on the
decision about the land directly  north of  it,  because this  de-
cision  is  observed. None of  the  other  decisions affect  this
agents utility  directly.  The SCCs in the  relevance graph all
have size 2:  they correspond to  pairs of  decisions about plots
that  are across from each other.

Even for  small  values  of  n,  it  is  infeasible

to  solve
the  Road example with  standard  game-solving algorithms.

Suppose the  chance and decision  variables  each have three
possible values,  corresponding to  three  types of  buildings.
Then the  game tree  corresponding  to  the  Road MAID has
32n terminal nodes. Since each agent (except the  first
two)
can observe three  ternary  variables,  he has 27 information
sets.  So the  number of  possible pure (deterministic)  strate-
gies  for  each agent is  32r,  and the  number of  pure strategy
profiles  for all  n players is  (327)(n-2)   (33)2.  In the  sim-
plest  interesting  case,  where n  = 4,  we obtain  a game tree
with 6561 terminal  nodes, and standard solution  algorithms
would need to  operate on a strategic-form  game matrix with
about 4.7 x 1027 entries  (one for  each pure strategy profile).

SO00

4500

4000

3500

~3ooo

5OO

0

,

,

,

,

,

5

10

15

20

Number of Plots of Land

25

30

Divide end Conquer Algorithm

Figure 4:  Performance results  for  the  Road example.

Figure  4  shows how our  divide-and-conquer  algorithm
performs  on  the  Road  example.  We converted  each  of
the  induced MAIDs constructed  during the  algorithm into  a
small  game tree,  and used  the  game solver  GAMBIT (McK-
elvey,  McLennan, & Turocy 2000) to  solve  it.  As expected,
the  time required  by our  algorithm grows polynomially with
n.  Thus, we can solve  a Road MAID with 34 agents  (corre-
sponding to  a game tree  with 368 terminal  nodes) in  about
hour and 21 minutes.

Discussion

and  Future  Work

We have introduced  a new formalism, multi-agent  influence
diagrams (MAIDs), for  modeling multi-agent  scenarios  with
imperfect  information.  MAIDs allow  the  conditional  inde-
pendence structure  of  a scenario  to  be represented explic-
itly,
limiting  the  state  space explosion which plagues both
strategic-form  and extensive-form  games. We have also
shown that  MAIDs allow  us to  define  a  qualitative  graph-
based notion that  represents strategic  relevance, and to  ex-
ploit  it  as  the basis for algorithms that  find equilibria effi-
ciently.

Although the  possibility  of  extending influence  diagrams
to  multi-agent scenarios was recognized at  least  fifteen  years
ago (Shachter  1986),  the  idea  seems to  have been dormant
for  some time.  Suryadi and Gmytrasiewicz (1999) have used
influence  diagrams as  a  framework for  learning  in  multi-
agent  systems.  The focus  of  their  work is  very  differ-

52

ent,  and they  do not  consider  the  computational benefits
derived  from the  influence  diagram representation.  Milch
and Koller (2000) use  multi-agent  influence  diagrams as
representational  framework for  reasoning about agents  be-
liefs  and decisions.  However, they  do not  deal  explicitly
with the  conversion of  a MAID into  a  game tree,  and leave
open the  question  of  how to  find  equilibria.  Nilsson and
Lauritzen  (2000)  have done related  work on limited  mem-
ory  influence  diagrams,  or  LIMIDs. Although they  mention
that  LIMIDs could be applied to  multi-agent scenarios,  they
only consider  the  use  of  LIMIDs to  speed up inference  in
single-agent settings.

MAIDs are  also  related  to  La Muras (2000)  game net-
in-
works, which incorporate both probabilistic  and utility
dependence. La Mura defines  a  notion of  strategic
indepen-
dence, and also  uses it  to  break up the  game into  separate
components. However, his  notion  of  strategic
independence
is  an undirected one, and thus does not allow as  fine-grained
a decomposition as  the  directed  relevance graph used in  this
paper, nor  the  use of  a  backward induction process for  deci-
sions that  are not strategically  independent.

This work leaves  many interesting  open questions.  First,
there is  a great deal of  work to be done in  relating  MAIDs to
existing  concepts in  game theory,  particularly  equilibrium
refinements.  On the  algorithmic  front,
the  most pressing
question  is  whether we can take  advantage of  independence
structure  within SCCs in  the  relevance  graph.  On the  rep-
resentational  front,  it  is  important to  extend MAIDs to  deal
with asymmetric situations,  where the  decisions  to  be made
and the  information available  depend on previous decisions
or  chance  moves. Game trees  represent  such  asymmetry
in  a natural  way, whereas in  MAIDs (as  in  influence  dia-
grams and BNs), a naive  representation  of  an asymmetric
situation
leads  to  unnecessary  blowup. We may
be able  to  avoid these  difficulties
representing context-specificity, as  in (Boutilier et  al.  1996;
Smith, Holtzman, & Matheson 1993), integrating  the  best  of
the  game tree  and MAID representations.

in  MAIDs by explicitly

typically

