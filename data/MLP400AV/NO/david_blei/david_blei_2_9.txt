Abstract

We develop the syntactic topic model (STM), a nonparametric Bayesian model
of parsed documents. The STM generates words that are both thematically and
syntactically constrained, which combines the semantic insights of topic models
with the syntactic information available from parse trees. Each word of a sentence
is generated by a distribution that combines document-specic topic weights and
parse-tree-specic syntactic transitions. Words are assumed to be generated in an
order that respects the parse tree. We derive an approximate posterior inference
method based on variational methods for hierarchical Dirichlet processes, and we
report qualitative and quantitative results on both synthetic data and hand-parsed
documents.

1 Introduction

Probabilistic topic models provide a suite of algorithms for nding low dimensional structure in a
corpus of documents. When t to a corpus, the underlying representation often corresponds to the
topics or themes that run through it. Topic models have improved information retrieval [1], word
sense disambiguation [2], and have additionally been applied to non-text data, such as for computer
vision and collaborative ltering [3, 4].
Topic models are widely applied to text despite a willful ignorance of the underlying linguistic
structures that exist in natural language. In a topic model, the words of each document are assumed
to be exchangeable; their probability is invariant to permutation. This simplication has proved
useful for deriving efcient inference techniques and quickly analyzing very large corpora [5].
However, exchangeable word models are limited. While useful for classication or information
retrieval, where a coarse statistical footprint of the themes of a document is sufcient for success,
exchangeable word models are ill-equipped for problems relying on more ne-grained qualities of
language. For instance, although a topic model can suggest documents relevant to a query, it cannot
nd particularly relevant phrases for question answering. Similarly, while a topic model might
discover a pattern such as eat occurring with cheesecake, it lacks the representation to describe
