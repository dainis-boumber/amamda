ABSTRACT
Linear Support Vector Machines (SVMs) have become one
of the most prominent machine learning techniques for high-
dimensional sparse data commonly encountered in applica-
tions like text classication, word-sense disambiguation, and
drug design. These applications involve a large number of
examples n as well as a large number of features N , while
each example has only s << N non-zero features. This
paper presents a Cutting-Plane Algorithm for training lin-
ear SVMs that provably has training time O(sn) for clas-
sication problems and O(sn log(n)) for ordinal regression
problems. The algorithm is based on an alternative, but
equivalent formulation of the SVM optimization problem.
Empirically, the Cutting-Plane Algorithm is several orders
of magnitude faster than decomposition methods like SVM-
Light for large datasets.
Categories and Subject Descriptors
I.2.6 [Articial Intelligence]: Learning
General Terms
Algorithms, Performance, Experimentation
Keywords
Support Vector Machines (SVM), Training Algorithms, Or-
dinal Regression, Large-Scale Problems, ROC-Area

1.

INTRODUCTION

Many applications of machine learning deal with problems
where both the number of features N as well as the number
of examples n is large (in the millions). Examples of such
problems can be found in text classication, word-sense dis-
ambiguation, and drug design. While problems of such size
seem daunting at rst glance, the examples mentioned above
have extremely sparse feature vectors, which gives hope that
these problems can be handled eciently.

Linear Support Vector Machines (SVMs) are among the
most prominent machine learning techniques for such high-
dimensional and sparse data. On text classication prob-

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for prot or commercial advantage and that copies
bear this notice and the full citation on the rst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specic
permission and/or a fee.
KDD06, August 2023, 2006, Philadelphia, Pennsylvania, USA.
Copyright 2006 ACM 1-59593-339-5/06/0008 ...$5.00.

lems, for example, linear SVMs provide state-of-the-art pre-
diction accuracy [10, 5, 17]. While conventional training
methods for linear SVMs, in particular decomposition meth-
ods like SVM-Light [11], SMO [19], LIBSVM [2], and SVM-
Torch [3] handle problems with a large number of features
N quite eciently, their super-linear scaling behavior with
n [11, 19, 9] makes their use inecient or even intractable
on large datasets. On the other hand, while there are train-
ing methods that scale linear in n (e.g. [18, 7, 6, 15]), such
methods empirically (or at least in the worst case) scale
quadratically with the number of features N .

Even more dicult is the current situation for training lin-
ear Ordinal Regression SVMs (OR-SVMs) [8]. In Herbrich
et al.s formulation, an ordinal regression SVM over n ex-
amples is solved by translating it into a classication SVM
with O(n2) examples, which obviously makes scaling with
n even worse than for straightforward classication SVMs.
Nevertheless, OR-SVM are very interesting even beyond ac-
tual ordinal regression problems like those in information
retrieval. When applied to problems with only two ranks,
OR-SVMs are know to directly optimize the ROC-Area of
the classication rule [20, 14]. This is a desirable criterion
to optimize in many applications.

In this paper, we propose the rst general training algo-
rithm for linear SVMs that provably scales O(s n) for clas-
sication and O(s n log(n)) for ordinal regression, where s
is the average number of non-zero features. Obviously, this
scaling is very attractive for high-dimensional and sparse
data. The algorithm is based on an alternative, yet equiv-
alent formulation of the SVM training problem. Compared
to existing methods, the algorithm has several advantages.
First, it is very simple and easy to implement. Second, it is
several orders of magnitude faster than existing decompo-
sition methods on large classication problems. On a text
classication problem with 800,000 examples and 47,000 fea-
tures, the new algorithm is roughly 100 times faster than
SVM-Light. Third, the algorithm has a meaningful stopping
criterion that directly relates to training error. This avoids
wasting time on solving the optimization problem to a higher
precision than necessary. And, fourth, the algorithm can
handle ordinal regression problems with hundred-thousands
of examples with ease, while existing methods become in-
tractable with only a few thousand examples.

2. STRUCTURAL SVMS

We rst introduce the formulation of the SVM optimiza-
tion problem that provides the basis of our algorithm, both
for classication and for ordinal regression SVMs. Both for-

mulations are derived from Structural SVMs [24, 14] previ-
ously used for predicting structured outputs and optimizing
to multivariate performance measures. For each alternative
formulation, we will show that it is equivalent to the respec-
tive conventional SVM optimization problem.
2.1 Classication
For a given training set (x1, y1), ..., (xn, yn) with xi  (cid:2)N
and yi  {1, +1}, training a binary classication SVM
means solving the following optimization problem. For sim-
plicity of the following theoretical results, we focus on classi-
cation rules hw(x) = sign(wT x+b) with b = 0. A non-zero
b can easily be modeled by adding an additional feature of
constant value to each x (see e.g. [18]).

OP 1. (Classification SVM (primal))

min
w,i0

s.t.

n

C
n

T

w +

1
w
2
i  {1, ..., n} : yi(w

(cid:0)i=1

i

T

xi) 1i

Note that we adopted the formulation of [22, 21] where

 i is divided by n to better capture how C scales with the

training set size. Most training algorithms solve either OP1
or its dual (see [21] for the dual).

The algorithm we explore in the following considers a dif-
ferent optimization problem, which was proposed for train-
ing SVMs to predict structured outputs [24] and to optimize
multivariate performance measures like F1-Score or the Pre-
cision/Recall Break-Even Point [14]. The following is a spe-
cialization of this formulation for the case of error rate, and
we will refer to it as the structural formulation.

OP 2. (Structural Classification SVM (primal))

min
w,0

s.t.

w + C 

T

w

1
2
c{0, 1}n

:

T

1
n w

n

(cid:0)i=1

ciyixi 1
n

ci  

n

(cid:0)i=1

While OP2 has 2n constraints, one for each possible vec-
tor c = (c1, ..., cn)  {0, 1}n, it has only one slack variable
 that is shared across all constraints. Each constraint in
this structural formulation corresponds to the sum of a sub-
set of constraints from OP1, and the ci select the subset.
n
1
i=1 ci can be seen as the maximum fraction of training
errors possible over each subset, and  is an upper bound
on the fraction of training errors made by hw. Interestingly,
OP1 and OP2 are equivalent in the following sense.

n 


Theorem 1. Any solution w
of OP1 (and vice versa), with 

of OP2 is also a solution
= 1

i=1 
i .

n

Proof. Adapting the proof from [14], we will show that
both optimization problems have the same objective value
and an equivalent set of constraints. In particular, for every

w the smallest feasible  andi i are related as  = 1
n i i.
For a given w, the i in OP1 can be optimized individually,
and the optimum is achieved for i = max{0, 1yi(wT xi)}.
For OP2, the optimal  for a given w is

n 

 = max

c{0,1}n 1

n

ci  1
n

n

(cid:0)i=1

n

(cid:0)i=1

ciyi(w

T

xi)

Since the function is linear in ci, each ci can be optimized
independently.
n

min C =

=

n

max

ci{0,1}(cid:4) 1
max(cid:4)0, 1

n

n

(cid:0)i=1
(cid:0)i=1

ci  1
n

ciyi(w

 1
n

T

yi(w

T

xi)(cid:5)
xi)(cid:5) = min

i

C
n

n

(cid:0)i=1

Therefore, the objective functions of both optimization prob-
lems are equal for any w given the optimal  and i, and
consequently so are their optima.

The theorem shows that it is possible to solve OP2 instead
of OP1 to nd the same soft-margin hyperplane. While
OP2 does not appear particularly attractive at rst glance,
we will show in Section 3 that its Wolfe Dual has desirable
sparseness properties. Before we show that a similar formu-
lation also exists for Ordinal Regression SVMs [8], we rst
state the Wolfe dual of OP2, since it will be referred to later.
Denote with xc the sum 1
L1-norm of c (i.e. the number ones in c for binary c).

i=1 ciyixi and with ||c||1 the

n

OP 3. (Structural Classification SVM (dual))

2 (cid:0)c{0,1}n (cid:0)c(cid:1){0,1}n

cc(cid:1) x

T
c xc(cid:1)

n 
c  1

||c||1

n
c  C

max
0

s.t.

(cid:0)c{0,1}n
(cid:0)c{0,1}n

2.2 Ordinal Regression

In ordinal regression, the label yi of an example (xi, yi)
indicates a rank instead of a nominal class. Without loss of
generality, let yi  {1, ..., R} so that the values 1, ..., R are
related on an ordinal scale. In the formulation of Herbrich
et al. [8], the goal is to learn a function h(x) so that for any
pair of examples (xi, yi) and (xj, yj) it holds that

h(xi) > h(xj)  yi > yj.

Given a training set (x1, y1), ..., (xn, yn) with xi  (cid:2)N and
yi  {1, ..., R}, Herbrich et al.
formulate the following or-
dinal regression SVM (OR-SVM). Denote with P the set
of pairs (i, j) for which example i has a higher rank than
example j, i.e. P = {(i, j) : yi > yj}, and let m = |P|.

OP 4. (Ordinal Regression SVM (primal))

min

w,ij0

s.t.

C

T

w +

1
w
2
(i, j)  P : (w

m (cid:0)(i,j)P

T

ij

xi) (w

T

xj) + 1ij

Intuitively, this formulation nds a large-margin linear
function h(x) that minimizes the number of pairs of training
examples that are swapped w.r.t. their desired order. Like
for classication SVMs, OP4 is a convex quadratic program.
Ordinal regression problems have applications in learning re-
trieval functions for search engines [12]. Furthermore, if the
labels y take only two values, OP4 optimizes the ROC-Area
of the classication rule [20, 14].
In general, OP4 has m  O(n2) constraints and slack vari-
ables. While this problem can be brought into the same form
as OP1 by rewriting the constraints as wT (xixj )  1ij ,
even relatively small training sets with only a few thousand

examples are already intractable for conventional training
methods. So far, researchers have tried to cut down on the
number of constraints with various heuristics [20] which,
however, cannot guarantee that the computed solution is
optimal.

We will now derive a similar structural formulation of the
ordinal regression SVM as we have already done for the bi-
nary classication SVM.

OP 5. (Structural Ord. Regr. SVM (primal))

min
w,0

s.t.

T

w

w + C 

1
2
(i,j)P cij{0,1} :

T

1
m w

m

(cid:0)i=1

cij (xixj) 1
m

cij

m

(cid:0)i=1

Like for classication, the structural formulation has O(2n)
constraints, but only a single slack variable . Analogous
to the classication SVM, the following theorem establishes
that both formulations of the OR-SVM have equivalent so-
lutions.


Theorem 2. Any solution w
of OP4 (and vice versa), with 

of OP5 is also a solution
= 1

ij.

m (i,j)P 

Proof. As mentioned above, the constraints in OP4 can
be rewritten as yij (wT (xi  xj))  1 ij with all yij set to
1. Theorem 1 applies immediately after substituting xij =
xi  xj, since OP4 has the same form as OP1, and OP5 has
the same form as OP2.

3. CUTTING-PLANE ALGORITHM

While the alternative formulations of the classication and
the ordinal regression SVM from above have an exponential
number of constraints, they are very convenient in several
ways.

First, there is a single slack variable  that measures train-
ing loss, and there is a direct correspondence between  and
the (in)feasibility of the set of constraints. In particular, if
we have a point (w, ) which fullls all constraints up to
precision , then (w,  + ) is feasible. So, the approxima-
tion accuracy  of an approximate solution to OP2 or OP5 is
directly related to training loss, which provides an intuitive
precision criterion.

Second, OP2 and OP5 are special cases of Structural SVMs
[24, 14]. As we will detail below, for this type of formula-
tion it is possible to prove bounds on the sparsity of an
-approximate solution of the Wolfe dual. In particular, we
will show that the sparsity is independent of the training set
size n, and that simple Cutting-Plane Algorithms [16] nd
an -approximate solution in a constant number of iterations
for both OP2 or OP5.
3.1 Classication

Algorithm 1 is our adaptation of the Cutting-Plane Al-
gorithm for the Classication SVM optimization problem
OP2.
It is an adaptation of the Structural SVM training
algorithm [24, 14]. The algorithm iteratively constructs a
sucient subset W of the set of constraints in OP2. The al-
gorithm starts with an empty set of constraints W. In each
iteration, it rst computes the optimum over the current
working set W (i.e. w = 0 and  = 0 in the rst iteration)
in Line 4. In Lines 5-7 it then nds the most violated con-
straint in OP2 and adds it to the working set W in Line 8.

Algorithm 1 for training Classication SVMs via OP2.
1: Input: S = ((x1, y1), . . . , (xn, yn)), C, 
2: W  
3: repeat
4:

(w, )  argminw,0

2 wT w + C

1

n wT

ciyixi 1

n

n

i=1

n

ci
i=1

for i=1,...,n do

s.t. cW: 1
ci (cid:4) 1 yi(wT xi) < 1

0 otherwise

5:

6:

end for

7:
8: W  W  {c}
ci  1
9: until 1
i=1
n
10: return(w,)

n

n

ciyi(wT xi)}   + 

n

i=1

Note that this assignment to (c1, ..., cn) = c corresponds to
the constraint in OP2 that requires the largest  to make it
feasible given the current w, i.e.
ci  1
n

c = argmax

ciyi(w

n

n

n

T

c{0,1}n 1

xi) .

(cid:0)i=1

(cid:0)i=1

The algorithm then continues in Line 4 by optimizing over
the new working set, unless the most violated constraint is
not violated by more than the desired precision .

In the following, we will analyze the correctness and the
time complexity of the algorithm. We will show that the
algorithm always terminates after a polynomial number of
iterations that does not depend on the size n of the train-
ing set. Regarding its correctness, the following theorem
characterizes the accuracy of the solution computed by Al-
gorithm 1.

Theorem 3. (Correctness of Algorithm 1)

, 

For any training sample S = ((x1, y1), . . . , (xn, yn)) and
any  > 0, if (w
) is the optimal solution of OP2, then
Algorithm 1 returns a point (w, ) that has a better objective
, 
), and for which (w,  + ) is feasible in
value than (w
OP2.

Proof. We rst verify that Lines 5-7 compute the vector

c  {0, 1}n that maximizes

(cid:4)

= max

c{0,1}n 1

n

ci  1
n

n

(cid:0)i=1

n

(cid:0)i=1

ciyi(w

T

xi) .

(cid:4)
is the minimum value needed to fulll all constraints in
OP2 for the current w. Since the function is linear in ci,
each ci can be maximized independently.
(cid:4)

max{0, 1yi(w

{ciciyi(w

xi)} =

xi)}

=

n

n

T

T

1
n

(cid:0)i=1

max
ci{0,1}

1
n

(cid:0)i=1

This directly corresponds to the assignment in Line 6. As
checked in Line 9, the algorithm terminates only if (cid:4)
does
not exceed the  from the solution over W by more than  as
desired.

Since the (w, ) returned by Algorithm 1 is the solu-
tion on a subset of the constraints from OP2, it holds that
T w
1
2 w

+ C  1

2 wT w + C.



Using a stopping criterion based on the accuracy of the
training loss  is very intuitive and practically meaningful,

unlike the stopping criteria typically used in decomposition
Intuitively,  can be used to indicate how close
methods.
one wants to be to the error rate of the best hyperplane.
In most machine learning applications, tolerating a training
error that is suboptimal by 0.1% is very acceptable. This
intuition makes selecting the stopping criterion much easier
than in decomposition methods, where it is usually dened
based on the accuracy of the Kuhn-Tucker Conditions of
the dual (see e.g.
[11]). Solving OP2 to an arbitrary but
xed precision of  is essential in our analysis below, making
sure that computation time is not wasted on computing a
solution that is more accurate than necessary.

We next analyze the time complexity of Algorithm 1. It is
easy to see that each iteration of the algorithm takes poly-
nomial time, and that time scales linearly with n and s. We
then show that the number of iterations until convergence
is bounded, and that this upper bound is independent of n.

Lemma 1. Each iteration of Algorithm 1 takes time O(sn)

for a constant working set size |W|.

Proof. Each dot-product in Lines 6 and 9 takes time
O(s) when using sparse vector algebra, and n dot-products
are computed in each line.
Instead of solving the primal
quadratic program, one can instead solve the dual OP3 in
Line 4. Setting up the dual over W in Line 4 is dominated by
computing the O(|W|2) elements of the Hessian, which can
be done in O(|W|2sn) after rst computing 1
n
i=1 ciyixi
n 
for each constraint in W. Note that N  sn. The time for
solving the dual is then independent of n and s. This leads
to an overall time complexity of O(sn) per iteration.

Lemma 2. For any  > 0, C > 0, and any training sam-
ple S = ((x1, y1), . . . , (xn, yn)), Algorithms 1 and 2 termi-
nate after at most

max(cid:4) 2



, 8CR2
2 (cid:5)

(1)
iterations. R = maxi ||xi|| for Algorithm 1 and for Algo-
rithm 2 it is R = 2 maxi ||xi||.

Proof. Following the proof scheme in [24, 13], we will
show that adding each new constraint to W increases the
objective value at the solution of the quadratic program in
Line 4 by at least some constant positive value. Since the
objective value of the solution of OP2 is upper bounded by
C (since w = 0 and  = 1 is a feasible point in the primal),
the algorithm can only perform a constant number of itera-
tions before termination. The amount by which the solution
increases by adding one constraint that is violated by more
then  (i.e. the criteria in Lines 9 and 26 respectively) to
W is characterized by Proposition 17 in [24]. A lower bound
on the increase is

min(cid:4) C

2

,

2

8Q2(cid:5)

where Q is an upper bound on the L2-norm of the coecient
vectors in the constraints. For OP2
n

n

in the case of Algorithm 1 and for OP5

Q = max

1
n

(cid:0)i=1

c{0,1}n(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)
(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)
(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)
c{0,1}m(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)
m (cid:0)(i,j)P

ciyixi(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)
(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)
(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)
cij (xixj )(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)(cid:6)

1

Q = max

||xi||  R

ci max

i

 1
n

(cid:0)i=1

 1
m (cid:0)(i,j)P

cij 2 max

i

||xi||  R

in the case of Algorithm 2. Due to this constant increase
of the objective value in each iteration, either algorithm can

add at most max 2

value exceeds C, which is an upper bound on the objective
value at the solution of OP2 and OP5.

2  constraints before the objective



, 8CR2

Note that the formulation of OP2 with the scaled C

n in-
stead of C in the objective is essential for this lemma. We
will empirically evaluate the adequacy of this scaling in Sec-
tion 4. Putting everything together leads to the following
bound on the time complexity of Algorithm 1.

Theorem 4. (Time Complexity of Algorithm 1)

For any distribution P (X, Y ) that generates feature vectors
of bounded L2-norm ||x|| and any xed value of C > 0 and
 > 0, Algorithm 1 has time complexity O(sn) for any train-
ing sample of size n and sparsity s.
Proof. Lemma 2 bounds the number of iterations (and
therefore the maximum working set size |W|) to a constant
that is independent of n and s. Each iteration has time
complexity O(sn) as established by Lemma 1.

To our knowledge, Algorithm 1 has the best scaling be-
havior of all known training algorithms for linear SVMs. De-
composition methods like SVM-Light [11], SMO [19], LIB-
SVM [2], and SVMTorch [3] handle sparse problems with a
large number of features N quite eciently. However, their
super-linear scaling behavior with n [11, 19, 9] makes them
inecient or even intractable on large datasets. We will
compare our algorithm against SVM-Light as a representa-
tive decomposition methods.

Other methods sacrice the statistical robustness [22] of

i

the  i loss in the objective for the numerically more con-
venient  2
i loss. With additional restrictions on how the
data is normalized, Core Vector Machines [23] are shown to
scale linear in n. However, the restrictions make the method
inapplicable to many datasets. Generally applicable are La-
grangian SVM [18] (using the  2
loss), Proximal SVM
[7] (using an L2 regression loss), and Interior Point Meth-
ods [6]. While these method scale linearly with n, they use
the Sherman-Morrison-Woodbury formula for inverting the
Hessian of the dual. This requires operating on N  N ma-
trices, which makes them applicable only for problems with
small N . As a representative of this group of methods, we
will compare against the Lagrangian SVM in Section 4.
The recent L2-SVM-MFN method [15] avoids explicitly
representing N  N matrices using conjugent gradient tech-
niques. While the worst-case cost is still O(sn min(n,N)) per
iteration, they observe that their method empirically scales
better. We will compare against this method as well.
3.2 Ordinal Regression

Algorithm 2 solves the ordinal regression SVM in the form
of OP5 and has a structure that is very similar to Algo-
rithm 1. It is a generalization of the algorithm for optimiz-
ing ROC-Area in [14] and similar to the algorithm indepen-
dently developed in [4]. The key dierence to Algorithm 1
lies in computing the most violated constraint of OP5

1

(cid:4)
c

= argmax

cij  1

c{0,1}m(cid:9)(cid:10)
(cid:11)

(xi  xj)(cid:12)(cid:13)
(cid:14)
without enumerating all m  O(n2) constraints from OP4.
To avoid O(n2) cost, Algorithm 2 makes use of a condensed

m (cid:0)(i,j)P

m (cid:0)(i,j)P

cij w

T

while (j  n)  (wT xi  wT xj < 1) do

j  c

j + (nr  a + 1)

if yj < r then

b + +; c

5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23: W  W  {(c+, c
)}

i )  1
24: until
i=1

end while
a + +; c+

25: return(w,)

i  c+

end if
i + +

end if
j + +

end while

i +c
(c+

i=1

end for

2m

m

n

n

1

i + b

Algorithm 2 for training Ord. Regr. SVMs via OP5.
1: Input: S = ((x1, y1), . . . , (xn, yn)), C, 
2: W  
3: repeat
4:

1

n

i=1

(w, )  argminw,0
s.t. (c+,c
)W: 1


2 wT w + C
ic
(c+
m wT
sort S by decreasing wT xi
c+  0; c
nr  number of examples with yi = r
for r = 2, ..., R do
i  1; j  1; a  0; b  0
while i  n do
if yi = r then

  0

i )xi 1

2m

i+c
(c+

i )

n

i=1

ic
(c+

i )(wT xi)   + 

representation of the constraints as follows. While the left-
hand side of the linear constraints in OP4 contains a sum
over m vectors of dierences (xi  xj), most individual vec-
tors xi are added and subtracted multiple time. With proper
coecients c+
j , each constraint can be rewritten as
a sum of n vectors

i and c

T

1
m w

n

(cid:0)i=1

i  c
(c+

i )xi  1
2m

i + c
(c+

i )  

n

(cid:0)i=1

i


If c+ and c

where c+
is the number of times xi occurs with positive
sign (i.e. cij = 1) and c
i
is the number of times xi oc-
curs with negative sign (i.e. cji = 1).
are
known, each constraint can be evaluated in time O(sn) in-
stead of O(sm). Furthermore, the right hand side of each

constraint can be computed from c+ and c
in time O(n)
i + c
n
instead of O(m), since 1
i ). The
following theorem shows that Algorithm 2 computes the co-

ecient vectors c+ and c
of the most violated constraint,
and therefore converges to the optimal solution in the same
sense as Algorithm 1.

2m 

i=1cij = 1

m

i=1(c+

m

Theorem 5. (Correctness of Algorithm 2)

For any training sample S = ((x1, y1), . . . , (xn, yn)) and
any  > 0, if (w
) is the optimal solution of OP5, then
Algorithm 2 returns (w, ) that have a better objective value
than (w

), and for which (w,  + ) is feasible in OP5.

, 

, 

Proof. Analogous to the proof of Theorem 3,

(cid:4)
c

= argmax

c{0,1}m(cid:9)(cid:10)
(cid:11)

1

m (cid:0)(i,j)P

cij  1

m (cid:0)(i,j)P

T

cij w

(xi  xj)(cid:12)(cid:13)
(cid:14)

is reached for

cij (cid:4) 1 (wT xi)  (wT xj) < 1

0 otherwise

.

This means that the number of times xi enters with positive
and negative sign is

i = |{j : (yi > yj )  ((w
c+
i = |{j : (yj > yi)  ((w
c

T

T

T

xi)  (w
xj)  (w

T

xj) < 1)}|,
xi) < 1)}|.

To compute these quantities eciently, Algorithm 2 rst
sorts the training examples by decreasing value of wT xi.
Then, for each rank r in turn, it updates the values of c+
and c+ for all constraints (i, j)  P in OP4 with yi = r. By
going through the examples in order of wT xi, the algorithm
can keep track of

a = |l : (yl = r)  (w
b = |l : (yl < r)  (w

T

T

T

xl > w
T
xl > w

xi)|
xi  1)|

via incremental updates. Whenever it encounters an exam-
ple with yi = r, there are exactly b constraints (i, j)  P in
OP4 with yj < r and ((wT xi)  (wT xj) < 1). Similarly,
whenever it encounters an example with yj < r, there are ex-
actly (nr  a) constraints (i, j)  P in OP4 with yi = r and
((wT xi)  (wT xj) < 1). By exhaustively going through all
r, yi = r, and yj < r and adding the respective quantities to
i and c
c+
j , the algorithm implicitly considers all constraints
in OP4.

Like Algorithm 1, the iteration terminate only if no con-

straint in OP5 is violated by more than , and

T



w

w

1
2

+ C  1
2

T

w

w + C

since W is a subset of the constraints in OP4.

The following lemma characterizes the time Algorithm 2

takes in each iteration as a function of n and s.

Lemma 3. Each iteration of Algorithm 2 requires time
O(sn + n log(n) + Rn) for a constant working set size |W|.
Proof. The proof is analogous to that of Lemma 1. The
greatest expense per iteration in terms of n is the sort in
Line 5 and the computation of n inner products wT xi. Lines
8-24 take R  1 passes through the training set. Due to the
condensed representation, setting up the quadratic program
in Line 4 can again be done in time O(|W|2sn) analogous
to Lemma 1.

Lemma 2 already established an upper bound on the num-
ber of iterations of Algorithm 2. Analogous to Theorem 4,
the following characterizes its the scaling behavior.

Theorem 6. (Time Complexity of Algorithm 2)

For any distribution P (X, Y ) that generates feature vectors
of bounded L2-norm ||x|| and any xed value of C > 0 and
 > 0, Algorithm 2 has time complexity O(sn log(n)) for any
training sample of size n and sparsity s.

Note that conventional methods for training ordinal re-
gression SVMs based on OP4 have much worse scaling be-
havior. They scale roughly O(sn3) even under the (opti-
mistic) assumption that a problem with m constraints can
be solved in O(m) time. Only small training sets with hun-
dreds or at best a few thousand examples are tractable.

Table 1: Training time in CPU-seconds.

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics

n
804,414
804,414
62,369
522,911
150,000

N
47,236
47,236
99,757
54
78

s
0.16%
0.16%
0.08%
22.22%
38.42%

Classication

Ordinal Regression

SVM-Perf
149.7
178.9
16.9
171.7
31.9

SVM-Light
20,075.5
5,187.4
80.1
25,514.3
1,040.2

SVM-Perf
304.1
499.1
26.1
1,109.1
132.5

SVM-Light
NA
NA
NA
NA
NA

Heuristic approaches for pushing the limits by removing con-
straints oer no performance guarantees [20]. We will see
in the following experiments that Algorithm 2 can handle
problems with hundred-thousands of examples with ease.

4. EXPERIMENTS

While Theorems 4 and 6 characterize the asymptotic scal-
ing of Algorithms 1 and 2, the behavior for small sample
sizes may be dierent. We will empirically analyze the scal-
ing behavior in the following experiments, as well as its sensi-
tivity to C and . Furthermore, we compare the algorithms
against existing methods, in particular the decomposition
method SVM-Light.

We implemented Algorithms 1 and 2 using SVM-Light as
the basic quadratic programming software that is called in
Line 4 of each algorithm. However, other quadratic pro-
gramming tools would work just as well, since |W| remained
small in all our experiments. We will refer to our implemen-
tation of Algorithms 1 and 2 as SVM-Perf in the following.
SVM-Perf is available at http://svmlight.joachims.org.
We use 5 datasets in our experiments, selected to cover a

wide range of properties.

1. First, we consider the binary text classication task
CCAT from the Reuters RCV1 collection1 [17]. There
are 804,414 examples split into 23,149 training and
781,265 test examples, and there are 47,236 features
with sparsity 0.16%. This task has an almost balanced
class ratio.

2. Second, we include the task C11 from the RCV1 collec-
tion, since it has an unbalanced class ratio. Existing
decomposition methods like SVM-Light are know to
run faster for unbalanced tasks.

3. The third problem is classifying abstracts of scientic
papers from the Physics ArXiv by whether they are in
the Astro-physics section. We picked this task since
it has a large number of features (99,757) with high
sparsity (0.08%). There are 62,369 examples split into
29,882 training examples and 32,487 test examples.

4. The fourth problem is class 1 in the Covertype dataset2
of Blackard, Jock & Dean, which is comparably low-
dimensional with 54 features and a sparsity of 22.22%.
There are 581,012 examples which we split into 522,911
training examples and 58101 test examples.

5. Finally, we added the KDD04 Physics task from the
KDD-Cup 2004 [1], with 78 features (sparsity 38.42%)

1http://jmlr.csail.mit.edu/papers/volume5/lewis04a/
lyrl2004 rcv1v2 README.htm
2http://www.ics.uci.edu/mlearn/MLRepository.html

and 150,000 examples, which are split into 50,000 train-
ing examples and 100,000 test examples.

We use the Precision/Recall Break-Even Point (PRBEP)
(see e.g.
[10]) as the measure of performance for the text-
classication tasks, and Accuracy for the other problems.

The following parameters are used in our experiments,
unless noted otherwise. Both SVM-Light and SVM-Perf
use  = 0.001 (note that their interpretation of  is dif-
ferent, though). As the value of C, we use the setting that
achieves the best performance on the test set when using
the full training set (C = 10, 000 for Reuters CCAT, C =
50, 000 for Reuters C11, C = 20, 000 for Arxiv astro-ph,
C = 1, 000, 000 for Covertype 1, and C = 20, 000 for KDD04
Physics). Whenever possible, runtime comparisons are done
on the full set of examples, joining training and test data
together to get larger datasets. Experiments that com-
pare prediction performance report results for the standard
test/training split. All experiments are run on 3.6 Mhz Intel
Xeon processors with 2GB main memory under Linux.
4.1 How Fast are the Algorithms Compared

to Existing Methods?

Table 1 compares the CPU-time of SVM-Perf and SVM-
Light on the full data for the 5 tasks described above. For
the classication SVM, SVM-Perf is substantially faster than
SVM-Light on all problems, achieving a speedup of several
orders of magnitude on most problems. We will analyze
these results in detail in the following sections.

We also applied the ordinal regression SVM to these data-
sets, treating the binary classication problems as ordinal
problems with two classes. An alternative view on this
setup is that the OR-SVM learns a classication rule that
optimizes ROC Area [20, 14]. The runtimes are somewhat
slower than for classication, but still very tractable. We
tried to train SVM-Light in its ordinal regression mode on
these problems as well. However, training with SVM-Light
is intractable with more than  4,000 examples.

A method that was recently proposed for training linear
SVMs is the L2-SVM-MFN algorithm [15]. While they do
not provide an implementation of their method, they re-
port training times for the two publicly available dataset
Adult and Web in the version produced by John Platt. On
the Adult data with 32,562 examples and 120 features, they
report a training time of 1.6 CPU-seconds for the value of
C = 0.0625  32,562 achieving optimal cross-validation error,
which is comparable to 3.1 CPU-seconds needed by SVM-
Perf for C = 0.05  32,562 as recommended by Platt. Sim-
ilarly, for the Web data with 49,749 examples and 300 fea-
tures, L2-SVM-MFN is reported to take 5.0 CPU-seconds
(C = 1  49,749) while SVM-Perf takes 7.6 CPU-seconds for
the same value of C. While both methods seem to perform
comparably for these rather small training sets, it is unclear

100000

10000

SVM-Perf (Classication)

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics
O(x^0.8)

100000

10000

SVM-Light (Classication)

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics
O(x^1.7)

100000

10000

SVM-Perf (Class. opt. C)

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics
O(x^1.0)

100000

10000

SVM-Perf (Ord. Regr.)

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics
O(x^0.8)

s
d
n
o
c
e
S
U
P
C

-

1000

100

10

1

s
d
n
o
c
e
S
U
P
C

-

1000

100

10

1

s
d
n
o
c
e
S
U
P
C

-

1000

100

10

1

s
d
n
o
c
e
S
U
P
C

-

1000

100

10

1

0.1

100

1000  10000  100000  1e+06

0.1

100

1000  10000  100000  1e+06

0.1

100

1000  10000  100000  1e+06

0.1

100

1000  10000  100000  1e+06

Number of Training Examples

Number of Training Examples

Number of Training Examples

Number of Training Examples

Figure 1: Training time of SVM-Perf (left) and SVM-Light (left-middle) for classication as a function of n
for the value of C that gives best test set performance for the maximum training set size. The middle-right
plot shows training time of SVM-Perf for the value of C with optimum test set performance for the respective
training set size. The right-most plot is the CPU-time of SVM-Perf for ordinal regression.

how L2-SVM-MFN scales.
In the worst case, the authors
conclude that each iteration may scale O(sn min{n, N}), al-
though practical scaling is likely to be substantially better.
Finally, note that L2-SVM-MFN uses squared slack vari-
i to measure training loss instead of linear slacks

ables  2
 i like in SVM-Light and SVM-Perf.
MFN, the LSVM uses squared slack variables  2

The Lagrangian SVM (LSVM) [18] is another method par-
ticularly suited for training linear SVMs. Like the L2-SVM-
i to mea-
sure training loss. The LSVM can be very fast if the number
of features N is small, scaling roughly as O(nN 2). We ap-
plied the implementation of Mangasarian and Musicant3 to
the Adult and the Web data using the values of C from above.
With 31.4 CPU-seconds, the training time of the LSVM is
still comparable on Adult. For the higher-dimensional Web
task, the LSVM runs into convergence problems. Apply-
ing the LSVM to tasks with thousands of features is not
tractable, since the algorithm requires storing and inverting
an N  N matrix.
4.2 How does Training Time Scale with the

Number of Training Examples?

Figure 1 shows log-log plots of how CPU-time increases
with the size of the training set. The left-most plot shows the
scaling of SVM-Perf for classication, while the left-middle
plot shows the scaling of SVM-Light. Lines in a log-log
plot correspond to polynomial growth O(nd), where d cor-
responds to the slope of the line. The middle plot shows
that SVM-Light scales roughly O(n1.7), which is consistent
with previous observations [11]. SVM-Perf has much better
scaling, which is (to some surprise) better than linear with
roughly O(n0.8) over much of the range.

Figure 2 gives insight into the reason for this scaling be-
havior. The graph shows the number of iterations of SVM-
Perf (and therefore the maximum number of constraints in
the working set) in relation to the training set size n.
It
turns out that the number of iterations is not only upper
bounded independent of n as shown in Lemma 2, but that

3http://www.cs.wisc.edu/dmi/lsvm/

1000

s
n
o

i
t

a
r
e

t
I

100

10

1
1000

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics

10000

100000

1e+06

Number of Training Examples

Figure 2: Number of iterations of SVM-Perf for clas-
sication as a function of sample size n.

it does not grow with n even in the non-asymptotic region.
In fact, for some of the problems the number of iterations
decreases with n, which explains the sub-linear scaling in
CPU-time. Another explanation lies in the high xed cost
that is independent of n, which is mostly the cost for solving
a quadratic program in each iteration.

Since Lemma 2 identies that the number of iterations
depends on the value of C, scaling for the optimal value of
C might be dierent if the optimal C increases with training
set size. To analyze this, the middle-right plot of Figure 1
shows training time for the optimal value of C. While the
curves look more noisy, the scaling still seems to be roughly
linear.

Finally, the right-most plot in Figure 1 shows training
time of SVM-Perf for ordinal regression. The scaling is
slightly steeper than for classication as expected. The num-
ber of iterations is virtually identical to the case of classi-
cation shown in Figure 2. Note that training time of SVM-
Light would scale roughly O(n3.4) on this problem.

3

2

1

0

-1

-2

)
s
_
C
C
A


-


C
C
A

(

r
o


)
s
_
P
E
B
R
P


-


P
E
B
R
P

(

-3
100

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics

1000

10000

100000

1e+06

C

Figure 3: Dierence in prediction performance be-
tween SVM-Perf and SVM-Light for classication as
a function of C.

4.3 Is the Prediction Performance of SVM-

Perf Different from SVM-Light?

One potential worry is that the speedup of SVM-Perf over
SVM-Light somehow comes at the expense of prediction ac-
curacy, especially due to the choice of  = 0.001. However,
this is not the case. Figure 3 shows the dierence in test
set accuracy / PRBEP between the classiers produced by
SVM-Light and SVM-Perf. For better readability, the dif-
ference is shown in terms of percentage points. A positive
value indicates that SVM-Perf has higher prediction perfor-
mance, a negative value indicates that SVM-Light performs
better. For almost all values of C both methods perform al-
most identically. In particular, there is not indication that
the rules learned by SVM-Perf are less accurate. One case
where there is a large dierence is the Covertype 1 task for
small values of C, since SVM-Light stops before fully con-
verging.
4.4 How Small does  need to be?

The previous section showed that  = 0.001 is sucient
to get prediction accuracy comparable to SVM-Light. But
maybe a lower precision would suce and reduce training
time? Figure 4 shows the dierence (in percentage points) in
prediction accuracy / PRBEP compared to the performance
SVM-Perf reaches for  = 0.001. Values above (below) 0
indicate that the accuracy of SVM-Perf for that  is better
(worse) than the accuracy at  = 0.001. The graph shows
that for all   0.01 the prediction performance is within
half a percentage point. For larger values of  the resulting
rules are starting to have more variable and less reliable
performance. So, overall,  = 0.001 seems accurate enough
with some safety margin. However, one might elect to use
larger  at the expense of prediction accuracy, if training
time was substantially faster. We will evaluate this next.
4.5 How does Training Time Scale with ?

Lemma 2 indicates that the number of iterations, and
therefore the training time, should decrease as  increases.
Figure 5 shows number of iterations as a function of . In-
terestingly, the empirical scaling of roughly O( 1
0.3 ) is much
better than O( 1
2 ) in the bound from Lemma 2. For training
time, as shown in Figure 6, the scaling is O( 1

0.4 ).

.

)
]
1
0
0
0
=
s
p
e
P
E
B
R
P

[


-


P
E
B
R
P

(

r
o


)
]

.

1
0
0
0
=
s
p
e

[
c
c
A


-

c
c
A

(

3

2

1

0

-1

-2

-3
1e-04

CCAT
C11
ArXiv astro-ph
Covertype 1
KDD04 Physics

0.001

0.01

0.1

epsilon

Figure 4: Dierence in Accuracy or PRBEP of
SVM-Perf compared to its performance at  = 0.001
as a function of .

1000

s
n
o

i
t

a
r
e

t
I

100

10

1
1e-04

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics
O(1/x^0.3)

0.001

0.01

0.1

Epsilon

Figure 5: Number of iterations of SVM-Perf for clas-
sication as a function of .

Reuters CCAT
Reuters C11
ArXiv astro-ph
Covertype 1
KDD04 Physics
O(1/x^0.4)

1000

s
d
n
o
c
e
S
U
P
C

-

100

10

1
1e-04

0.001

0.01

0.1

epsilon

Figure 6: CPU-time of SVM-Perf for classication
as a function of .

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics

1

0.1

0.01

0.001

*
j
b
O

/
|
j

b
O


-

*
j
b
O

|

1

0.1

0.01

0.001

*
j
b
O

/
|
j

b
O


-

*
j
b
O

|

1e-04

100

1000

10000

100000

1e+06

1e-04

1e-04

0.001

C

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics

0.01
Epsilon

0.1

1

Figure 7: Relative dierence between the objective value of the SVM-Perf solution for classication and the
(approximately) true solution as a function of C (left) (with  = 0.001) and as a function of  (right) (with C
is set to maximize test set prediction performance).

Could the runtime of SVM-Light be improved by increas-
ing the value of  as well? While SVM-Light converges faster
for larger values of , the dierence is much smaller. Even
when increasing  to 0.5, the speedup is less than a factor of
2 on all ve problems.
4.6 Is the Solution Computed by SVM-Perf

Close to Optimal?

While we have already established that training with
 = 0.001 gives rules of comparable prediction accuracy, it
is also interesting to look at how close the objective value
of the relaxed solution is to the true optimum for dierent
values of . As Theorems 3 and 5 show, the objective value
is lower than the true objective, but by how much? Figure 7
shows the relative dierence

Obj(SVM-Light)  Obj(SVM-Perf)

Obj(SVM-Light)

between the solution of SVM-Perf and a high-precision solu-
tion computed by SVM-Light. The left-hand plot of Figure 7
indicates that for  = 0.001 the relative error is roughly be-
tween 0.1% and 1% over all values of C. The missing points
correspond to values where SVM-Light failed to converge.
The right-hand plot shows how the relative error decreases
with .
4.7 How does Training Time Scale with C?



Finally,

lets examine how the number of iterations of
SVM-Perf scales with the value of C. The upper bound of
Lemma 2 suggest a linear scaling, however, Figure 8 shows
C) for clas-
that the actual scaling is much better with O(
sication (and similarly for ordinal regression). Figure 9
shows the resulting training times (left) and compares them
against those of SVM-Light (right). Except for excessively
large values of C, the training time of SVM-Perf scales sub-
linearly with C. Note that the optimal values of C lie be-
tween 10, 000 and 50, 000 for all tasks except Covertype 1.
For all values of C, SVM-Perf is faster than SVM-Light.

5. ACKNOWLEDGMENTS

Reuters CCAT
Reuters C11
Arxiv astro-ph
Covertype 1
KDD04 Physics
O(x^0.5)

10000

1000

100

10

s
n
o

i
t

a
r
e

t
I

1
100

1000

10000

100000

1e+06

C

Figure 8: Number of iterations of SVM-Perf as a
function of C.

6. CONCLUSIONS

We presented a simple Cutting-Plane Algorithm for train-
ing linear SVMs that is shown to converge in time O(sn) for
classication and O(sn log(n)) for ordinal regression. It is
based on an alternative formulation of the SVM optimiza-
tion problem that exhibits a dierent form of sparsity com-
pared to the conventional formulation. The algorithm is em-
pirically very fast and has an intuitively meaningful stopping
criterion.

The algorithm opens several areas for research. Since it
takes only a small number of sequential iterations through
the data, it is promising for parallel implementations using
out-of-core memory. Also, the algorithm can in principle
be applied to SVMs with Kernels. While a straightforward
implementation is slower by a factor of n, matrix approxi-
mation techniques and the use of sampling might overcome
this problem.

