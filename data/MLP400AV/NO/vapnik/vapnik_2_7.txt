Abstract

Large VC-dimension classiers can learn dicult tasks, but are usually

impractical because they generalize well only if they are trained with huge

quantities of data. In this paper we show that even very high-order poly-

nomial classiers can be trained with a small amount of training data and

yet generalize better than classiers with a smaller VC-dimension. This

is achieved with a maximum margin algorithm (the Generalized Portrait).

The technique is applicable to a wide variety of classiers, including Per-

ceptrons, polynomial classiers (sigma-pi unit networks) and Radial Basis

Functions. The eective number of parameters is adjusted automatically

by the training algorithm to match the complexity of the problem. It is

shown to equal the number of those training patterns which are closest

patterns to the decision boundary (supporting patterns). Bounds on the

generalization error and the speed of convergence of the algorithm are

given. Experimental results on handwritten digit recognition demonstrate

good generalization compared to other algorithms.

1 INTRODUCTION

Both experimental evidence and theoretical studies [1] link the generalization of a

classier to the error on the training examples and the capacity of the classier.



Part of this work was done while B. Boser was at AT&T Bell Laboratories. He is now

at the University of California, Berkeley.

Classiers with a large number of adjustable parameters, and therefore large ca-

pacity, likely learn the training set without error, but exhibit poor generalization.

Conversely, a classier with insucient capacity might not be able to learn the task

at all. The goal of capacity tuning methods is to nd the optimal capacity which

minimizes the expected generalization error for a given amount of training data.

One distinguishes two ways of tuning the capacity: starting with a low capacity

system and allocating more parameters as needed or starting with an large capacity

system and eliminating unnecessary adjustable parameters with regularization. The

rst method requires searching in the space of classier structures which possibly

contains many local minima. The second method is computationally inecient since

it does not avoid adjusting a large number of parameters although the eective

number of parameters may be small.

With the method proposed in this paper, the capacity of some very large VC-

dimension classiers (such as polynomial classiers of high order) is adjusted au-

tomatically in the process of training. The problem is formulated as a quadratic

programming problem which has a single global minimum. Only the eective pa-

rameters get adjusted during training which ensures computational eciency.

1.1 MAXIMUM MARGIN AND SUPPORTING PATTERNS

Here is a familiar problem: Given is a limited number of training examples from two

classes A and B; nd the linear decision boundary which yields best generalization

performance. When the training data is scarce, there exist usually many errorless

separations (gure 1.1). This is especially true when the dimension of input space

(i.e. the number of tunable parameters) is large compared to the number of training

examples. The question arises which of these solutions to choose? Although there

is no denite answer to this question, the one solution that achieves the largest

possible margin between the decision boundary and the training patterns on either

side appears to be a good choice (gure 1.2). This solution is intuitively justiable:

a new example from class A is likely to fall within or near the convex envelope of

the examples of class A (and similarly for class B). By providing the largest possible

\safety" margin, we minimize the chances that examples from class A and B cross

the border to the wrong side.

An important property of the maximum margin solution is that it is only depen-

dent upon a restricted number of training examples, called supporting patterns (or

informative patterns). These are those examples which lie on the margin and there-

fore are closest to the decision boundary (gure 1.2). The number m of linearly

independent supporting patterns satises the inequality:

m  min(N + 1; p):

(1)

In this equation, (N + 1) is the number of adjustable parameters and equals the

Vapnik-Chervonenkis dimension (VC-dimension) [2], and p is the number of training

examples. In reference [3], we show that the generalization error is bounded by m=p

and therefore m is a measure of complexity of the learning problem. Because m is

bounded by p and is generally a lot smaller than p, the maximum margin solution

obtains good generalization even when the problem is grossly underdetermined,

i.e. the number of training patterns p is much smaller than the number of adjustable

x2

x2

A

A

B

B

(1)

x1

(2)

x1

Figure 1: Linear separations.

(1) When many linear decision rules separate the training set, which one to choose?

(2) The maximum margin solution. The distance to the decision boundary of the

closest training patterns is maximized. The grey shading indicates the margin area

in which no pattern falls. The supporting patterns (in white) lie on the margin.

parameters, N + 1. In section 2.3 we show that the existence of supporting patterns

is advantageous for computational reasons as well.

1.2 NON-LINEAR CLASSIFIERS

Although algorithms that maximize the margin between classes have been known

for many years [4], they have for computational reasons so far been limited to the

special case of nding linear separations and consequently to relatively simple clas-

sication problems. In this paper, we present an extension to one of these maximum

margin training algorithms called the \Generalized Portrait Method" (GP ) [2] to

various non-linear classiers, including including Perceptrons, polynomial classiers

(sigma-pi unit networks) and kernel classiers (Radial Basis Functions) (gure 2).

The new algorithm trains eciently very high VC-dimension classiers with a huge

number of tunable parameters. Despite the large number of free parameters, the

solution exhibits good generalization due to the inherent regularizationof the max-

imum margin cost function.

As an example, let us consider the case of a second order polynomial classiers. Its

decision surface is described by the following equation:

X

X

w

x

+

w

x

x

+ b = 0:

(2)

i

i

ij

i

j

i

i;j

The w

, w

and b are adjustable parameters, and x

are the coordinates of a pattern

i

ij

i

x. If n is the dimension of input pattern x, the number of adjustable parameters

x2

x2

A

A

B

B

(1)

x1

(2)

x1

Figure 2: Non-linear separations.

Decision boundaries obtained by maximizing the margin in '-space (see text). The

grey shading indicates the margin area pro jected back to x-space. The supporting

patterns (white) lie on the margin. (1) Polynomial classier of order two (sigma-pi

unit network), with kernel K (x; x

) = (x  x

+ 1)

. (2) Kernel classier (RBF) with

0

0

2

kernel K (x; x) = (exp kx  x

k=10).

0

of the second order polynomial classier is [n(n + 1)=2] + 1. In general, the number

of adjustable parameters of a q

order polynomial is of the order of N  n

.

th

q

The GP algorithm has been tested on the problem of handwritten digit recognition

(table 1.2). The input patterns consist of 16  16 pixel images (n = 256). The

results achieved with polynomial classiers of order q are summarized in table 1.2.

Also listed is the number of adjustable parameters, N . This quantity increases

rapidly with q and quickly reaches a level that is computationally intractable for

algorithms that explicitly compute each parameter [5]. Moreover, as N increases,

the learning problem becomes grossly underdetermined: the number of training

patterns (p = 600 for DB1 and p = 7300 for DB2) becomes very small compared

to N . Nevertheless, good generalization is achieved as shown by the experimental

results listed in the table. This is a consequence of the inherent regularization of

the algorithm.

An important concern is the sensitivity of the maximum margin solution to the

presence of outliers in the training data. It is indeed important to remove undesired

outliers (such as meaningless or mislabeled patterns) to get best generalization

performance. Conversely, \good" outliers (such as examples of rare styles) must be

kept. Cleaning techniques have been developed based on the re-examination by a

human supervisor of those supporting patterns which result in the largest increase

of the margin when removed and thus are the most likely candidates for outliers [3].

In our experiments on DB2 with linear classiers, the error rate on the test set

dropped from 15:2% to 10:5% after cleaning the training data (not the test data).

q

N

error <m>

error <m>

DB1 (p=600) DB2 (p=2300)

1 (linear)

256

3.2 %

36

10.5 %

97

2

3  10

1.5 %

44

5.8 %

89

4

3

8  10

1.7 %

50

5.2 %

79

7

4

4  10

4.9 %

72

9

5

1  10

5.2 %

69

12

Table 1: Handwritten digit recognition experiments. The rst database

(DB1) consists of 1200 clean images recorded from ten sub jects. Half of this data

is used for training, and the other half is used to evaluate the generalization per-

formance. The other database (DB2) consists of 7300 images for training and 2000

for testing and has been recorded from actual mail pieces. We use ten polynomial

classication functions of order q, separating one class against all others. We list the

number N of adjustable parameters, the error rates on the test set and the average

number <m>of supporting patterns per separating hypersurface. The results com-

pare favorably to neural network classiers which minimize the mean squared error

with backpropagation. For the one layer network (linear classier),the error on the

test set is 12.7 % on DB1 and larger than 25 % on DB2. The lowest error rate

for DB2, 4.9 %, obtained with a forth order polynomial is comparable to the 5.1 %

error obtained with a multi-layer neural network with sophisticated architecture

being trained and tested on the same data.

2 ALGORITHM DESIGN

The properties of the GP algorithm arise from merging two separate concepts de-

scribed in this section: Training in dual space, and minimizing the maximum loss.

For large VC-dimension classiers (N  p), the rst idea reduces the number of

eective parameters to be actually computed from N to p. The second idea reduces

it from p to m.

2.1 DUALITY

We seek a decision function for pattern vectors x of dimension n belonging to either

of two classes A and B. The input to the training algorithm is a set of p examples

x

with labels y

:

i

i

(x

; y

); (x

; y

); (x

; y

); . . . ; (x

; y

)

(3)

1

1

2

2

3

3

p

p



where

y

= 1

if x

2 class A

k

k

y

= 1 if x

2 class B:

k

k

From these training examples the algorithm nds the parameters of the decision

function D(x) during a learning phase. After training, the classication of unknown

patterns is predicted according to the following rule:

x 2 A if D(x) > 0

x 2 B otherwise.

(4)

We limit ourselves to classiers linear in their parameters, but not restricted to

linear dependences in their input components, such as Perceptrons and kernel-based

classiers. Perceptrons [5] have a decision function dened as:

D(x) = w  '(x) + b =

w

'

(x) + b;

(5)

i

i

i=1

N

X

where the '

are predened functions of x, and the w

and b are the adjustable

i

i

parameters of the decision function. This denition encompasses that of polynomial

classiers. In that particular case, the '

are products of components of vector x(see

i

equation 2). Kernel-based classiers, have a decision function dened as:

p

X

D(x) =



K (x

; x) + b;

(6)

k

k

k=1

The coecients

and the bias b are the parameters to be adjusted and the x

k

k

are the training patterns. The function K is a predened kernel, for example a

potential function [6] or any Radial Basis Function (see for instance [7]).

Perceptrons and RBFs are often considered two very distinct approaches to classi-

cation. However, for a number of training algorithms, the resulting decision function

can be cast either in the form of equation (5) or (6). This has been pointed out

in the literature for the Perceptron and potential function algorithms [6], for the

polynomial classiers trained with pseudo-inverse [8] and more recently for regular-

ization algorithms and RBF's [7]. In those cases, Perceptrons and RBFs constitute

dual representations of the same decision function.

The duality principle can be understood simply in the case of Hebb's learning rule.

The weight vector of a linear Perceptron ('

(x) = x

), trained with Hebb's rule, is

i

i

simply the average of all training patterns x

, multiplied by their class membership

polarity y

:

k

k

p

X

1

w =

y

x

:

k

k

p

k=1

Substituting this solution into equation (5), we obtain the dual representation

D(x) = w  x + b =

y

x

 x + b :

k

k

p

X

1

p

k=1

0

0

The corresponding kernel classier has kernel K (x; x

) = x  x

and the dual param-

eters

are equal to (1=p)y

.

k

k

In general, a training algorithm for Perceptron classiers admits a dual kernel rep-

resentation if its solution is a linear combination of the training patterns in '-space:

p

X

w =



'(x

) :

(7)

k

k

k=1

Reciprocally, a kernel classier admits a dual Perceptron representation if the kernel

function possesses a nite (or innite) expansion of the form:

X

0

0

K (x; x

) =

'

(x) '

(x

) :

(8)

i

i

i

Such is the case for instance for some symmetric kernels [9]. Examples of kernels

that we have been using include

K (x; x

) = (x  x

+ 1)

(polynomial expansion of order q);

0

0

q

K (x; x

) = tanh (
x  x

)

(neural units);

0

0

K (x; x

) = exp (
x  x

)  1

(exponential expansion);

0

0

0

0

2





K (x; x

) = exp

kx  x

k

=

(gaussian RBF);

K (x; x

) = exp (kx  x

k=
)

(exponential RBF);

0

0

K (x; x

) = (x  x

+ 1)

exp (kx  x

k=
)

(mixed polynomial and RBF):

0

0

0

q

These kernels have positive parameters (the integer q or the real number
) which

can be determined with a Structural Risk Minimization or Cross-Validation proce-

dure (see for instance [2]). More elaborate kernels incorporating known invariances

of the data could be used also.

(9)

The GP algorithm computes the maximum margin solution in the kernel representa-

tion. This is crucial for making the computation tractable when training very large

VC-dimension classiers. Training a classier in the kernel representation is compu-

tationally advantageous when the dimension N of vectors w (or the VC-dimension

N + 1) is large compared to the number of parameters

, which equals the number

k

of training patterns p. This is always true if the kernel function possesses an innite

expansions (8). The experimental results listed in table `refresults indicate that this

argument holds in practice even for low order polynomial expansions.

2.2 MINIMIZING THE MAXIMUM LOSS

The margin, dened as the Euclidean distance between the decision boundary and

the closest training patterns in '-space can be computed as

M = min

:

(10)

y

D(x

)

k

k

k

kwk

The goal of the maximum margin training algorithm is to nd the decision function

D(x) which maximizes M , that is the solution of the optimization problem

max

min

:

y

D(x

)

k

k

w

k

kwk

The solution w os this problem depends only on those patterns which are on the

margin, i.e. the ones that are closest to the decision boundary, called supporting

patterns. It can be shown that w can indeed be represented as a linear combination

of the supporting patterns in '-space.

In the classical framework of loss minimization, problem 2.2 is equivalent to mini-

mizing (over w) the maximum loss. The loss function is dened as

l(x

) = y

D(x

)=kwk:

k

k

k

This \minimax" approach contrasts with training algorithms which minimize the

average loss. For example, backpropagation minimizes the mean squared error

(MSE), which is the average of

l(x

) = (D(x

)  y

)

:

k

k

k

2

The benet of minimax algorithms is that the solution is a function only of a

restricted number of training patterns, namely the supporting patterns. This results

in high computational eciency in those cases when the number m of supporting

patterns is small compared to both the total number of training patterns p and the

dimension N of '-space.

2.3 THE GENERALIZED PORTRAIT

The GP algorithm consists in formulating the problem 2.2 in the dual -space as

the quadratic programming problem of maximizing the cost function

p

X

1

J (; b) =



(1  by

) 

 H  ;

k

k

k=1

2

under the constrains

> 0 [4, 2]. The p  p square matrix H has elements:

k

H

= y

y

K (x

; x

):

kl

k

l

k

l

where K (x; x

) is a kernel, such as the ones proposed in (9), which can be expanded

0

as in (8). K (x; x

) is not restricted to the dot product K (x; x

) = x  x

as in the

0

0

0

original formulation of the GP algorithm [2]).

In order for a unique solution to exist, H must be positive denite. The bias b can

be either xed or optimized together with the parameters

. This case introduces

P

k

another set of constraints:

y



= 0 [4].

k

k

k

The quadratic programming problem thus dened can be solved eciently by stan-

dard numerical methods [10]. Numerical computation can be further reduced by

processing iteratively small chunks of data [2]. The computational time is linear the

dimension n of x-space (not the dimension N of '-space) and in the number p of

training examples and polynomial in the number m < min(N + 1; p) of supporting

patterns. It can be theoretically proven that it is a polynomial in m of order lower

than 10, but experimentally an order 2 was observed.

Only the supporting patterns appear in the solution with non-zero weight

:

k



D(x) =

y



K (x

; x) + b;



 0;

k

k

k

k

X





k



= w

 '(x) + b

X





w

=

y



'(x

):

k

k

k

k

Using the kernel representation, with a factorized kernel (such as 9), the classica-

tion time is linear in n (not N ) and in m (not p).

3 CONCLUSIONS

We presented an algorithm to train polynomial classiers of high order and Radial

Basis functions which has remarquable computational and generalization perfor-

mances. The algorithms seeks the solution with the largest possible margin on both

side of the decision boundary. The properties of the algorithm arise from the fact

that the solution is a function only of a small number of supporting patterns, namely

those training examples that are closest to the decision boundary. The generaliza-

tion error of the maximum margin classier is bounded by the ratio of the number

of linearly independent supporting patterns and the number of training examples.

This bound is tighter than a bound based on the VC-dimension of the classier

family. For further improvement of the generalization error, outliers corresponding

to supporting patterns with large

can be eliminated automatically or with the

k

assistance of a supervisor. This feature suggests other interesting applications of

the maximum margin algorithm for database cleaning.

Acknowledgements

We wish to thank our colleagues at UC Berkeley and AT&T Bell Laboratories for

many suggestions and stimulating discussions. Comments by L. Bottou, C. Cortes,

S. Sanders, S. Solla, A. Zakhor, are gratefully acknowledged. We are especially in-

debted to R. Baldick and D. Hochbaum for investigating the polynomial convergence

property, S. Hein for providing the code for constrained nonlinear optimization, and

D. Haussler and M. Warmuth for help and advice regarding performance bounds.

