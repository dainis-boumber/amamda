AbstractStatistical learning theory was introduced in the late
1960s. Until the 1990s it was a purely theoretical analysis of the
problem of function estimation from a given collection of data.
In the middle of the 1990s new types of learning algorithms
(called support vector machines) based on the developed theory
were proposed. This made statistical learning theory not only
a tool for the theoretical analysis but also a tool for creating
practical algorithms for estimating multidimensional functions.
This article presents a very general overview of statistical learning
theory including both theoretical and algorithmic aspects of the
theory. The goal of this overview is to demonstrate how the
abstract learning theory established conditions for generalization
which are more general than those discussed in classical statis-
tical paradigms and how the understanding of these conditions
inspired new algorithmic approaches to function estimation prob-
lems. A more detailed overview of the theory (without proofs) can
be found in Vapnik (1995). In Vapnik (1998) one can nd detailed
description of the theory (including proofs).

I. SETTING OF THE LEARNING PROBLEM

IN this section we consider a model of the learning and show

that analysis of this model can be conducted in the general
statistical framework of minimizing expected loss using ob-
served data. We show that practical problems such as pattern
recognition, regression estimation, and density estimation are
particular case of this general model.

A. Function Estimation Model

The model of learning from examples can be described

using three components:

1) a generator of random vectors

, drawn independently

from a xed but unknown distribution

;

2) a supervisor that returns an output vector

for every
, according to a conditional distribution

input vector
function1

, also xed but unknown;

3) a learning machine capable of implementing a set of

functions

.

The problem of learning is that of choosing from the given
the one which predicts the
set of functions
supervisors response in the best possible way. The selection
random independent identically
is based on a training set of
distributed (i.i.d.) observations drawn according to

B. Problem of Risk Minimization

In order to choose the best available approximation to the
supervisors response, one measures the loss or discrepancy
of the supervisor to
provided by the
a given input
learning machine. Consider the expected value of the loss,
given by the risk functional

between the response

and the response

(2)

The goal

mizes the risk functional

is to nd the function

which mini-
(over the class of functions
in the situation where the joint probabil-
is unknown and the only available

ity distribution
information is contained in the training set (1).

C. Three Main Learning Problems

This formulation of the learning problem is rather general.
It encompasses many specic problems. Below we consider
the main ones: the problems of pattern recognition, regression
estimation, and density estimation.

output

take on only two values

The Problem of Pattern Recognition: Let

the supervisors
and let
be a set of indicator functions (functions
which take on only two values zero and one). Consider the
following loss-function:

if
if

(3)

For this loss function, the functional (2) provides the proba-
given
bility of classication error (i.e., when the answers
by supervisor and the answers given by indicator function
differ). The problem, therefore, is to nd the function
which minimizes the probability of classication errors when
is unknown, but the data (1) are
probability measure
given.

The Problem of Regression Estimation: Let

the

sors answer
set of real functions which contains the regression function

be a real value, and let

supervi-
be a

(1)

It is known that if
then the regression function
is the one which minimizes the functional (2) with the the
following loss-function:

Manuscript received January 11, 1999; revised May 20, 1999.
The author is with AT&T Labs-Research, Red Bank, NJ 07701 USA.
Publisher Item Identier S 1045-9227(99)07267-7.
1 This is the general case which includes a case where the supervisor uses

a function y = f (x):

Thus the problem of regression estimation is the problem
of minimizing the risk functional (2) with the loss function

(4)

10459227/99$10.00 

1999 IEEE

VAPNIK: OVERVIEW OF STATISTICAL LEARNING THEORY

989

(4) in the situation where the probability measure
unknown but the data (1) are given.

is

E. Empirical Risk Minimization Principle
and the Classical Methods

The Problem of Density Estimation: Finally, consider the
problem of density estimation from the set of densities
For this problem we consider the following

loss-function:

(5)

It is known that desired density minimizes the risk functional
(2) with the loss-function (5). Thus, again, to estimate the
density from the data one has to minimize the risk-functional
under the condition where the corresponding probability mea-
sure

is unknown but i.i.d. data

The ERM principle is quite general. The classical methods
for solving a specic learning problem, such as the least
squares method in the problem of regression estimation or
the maximum likelihood method in the problem of density
estimation are realizations of the ERM principle for the
specic loss functions considered above.

Indeed,

in order to specify the regression problem one

introduces an

-dimensional variable

and uses loss function (4). Using this loss

function in the functional (8) yelds the functional

which one needs to minimize in order to nd the regression
estimate (i.e., the least square method).

In order to estimate a density function from a given set of
one uses the loss function (5). Putting this
functions
loss function into (8) one obtains the maximum likelihood
method: the functional

which one needs to minimize in order to nd the approxima-
tion to the density.

Since the ERM principle is a general formulation of these
classical estimation problems, any theory concerning the ERM
principle applies to the classical methods as well.

F. Four Parts of Learning Theory

Learning theory has to address the following four questions.
1) What are the conditions for consistency of the ERM

principle?

To answer this question one has to specify the neces-
sary and sufcient conditions for convergence in proba-
bility2 of the following sequences of the random values.

a)

The values of risks
minimal possible value of the risk

converging to the
[where
are the expected risks for
each minimizing the empirical

(9)

obtained

empirical

risks
converging to the

are given.

The General Setting of the Learning Problem: The general
setting of the learning problem can be described as follows.
Let the probability measure
Consider the set of functions
minimize the risk functional

be dened on the space

The goal is: to

(6)

if probability measure

is unknown but an i.i.d. sample

(7)

is given.

The learning problems considered above are particular cases
of this general problem of minimizing the risk functional (6) on
the basis of empirical data (7), where
and
is the specic loss function [for example, one
of (3), (4), or (5)]. Below we will describe results obtained
for the general statement of the problem. To apply it for
specic problems one has to substitute the corresponding loss-
functions in the formulas obtained.

describes a pair

D. Empirical Risk Minimization Induction Principle

In order to minimize the risk functional (6), for an unknown
the following induction principle is

probability measure
usually used.

The expected risk functional

is replaced by the

empirical risk functional

functions
risk

b) The

values

of

minimal possible value of the risk

(8)

(10)

constructed on the basis of the training set (7).

The principle is to approximate the function

which
which minimizes
minimizes risk (6) by the function
empirical risk (8). This principle is called the empirical risk
minimization induction principle (ERM principle).

2 Convergence in probability of values R(`) means that for any " > 0
and for any  > 0 there exists a number `0 = `0("; ) such, that for any
` > `0 with probability at least 1   the inequality

R(`)  R(0) < "

holds true.

990

IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 10, NO. 5, SEPTEMBER 1999

Equation (9) shows that solutions found using ERM
converge to the best possible one. Equation (10) shows
that values of empirical risk converge to the value of
the smallest risk.

2) How fast does the sequence of smallest empirical risk
values converge to the smallest actual risk? In other
words what is the rate of generalization of a learning
machine that implements the empirical risk minimization
principle?

3) How can one control the rate of convergence (the rate of

generalization) of the learning machine?

4) How can one construct algorithms that can control the

This type of convergence is called uniform one-sided conver-
gence.

In other words, according to the Key theorem the conditions
for consistency of the ERM principle are equivalent to the
conditions for existence of uniform one-sided convergence
(11).

This theorem is called the Key theorem because it asserts
that any analysis of the convergence properties of the ERM
principle must be a worst case analysis. The necessary condi-
tion for consistency (not only the sufcient condition) depends
on whether or not the deviation for the worst function over
the given set of of functions

rate of generalization?

The answers to these questions form the four parts of

learning theory:

1) the theory of consistency of learning processes;
2) the nonasymptotic theory of the rate of convergence of

learning processes;

3) the theory of controlling the generalization of learning

processes;

4) the theory of constructing learning algorithms.

II. THE THEORY OF CONSISTENCY OF LEARNING PROCESSES
The theory of consistency is an asymptotic theory. It de-
scribes the necessary and sufcient conditions for convergence
of the solutions obtained using the proposed method to the
best possible as the number of observations is increased. The
question arises:

Why do we need a theory of consistency if our goal is to

construct algorithms for a small (nite) sample size?

The answer is:
We need a theory of consistency because it provides not
only sufcient but necessary conditions for convergence of
the empirical risk minimization inductive principle. Therefore
any theory of the empirical risk minimization principle must
satisfy the necessary and sufcient conditions.

In this section, we introduce the main capacity concept (the
so-called VapnikCervonenkis (VC) entropy which denes
the generalization ability of the ERM principle. In the next
sections we show that the nonasymptotic theory of learning is
based on different types of bounds that evaluate this concept
for a xed amount of observations.

A. The Key Theorem of the Learning Theory

The key theorem of the theory concerning the ERM-based

learning processesis the following [27].

The Key Theorem: Let

be a set of functions

that has a bounded loss for probability measure

converges in probability to zero.

From this theorem it follows that the analysis of the ERM
principle requires an analysis of the properties of uniform
convergence of the expectations to their probabilities over the
given set of functions.

B. The Necessary and Sufcient Conditions
for Uniform Convergence

To describe the necessary and sufcient condition for uni-
form convergence (11), we introduce a concept called the
on the sample
entropy of the set of functions
of size

We introduce this concept in two steps: rst for sets of
indicator functions and then for sets of real-valued functions.

Entropy of the Set of Indicator Functions: Let

be a set of indicator functions, that is the functions
which take on only the values zero or one. Consider a sample

(12)

Let us characterize the diversity of this set of functions
on the given sample by a quantity
the number of different
separations of this sample that can be obtained using functions
from the given set of indicator functions.

represents

that

Let us write this in another form. Consider the set of

-dimensional binary vectors

takes various values from

Then
that one obtains when
is the number of dif-
geometrically speaking
ferent vertices of the -dimensional cube that can be obtained
and the set of functions
on the basis of the sample

Let us call the value

Then for the ERM principle to be consistent it is necessary and
converge uniformly
sufcient that the empirical risk
as follows:
to the actual risk

over the set

(11)

the random entropy. The random entropy describes the diver-
sity of the set of functions on the given data.
is a random variable since it was constructed using random
i.i.d. data. Now we consider the expectation of the random
entropy over the joint distribution function

VAPNIK: OVERVIEW OF STATISTICAL LEARNING THEORY

991

on samples of size

We call
,
functions
the set of functions

this quantity the entropy of the set of indicator
It depends on
, the probability measure
, and the number of observations The entropy describes
the expected diversity of the given set of indicator functions
on the sample of size

,

The main result of the theory of consistency for the pat-
tern recognition problem (the consistency for indicator loss
function) is the following theorem [24].

Theorem: For uniform two-sided convergence of the fre-

quencies to their probabilities3

it is necessary and sufcient that the equality

(13)

(14)

hold.

Slightly modifying the condition (14) one can obtain the
necessary and sufcient condition for one-sided uniform con-
vergence (11).

Entropy of the Set of Real Functions: Now we generalize
the concept of entropy for sets of real-valued functions. Let
be a set of bounded loss functions.
Using this set of functions and the training set (12) one
-dimensional real-valued
can construct the following set of
vectors

(15)

This set of vectors belongs to the -dimensional cube with
Let
the edge
be the number of elements of the

and has a nite -net4 in the metric

minimal

-net of the set of vectors

The logarithm of the (random) value

is called the random VC-entropy5 of the set of functions
The expectation

on the sample

of the random VC-entropy

is called the VC-entropy of the set of functions

on the sample of the size

Here expectation

3 The sets of indicator functions R() denes probability and Remp()

denes frequency.

4 The set of vectors q();  2  has minimal "-net q(1);    ; q(N )
if: 1. There exist N = N ("; z1;    ; z`) vectors q(1);    ; q(N ); such
that for any vector q();  2  one can nd among these N vectors one
q(r) which is "-close to this vector (in a given metric). For a C metric that
means

(q(); q(r)) = max
1i`

jQ(zi)  Q(zi; r)j  ":

N is minimal number of vectors which possess this property.

5 Note that VC-entropy is different from classical metrical "-entropy

H 

cl(") = ln N (")

where N (") is cardinality of the minimal "-net of the set of functions
Q(z; );  2 :

is taken with respect to product-measure

The main results of the theory of uniform convergence of the
empirical risk to actual risk for bounded loss function includes
the following theorem [24].

Theorem: For uniform two-sided convergence of the em-

pirical risks to the actual risks

it is necessary and sufcient that the equality

(16)

(17)

be valid.

Slightly modifying the condition (17) one can obtain the
necessary and sufcient condition for one-sided uniform con-
vergence (11).

According to the key assertion this implies the necessary and

sufcient conditions for consistency of the ERM principle.

C. Three Milestones in Learning Theory

In this section, for simplicity, we consider a set of indicator
(i.e., we consider the problem of
functions
pattern recognition). The results obtained for sets of indicator
functions can be generalized for sets of real-valued functions.
In the previous section we introduced the entropy for sets

of indicator functions

Now, we consider two new functions that are constructed
the annealed VC-
on the basis of the values
entropy

and the growth function

These functions are determined in such a way that for any
the inequalities

are valid. On the basis of these functions, the three main
milestones in statistical learning theory are constructed.

In the previous section, we introduced the equation

describing the necessary and sufcient condition for consis-
tency of the ERM principle. This equation is the rst milestone
in learning theory: any machine minimizing empirical risk
should satisfy it.

However,

convergence of obtained risks

this equation says nothing about

the rate of
to the minimal one
It is possible that the ERM principle is consistent but

has arbitrary slow asymptotic rate of convergence.

992

IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 10, NO. 5, SEPTEMBER 1999

The question is:
Under what conditions is the asymptotic rate of convergence

fast?

We say that the asymptotic rate of convergence is fast if for

any

the exponential bound

A. The Structure of the Growth Function

Theorem: Any growth function either satises the equality

or is bounded by the inequality

holds true, where

The equation

is some constant.

where

is an integer for which

describes the sufcient condition for fast convergence.6 It is the
second milestone in statistical learning theory: it guarantees a
fast asymptotic rate of convergence.

Note that both the equation describing the necessary and
sufcient condition for consistency and the one that describes
the sufcient condition for fast convergence of the ERM
(both
method are valid for a given probability measure
are con-
VC-entropy
structed using this measure). However our goal is to construct
a learning machine for solving many different problems (i.e.,
for many different probability measures).

and VC-annealed entropy

The question is:
Under what conditions is the ERM principle consistent and
rapidly converging, independently of the probability measure?
The following equation describes the necessary and suf-
cient conditions for consistency of ERM for any probability
measure

This condition is also sufcient for fast convergence.

This equation is the third milestone in statistical learning
theory. It describes the conditions under which the learning
machine implementing ERM principle has an asymptotic high
rate of convergence independently of the problem to be solved.
These milestones form a foundation for constructing both
distribution independent bounds and rigorous distribution de-
pendent bounds for the rate of convergence of learning ma-
chines.

III. BOUNDS ON THE RATE OF CONVERGENCE

OF THE LEARNING PROCESSES

In order to estimate the quality of the ERM method for
a given sample size it is necessary to obtain nonasymptotic
bounds on the rate of uniform convergence.

A nonasymptotic bound of the rate of convergence can
be obtained using a new capacity concept, called the VC
dimension, which allows us to obtain a constructive bound
for the growth function.

The concept of VC-dimension is based on a remarkable

property of the growth-function

.

6 The necessity of this condition for fast convergence is open question.

In other words the growth function will be either a linear
function or will be bounded by a logarithmic function. (For
example, it cannot be of the form

We say that

the VC dimension of the set of indicator
is innite if the Growth function

functions
for this set of functions is linear.

We say that

the VC dimension of the set of indicator
if the growth
functions
function is bounded by a logarithmic function with coefcient

is nite and equals

The niteness of the VC-dimension of the set of indicator
functions implemented by the learning machine forms the
necessary and sufcient condition for consistency of the ERM
method independent of probability measure. Finiteness of VC-
dimension also implies fast convergence.

B. Equivalent Denition of the VC Dimension

In this section, we give an equivalent denition of the VC
dimension of sets of indicator functions and then we generalize
this denition for sets of real-valued functions.

The VC Dimension of a Set of Indicator Functions: The

VC-dimension of a set of indicator functions
is the maximum number
be separated in all
set7 (shattered by this set of functions). If for any
exists a set of

which can
possible ways using functions of this
there
vectors which can be shattered by the set

of vectors

then the VC-dimension is equal to innity.

The VC Dimension of a Set of Real-Valued Functions: Let
be a set of real-valued functions

bounded by constants
can approach

and

can approach

and

Let us consider along with the set of real-valued functions

the set of indicator functions

(18)

where

is some constant,

is the step function

if
if

The VC dimension of

the set of real valued functions
is dened to be the VC-dimension of the

set of indicator functions (18).

7 Any indicator function separates a set of vectors into two subsets: the
subset of vectors for which this function takes value zero and the subset of
vectors for which it takes value one.

VAPNIK: OVERVIEW OF STATISTICAL LEARNING THEORY

993

C. Two Important Examples

Example 1:
1) The VC-dimension of the set of linear indicator func-

tions

Case 1The Set of Totally Bounded Functions: Without

restriction in generality, we assume that

(19)

in -dimensional coordinate space
is
, since using functions of this set one
equal to
is the step
can shatter at most
function, which takes value one, if the expression in the
brackets is positive and takes value zero otherwise.

vectors. Here

2) The VC-dimension of the set of linear functions

is
because the VC-dimension of

in -dimensional coordinate space
also equal to
corresponding linear indicator functions is equal to
(using
indicator functions).

does not changes the set of

instead of

Example 2: We call a hyperplane

-margin separating hyperplane if it classies vectors

the
as follows:

if
if

(classications of vectors
are undened).

that fall into the margin

Theorem: Let vectors
. Then the set of

belong to a sphere of radius
-margin separating hyperplanes has the

VC dimension

bounded by the inequality

These examples show that in general the VC dimension
is
of the set of hyperplanes is equal
dimensionality of input space. However, the VC dimension
-margin separating hyperplanes (with a large
of the set of
This fact will play
value of margin
an important role for constructing new function estimation
methods.

can be less than

, where

to

D. Distribution Independent Bounds for the Rate of
Convergence of Learning Processes

The main result in the theory of bounds for sets of totally

bounded functions is the following [20][22].

Theorem: With probability at least

, the inequality

(20)

holds true simultaneously for all functions of the set (19),
where

(21)

For the set of indicator functions,
This theorem provides bounds for the risks of all func-
which
tions of the set (18) [including the function
minimizes empirical risk (8)]. The bounds follow from the
bound on uniform convergence (13) for sets of totally bounded
functions that have nite VC dimension.

Case 2The Set of Unbounded Functions: Consider

the

set of (nonnegative) unbounded functions

It

is easy to show (by constructing an example) that,
without additional information about the set of unbounded
functions and/or probability measures,
is impossible to
obtain an inequality of type (20). Below we use the following
information:

it

(22)

where

is some xed constant.8

The main result for the case of unbounded sets of loss

functions is the following [20][22].
Theorem: With probability at least

the inequality

(23)

holds true simultaneously for all functions of the set, where
is determined by (22),

The theorem bounds the risks for all functions of the set

(including the function

Consider sets of functions which possess a nite VC-

dimension We distinguish between two cases:

1) the case where the set of loss functions

is a set of totally bounded functions;

2) the case where the set of loss functions

is not necessarily a set of totally bounded functions.

8 This inequality describes some general properties of distribution functions
of the random variables 
= Q(z; ), generated by the P (z): It describes the
tails of distributions (the probability of big values for the random variables
): If the inequality (22) with p > 2 holds, then the distributions have so-
called light tails (large values do not occurs very often). In this case rapid
convergence is possible. If, however, (22) holds only for p < 2 (large values
of the random variables  occur rather often) then the rate of convergence
will be small (it will be arbitrarily small if p is sufciently close to one).

994

IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 10, NO. 5, SEPTEMBER 1999

E. Problem of Constructing Rigorous
(Distribution Dependent) Bounds

sample size).9 The goal
appropriate for a given sample size.

is to specify methods which are

To construct rigorous bounds for the rate of convergence
one has to take into account information about probability
be a set of all probability measures and let
measure. Let
We say that one has prior
if

information about an unknown probability measure
one knows the set of measures

be a subset of the set

that contains

Consider the following generalization of the growth func-

tion:

For indicator functions

and for the extreme

the generalized growth function

case where
coincides with the growth function
case where
growth function coincides with the annealed VC-entropy.

contains only one function

For another extreme
the generalized

The following assertion is true [20], [26].
Theorem: Suppose that a set of loss-functions is bounded

Then for sufciently large

the following inequality:

A. Structural Risk Minimization Induction Principle

The ERM principle is intended for dealing with a large
sample size. Indeed, the ERM principle can be justied by
is large, the second
considering the inequalities (20). When
summand on the right hand side of inequality (20) becomes
small. The actual risk is then close to the value of the empirical
risk. In this case, a small value of the empirical risk provides
a small value of (expected) risk.

However, if

is small, then even a small

does not guarantee a small value of risk. In this case the
requires a new principle, based on
minimization for
the simultaneous minimization of two terms in (20) one of
which depends on the value of the empirical risk while the
second depends on the VC-dimension of the set of functions.
To minimize risk in this case it is necessary to nd a method
which, along with minimizing the value of empirical risk,
controls the VC-dimension of the learning machine.

The following principle, which is called the principle of
structural risk minimization (SRM), is intended to minimize
the risk functional with respect to both empirical risk and
VC-dimension of the set of functions.

Let

the set of functions

a structure: so that
functions

be provided with
is composed of the nested subsets of

such that

(24)

holds true.

From this bound it follows that for sufciently large with
(including the
probability
one that minimizes the empirical risk) the following inequality
is valid:

simultaneously for all

and

An admissible structure is one satisfying the following three

properties.

1) The set
2) The VC-dimension

is everywhere dense in
of each set

of functions is

nite.

3) Any element

of the structure contains totally bounded

functions

vations

The SRM principle suggests that for a given set of obser-
, where
for which

and choose the particular function from

choose the element of structure

However,

this bound is nonconstructive because theory
does not specify a method to evaluate the generalized growth
function. To make this bound constructive and rigorous one
has to estimate the generalized growth function for a given
set of loss-functions and a given set of probability measures.
This is one of the main subjects of the current learning theory
research.

IV. THEORY FOR CONTROLLING THE

GENERALIZATION OF LEARNING MACHINES

The theory for controlling the generalization of a learning
machine is devoted to constructing an induction principle for
minimizing the risk functional which takes into account the
size of the training set (an induction principle for a small

the guaranteed risk (20) is minimal.

The SRM principle actually suggests a tradeoff between
the quality of the approximation and the complexity of the
increases, the minima of em-
approximating function. (As
pirical risk are decreased; however, the term responsible for
the condence interval [summand in (20)] is increased. The
SRM principle takes both factors into account.)

The main results of the theory of SRM are the following

[9], [22].

Theorem: For any distribution function the SRM method
provides convergence to the best possible solution with prob-
ability one.

In other words SRM method is universally strongly con-

sistent.

9 The sample size ` is considered to be small if `=h is small, say `=h < 20:

VAPNIK: OVERVIEW OF STATISTICAL LEARNING THEORY

995

Theorem: For admissible structures the method of structural
for
converge to the best

risk minimization provides approximations
which the sequence of risks
one

with asymptotic rate of convergence10

if the law

is such that

In (25)
the rate of approximation

is the bound for functions from

and

(25)

(26)

is

V. THEORY OF CONSTRUCTING LEARNING ALGORITHMS
To implement

the SRM induction principle in learning
algorithms one has to control two factors that exist in the
bound (20) which has to be minimized:

1) the value of empirical risk;
2) the capacity factor (to choose the element

appropriate value of VC dimension).

with the

Below we restrict ourselves to the pattern recognition case.

We consider two type of learning machines:
1) Neural networks (NNs) that were inspired by the bio-

logical analogy to the brain;

2) the support vector machines that were inspired by sta-

tistical learning theory.

We will discuss how each corresponding machine can

control these factors.

A. Methods of Separating Hyperplanes and
Their Generalization

Consider rst the problem of minimizing empirical risk on

the set of linear indicator functions

can nd the exact solution while when the minimum of this
functional is nonzero one can nd an approximate solution.
Therefore by constructing a separating hyperplane one can
control the value of empirical risk.

Unfortunately the set of separating hyperplanes is not ex-
ible enough to provide low empirical risk for many real-life
problems [13].

Two opportunities were considered to increase the exibility

of the sets of functions:

1) to use a richer set of indicator functions which are

superpositions of linear indicator functions;

2) to map the input vectors in high dimensional feature
-margin separating

space and construct in this space a
hyperplane (see Example 2 in Section III-C)

The rst idea corresponds to the neural network. The second

idea leads to support vector machines.

B. Sigmoid Approximation of Indicator
Functions and Neural Nets

To describe the idea behind the NN let us consider the
method of minimizing the functional (28). It is impossible
to use regular gradient-based methods of optimization to min-
imize this functional. (The gradient of the indicator function
is either equal to zero or is undened.) The solution
is to approximate the set of indicator functions (27) by so-
called sigmoid functions

(29)

where

is a smooth monotonic function such that

For example, the functions

are sigmoid functions.

For the set of sigmoid function, the empirical risk functional

Let

(27)

(30)

It has a gradient grad

and therefore
is smooth in
can be minimized using gradient-based methods. For example,
the gradient descent method uses the following update rule:

be a training set, where

is a vector,

To minimize the empirical risk one has to nd the pa-
(weights) which minimize the

rameters
empirical risk functional

where the data
number
a local minimum, it is enough that

depends on the iteration
For convergence of the gradient descent method to
satisfy the conditions

(28)

There are several methods for minimizing this functional. In
the case when the minimum of the empirical risk is zero one
10 We say that the random variables `; ` = 1; 2;    converge to the value

0 with asymptotic rate V (`) if there exists constant C such that

V 1(`)j`  0j !P

`!1 C:

Thus, the idea is to use the sigmoid approximation at the stage
of estimating the coefcients, and use the indicator functions
with these coefcients at the stage of recognition.

The generalization of this idea leads to feedforward NNs.
In order to increase the exibility of the set of decision rules

996

IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 10, NO. 5, SEPTEMBER 1999

of the learning machine one considers a set of functions
which are the superposition of several linear indicator func-
tions (networks of neurons) [13] instead of the set of linear
indicator functions (single neuron). All indicator functions in
this superposition are replaced by sigmoid functions.

A method for calculating the gradient of the empirical risk
for the sigmoid approximation of NNs, called the backprop-
agation method, was found [15], [12]. Using this gradient
descent method, one can determine the corresponding coef-
cient values (weights) of all elements of the NN.

In the 1990s, it was proven that the VC dimension of NNs
depends on the type of sigmoid functions and the number of
weights in the NN. Under some general conditions the VC
dimension of the NN is bounded (although it is sufciently
large). Suppose that the VC dimension does not change during
the NN training procedure, then the generalization ability of
NN depends on how well the NN minimizes the empirical risk
using sufciently large training data.

The three main problems encountered when minimizating
the empirical risk using the backpropagation method are as
follows.

1) The empirical risk functional has many local minima.
Optimization procedures guarantee convergence to some
local minimum. In general the function which is found
using the gradient-based procedure can be far from the
best one. The quality of the obtained approximation
depends on many factors, in particular on the initial
parameter values of the algorithm.

2) Convergence to a local minimum can be rather slow (due

to the high dimensionality of the weight-space).

3) The sigmoid function has a scaling factor which affects
the quality of the approximation. To choose the scaling
factor one has to make a tradeoff between quality of
approximation and the rate of convergence.

Therefore, a good minimization of the empirical risk de-

pends in many respects on the art of the researcher.

C. The Optimal Separating Hyperplanes

To introduce the method which is an alternative to the NN

let us consider the optimal separating hyperplanes [25].

Suppose the training data

can be separated by a hyperplane

(31)

We say that this set of vectors is separated by the optimal hy-
perplane (or the maximal margin hyperplane) if it is separated
without error and the distance between the closest vector and
the hyperplane is maximal.

To describe the separating hyperplane let us use the follow-

ing form:

if

if

In the following we use a compact notation for these inequal-
ities:

(32)

It is easy to check that the Optimal hyperplane is the one that
satises the conditions (32) and minimizes functional

(The minimization is taken with respect to both vector
scalar

)

(33)

and

The solution to this optimization problem is given by the

saddle point of the Lagrange functional (Lagrangian)

(34)

where the
be minimized with respect to
to

are Lagrange multipliers. The Lagrangian has to
and maximized with respect

In the saddle point, the solutions

and

should

satisfy the conditions

Rewriting these equations in explicit form one obtains the
following properties of the optimal hyperplane.

1) The coefcients

for the optimal hyperplane should

satisfy the constraints

(35)

2) The parameters of the optimal hyperplane (vector

)
are linear combination of the vectors of the training set.

(36)

3) The solution must satisfy the following KuhnTucker

conditions:

(37)

From these conditions it follows that only some training
vectors in expansion (36), the support vectors, can have
The
nonzero coefcients
support vectors are the vectors for which, in (36), the
equality is achieved. Therefore we obtain

in the expansion of

(38)

Substituting the expression for

back into the Lagrangian
the KuhnTucker conditions, one

and taking into account
obtains the functional

It remains to maximize this functional in the nonnegative
quadrant

(39)

VAPNIK: OVERVIEW OF STATISTICAL LEARNING THEORY

997

under the constraint

(40)

Putting the expression for
as an expansion on support vectors

in (31) we obtain the hyperplane

(41)

To construct

the optimal hyperplane in the case when
the data are linearly nonseparable, we introduce nonnegative
variables

and the functional

The problem then arises of how to computationally deal
with such high-dimensional spaces: to construct a polynomial
of degree 4 or 5 in a 200-dimensional space it is necessary to
construct hyperplanes in a billion-dimensional feature space.
In 1992, it was noted [5] that for both describing the optimal
separating hyperplane in the feature space (41) and estimating
the corresponding coefcients of expansion of the separating
hyperplane (39) one uses the inner product of two vectors
, which are images in the feature space of the
Therefore if one can estimate the
and

input vectors
inner product of two vectors in the feature space
as a function of two variables in input space

and

and

which we will minimize subject to constraints

Using the same formalism with Lagrange multipliers one
can show that the optimal hyperplane also has an expansion
can be found by
(41) on support vectors. The coefcients
maximizing the same quadratic form as in the separable case
(39) under slightly different constraints

than it will be possible to construct the solutions which are
equivalent to the optimal hyperplane in the feature space. To
get this solution one only needs to replace the inner product

in (39) and (41) with the function

In other words, one constructs nonlinear decision functions

in the input space

(43)

that are equivalent to the linear decision functions (33) in the
in (43) are dened by solving
feature space. The coefcients
the equation

(42)

(44)

D. The Support Vector Network

The support-vector network implements the following idea
[21]: Map the input vectors into a very high-dimensional fea-
through some nonlinear mapping chosen a priori.
ture space
In this space comstruct an optimal separating hyperplane. The
goal is to create the situation described in Example 2 of
-margin separating hyperplanes the
Section III-C, where for
To generalize
VC dimension is dened by the ratio
well, we control (decrease) the VC dimension by constructing
an optimal separating hyperplane (that maximizes the margin).
To increase the margin we use very high dimensional spaces.
Example: Consider a maping that allows us to construct
decision polynomials in the input space. To construct a poly-
nomial of degree two, one can create a feature space which
has

coordinates of the form

coordinates
coordinates

coordinates

The separating hyperplane con-
where
structed in this space is a separating second-degree polynomial
in the input space.

To construct a polynomial of degree

input space one has to construct
space, where one then constructs the optimal hyperplane.

in an -dimensional
-dimensional feature

under constraints (42).

In 1909 Mercer proved a theorem which denes the general

form of inner products in Hilbert spaces.

Theorem: The general form of the inner product in Hilbert
space is dened by the symmetric positive denite function

that satises the condition

for all functions

satisfying the inequality

Therefore any function

satisfying Mercers condi-
tion can be used for constructing rule (43) which is equivalent
to constructing an optimal separating hyperplane in some
feature space.

The learning machines which construct decision functions of
the type (43) are called support vectors networks or support
vector machines (SVMs).11

Using different expressions for inner products

one
can construct different learning machines with arbitrary types
of (nonlinear in input space) decision surfaces.

11 This name stresses that for constructing this type of machine, the idea
of expanding the solution on support vectors is crucial. In the SVM the
complexity of construction depends on the number of support vectors rather
than on the dimensionality of the feature space.

998

IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 10, NO. 5, SEPTEMBER 1999

For example to specify polynomials of any xed order

one can use the following functions for the inner product in
the corresponding feature space:

Radial basis function machines with decision functions of the
form

can be implemented by using a function of the type

In this case the SVM machine will nd both the centers
and the corresponding weights

The SVM possesses some useful properties.
 The optimization problem for constructing an SVM has

a unique solution.

training data), the condence interval
will be large.
In this case, even if one could minimize the empirical risk
down to zero, the amount of errors on the test set could be
big. This case is called overtting.

To avoid over tting (to get a small condence interval) one

has to construct networks with small VC-dimension.

Therefore to generalize well using an NN one must rst
suggest an appropriate architecture of the NN and second nd
in this network the function that minimizes the number of
errors on the training data. For NNs both of these prob-
lems are solving using some heuristics (see remarks on the
backpropagation method).

In support vector methods one can control both parameters:
in the separable case one obtains the unique solution which
-margin
minimizes the empirical risk (down to zero) using a
separating hyperplane with the maximal margin (i.e., subset
with the smallest VC dimension).

In the general case one obtains the unique solution when

one chooses the value of the trade off parameter

 The learning process for constructing an SVM is rather

VI. CONCLUSION

fast.

 Simultaneously with constructing the decision rule, one

obtains the set of support vectors.

 Implementation of a new set of decision functions can be

done by changing only one function (kernel
which denes the dot product in

-space.

E. Why Can Neural Networks and Support
Vectors Networks generalize?

The generalization ability of both the NNs and support
vectors networks is based on the factors described in the theory
for controlling the generalization of the learning processes. Ac-
cording to this theory, to guarantee a high rate of generalization
of the learning machine one has to construct a structure

and
on the set of decision functions
of the structure
then choose both an appropriate element
that
and a function
minimizes bound (20). The bound (16) can be rewritten in
the simple form

within this element

(45)

where the rst term is an estimate of the risk and the second
is the condence interval for this estimate.

In designing an NN, one determines a set of admissible

functions with some VC-dimension
of training data the value

determines the condence interval
for the network. Choosing the appropriate element of
a structure is therefore a problem of designing the network for
a given training set.

For a given amount

During the learning process this network minimizes the rst
term in the bound (45) (the number of errors on the training
set).

If it happens that at the stage of designing the network one
constructs a network too complex (for the given amount of

This article presents a very general overview of statistical
learning theory. It demonstrates how an abstract analysis
allows us to discover a general model of generalization.

According to this model, the generalization ability of learn-
ing machines depends on capacity concepts which are more
sophisticated than merely the dimensionality of the space or
the number of free parameters of the loss function (these con-
cepts are the basis for the classical paradigm of generalization).
The new understanding of the mechanisms behind gen-
eralization not only changes the theoretical foundation of
generalization (for example from the new point of view the
Occam razor principle is not always correct), but also changes
the algorithmic approaches to function estimation problems.
The approach described is rather general. It can be applied
for various function estimation problems including regression,
density estimation, solving inverse equations and so on.

Statistical learning theory started more than 30 years ago.
The development of this theory did not involve many re-
searchers. After the success of the SVM in solving real-life
problems, the interest in statistical learning theory signicantly
increased. For the rst time, abstract mathematical results in
statistical learning theory have a direct impact on algorithmic
tools of data analysis. In the last three years a lot of articles
have appeared that analyze the theory of inference and the
SVM method from different perspectives. These include:

1) obtaining better constructive bounds than the classical
one described in this article (which are closer in spirit to
the nonconstructive bound based on the growth function
than on bounds based on the VC dimension concept).
Success in this direction could lead, in particular, to
creating machines that generalize better than the SVM
based on the concept of optimal hyperplane;

2) extending the SVM ideology to many different problems

of function and data-analysis;

3) developing a theory that allows us to create kernels
that possess desirable properties (for example that can
enforce desirable invariants);

VAPNIK: OVERVIEW OF STATISTICAL LEARNING THEORY

999

4) developing a new type of inductive inference that is
based on direct generalization from the training set to the
test set, avoiding the intermediate problem of estimating
a function (the transductive type inference).

The hope is that this very fast growing area of research will

signicantly boost all branches of data analysis.

ACKNOWLEDGMENT

The author wishes to thank F. Mulier for discussions and

helping to make this article more clear and readable.

