1. Introduction

Learning involves the ability to generalize from past expe-
rience in order to deal with new situations that are related
to this experience. The inductive leaap needed to deal with
new situations seems to be possible only under certain biases
for choosing one generalization of the situation over another.
This paper denes precisely the notion of bias in generaliza-
tion problems, then shows that biases are necessary for the
inductive leap. Classes of justiable biases are considered,
and the relationship between bias and domain-independence
is considered.

We restrict the scope of this discussion to the problem of

generalizing from training instances, dened as follows:

The Generalization Problem
Given:

1. Language of instances.
2. Language of generalizations.
3. Matching predicate for matching generalizations to in-

stances.

4. Sets of positive and negative training instances.

Determine:

 Generalization(s) consistent with the training instances.

As a concrete example of the above generalization prob-
lem, consider the task addressed by Winstons program for
learning classes of block structures (Winston 1975). Here,
the language of instances is the representation used to de-
scribe example block structures. The language of gener-
alizations is the language in which learned concepts (e.g.,
arch, tower) are described. The matching predicate species
whether a given generalization applies to a given instance
(e.g., whether the inferred description of an arch is satised
by a specic block structure).

This paper addresses a deep difculty with the general-
ization problem as dened above: If consistency with the
training instances is taken as the sole determiner of appro-
priate generalizations, then a program can never make the
inductive leap necessary to classify instances beyond those
it has observed. Only if the program has other sources of in-
formation, or biases for choosing one generalization over the

Converted to electronic version by: Roby Joehanes, Kansas State
University

Figure 1: Relationships among Instances and Generaliza-
tions (This gure was missing from the original publication
and added in 1990.)

other, can it non-arbitrarily classify instances beyond those
in the training set.

In this paper, we use the term bias to refer to any basis for
choosing one generalization over another, other than strict
consistency with the observed training instances.

2. What is an UNbiased Generalizer

If generalization is the problem of guessing the class of in-
stances to which the positive training instances belong, then
an unbiased generalizer is one that makes no a priori as-
sumptions about which classes of instances are most likely,
but bases all its choices on the observed data. Two com-
mon sources of bias in existing learning systems are (1) the
generalization language is not capable of expressing all pos-
sible classes of instances, and (2) the generalization proce-
dure that searches through the space of expressible general-
izations is itself biased.

2.1. An Unbiased Generalization Language
In considering bias in the generalization language, it is use-
ful to view each generalization as denoting the set of in-
stances that it matches.
In gure 1, for example, g1 and
g2 are two generalizations expressible in some generaliza-
tion language, and each matches a different subset of the
instances.

Relative to a given langauge of instances, an unbiased
generalization language is then one which allows describ-
ing every possible subset of these instances.
In short, an

unbiased generalization language corresponds to the power
set of the given instance language.

The impact of using a biased generalization language is
clear: each subset of instances for which there is no express-
ible generalization is a concept that could be presented to
the program, but which the program will be unable to de-
scribe and therefore unable to learn. If it is possible to know
ahead of time that certain subsets of instances are irrelevant,
then it may be useful to leave these out of the generaliza-
tion language, in order to simplify the learning problem. For
example, on features of the instance (e.g., (Winston 1975),
(Buchanan & Mitchell 1978)) introduce a strong bias of this
kind, which reduces considerably the complexity of the gen-
eralization problem.

The strength of the bias introduced by generalization lan-
guages restricted to conjunctive constraints on features, is
illustrated by a simple example. Consider an instance lan-
guage of binary feature vectors containing 5 features, and
a generalization language that allows constraining each fea-
ture value to be 1, 0, or dont care. Some simple arith-
metic shows that only about one out of every 107 subsets of
instances is expressible in the generalization language. This
proportion worsens quickly as the number of features and
the number of allowed values per feature increases.

2.2. An Unbiased Generalization Procedure
The generalization procedure searches for expressible gen-
eralizations that denote sets of instances, each of which in-
cludes all of the positive but none of the negative training in-
stances. Of course, there may be many such generalizations.
In gure 1, for instance, if the observed positive instacnes
are contained in the intersection of the instance sets of g1
and g2, and the observed negative instances are outside both
sets, then both g1 and g2 are consistent with the observed
instances.

An unbiased generalization procedure is one which shows
no preference for one expressible generalization over an-
other, except on the basis of consistency with the training
instances.

Following (Mitchell 1977), we dene the version space
relative to a particular generalization language, and a given
set of training instances, as the set of all expressible gen-
eralizations consistent with the training instances. Then an
unbiased generalization procedure must compute the version
space relative to the observed training instances, and the pro-
vided generalization language. Such a generalization proce-
dure is described in (Mitchell 1978), and has been imple-
mented as part of the Meta-DENDRAL program (Buchanan
& Mitchell 1978).

In order to consider the consequences of an unbiased gen-
eralization procedure, it is necessary to consider how a com-
puted version space can be used to classify subsequent in-
stances as either positive or negative. An unbiased classi-
cation method classies the new instance as a positive in-
stance if and only if every generalization in the version space
matches it. The instance is classied as a negative instance
if and only if no generalization in the version space matches
it. If some, but not all, of the generalizations in the version
space match the instance, then the instane cannot be clas-

sied with certainty. The program could, however, give an
estimated classication based upon the proportion of gener-
alizations within the version space, that match and do not
match the instance.

3. The Futility of Removing Biases

For a generalization system to be unbiased  for it to con-
sider equally all possible subsets of instances as the possible
identity of the class being learned  it must employ an unbi-
ased generalization language, and compute the version space
relative to that language and the presented training instances.
Although removing all biases from a generalization sys-
tem may seem to be a desirable goal, in fact the result is
nearly useless. An unbiased learning systems ability to clas-
sify new instances is no better than if it simply stored all the
training instances and performed a lookup when asked to
classify a subsequent instance.

To see that this is the case, consider the procedure de-
scribed above for using the computed version space to clas-
sify new instances. For an unbiased generalization language,
the new instance will match every generalization consistent
with the observed instances if and only if it is identical to one
of the observed positive instances. Similarly, to be classied
as a negative instance, the new instance must be identical
to one of the observed negative instances. Furthermore, any
instance that has not yet appeared as a training instance will
match exactly half the generalizations in the version space.
As a result, even the scheme described above for estimating
the classication will fail to produce useful results.

In retrospect, it is not surprising that an unbiased gen-
eralization system cannot make classications of instances
other than the training instances. An unbiased system is
one whose inferences logically follow from the training in-
stances, whereas classications of the new instances do not
logically follow from the classications of the training in-
stances.

4. Useful Classes of Biases

There is an important conclusion to the above discussion:
If totally unbiased generalization systems are incapable of
making the inductive leap to characteriza the new instances,
then the power of a generalization system follows directly
from its biases  from decisions based on criteria other than
consistency with the training instances. Therefore, progress
toward understanding learning mechanisms depends upon
understanding the sources of, and justication for, various
biases. This section classies certain kinds of biases that
have been used by learning programs.

Factual knowledge of the domain.

In learning gener-
alizations for a particular purpose, it may be possible to
limit the generalizations considered, by appealing to knowl-
edge about the task domain. The Meta-DENDRAL program
(Buchanan & Mitchell 1978) forms general rules that char-
acterize molecular bonds that fragment in a mass spectrom-
eter. Here, general knowledge of the domain, such as dou-
ble bonds rarely break, can be used to constrain the search
for appropriate generalizations. Similarly, in a program that
learns the rules of baseball (Soloway & Riseman 1978),

5. Conclusions

Unbiased generalization programs that use consistency with
the training instances as their only source of information,
cannot outperform programs that use rote learning. Addi-
tional information or biases are therefore critical to the abil-
ity to classify instances that are not identical to the training
instances. This fact has signicant implications for research
on machine learning.

If biases and initial knowledge are at the heart of the abil-
ity to generalize beyond observed data, then efforts to study
machine learning must focus on the combined use prior
knowledge, biases, and observation in guiding the learning
process. It would be wise to make the biases and their use
in controlling learning just as explicit as past research has
made the observations and their use.

6. Acknowledgements

The following people have provided thoughtful comments
on various drafts of this paper, and have contributed their
own ideas: Saul Amarel, George Drastal, N.S. Sridharan,
and Paul Utgoff. This work was supported by NIH grant RR-
643-09, and by an award from the Rutgers Research Coun-
cil.

