Abstract

We show quite good face clustering is possible for a dataset
of inaccurately and ambiguously labelled face images. Our
dataset is 44,773 face images, obtained by applying a face
nder to approximately half a million captioned news im-
ages. This dataset is more realistic than usual face recog-
nition datasets, because it contains faces captured in the
wild in a variety of congurations with respect to the cam-
era, taking a variety of expressions, and under illumina-
tion of widely varying color. Each face image is associated
with a set of names, automatically extracted from the as-
sociated caption. Many, but not all such sets contain the
correct name.

We cluster face images in appropriate discriminant co-
ordinates. We use a clustering procedure to break ambigu-
ities in labelling and identify incorrectly labelled faces. A
merging procedure then identies variants of names that re-
fer to the same individual. The resulting representation can
be used to label faces in news images or to organize news
pictures by individuals present.

An alternative view of our procedure is as a process that
cleans up noisy supervised data. We demonstrate how to
use entropy measures to evaluate such procedures.

1. Introduction
It is straightforward to obtain enormous datasets of images,
with attached annotations. Examples include: collections
of museum material [3]; the Corel collection of images; any
video with sound or closed captioning; images collected
from the web with their enclosing web pages; or captioned
news images.

Exploiting partially supervised data is a widely stud-
ied theme in vision research. Image regions may usefully
and fairly accurately be linked with words, even though the
words are not linked to the regions in the dataset originally
[7, 2]. For example, models based around templates and re-
lations may be learned from a dataset of motorcycle images

where one never species where in the image the motorcy-
cle lies (for faces, see [14, 10]; for animals in static images
and in video, see [16, 18]; for a range of objects, see [9]). In
this paper, we show that faces and names can be linked in an
enormous dataset, despite errors and ambiguities in proper
name detection, in face detection and in correspondence.

Face recognition is well studied, and cannot be surveyed
reasonably in the space available. Early face recognition is
done in [19, 21] and is reviewed in [12, 6, 13]. Our problem
is slightly different from face recognition, in that it is more
important to identify discriminant coordinates  which can
be used to distinguish between faces, even for individuals
not represented in the dataset  than to classify the faces.
As a result, we focus on adopting the kPCA/LDA method-
ology, rather than on building a multi-class classier. Our
current work is a necessary precursor to real world face
recognition machinery: building large and realistic sets of
labelled data for recognition. We can leverage past work
by using it to determine what features might be useful for
identifying similar faces.

The general approach involves using unambiguously
labelled data items to estimate discriminant coordinates

(section 3). We then use a version of -means to allocate

ambiguously labelled faces to one of their labels (section 4).
Once this is done, we clean up the clusters by removing data
items far from the mean, and re-estimate discriminant coor-
dinates (section 4.2). Finally, we merge clusters based on
facial similarities (section 4.3). We show qualitative and
quantitative results in section 5.
2. Dataset
We have collected a dataset consisting of approximately
half a million news pictures and captions from Yahoo News
over a period of roughly two years.

Faces: Using the face detector of [15] we extract 44,773
face images (size 86x86 or larger with sufcient face de-
tection scores and resized to 86x86 pixels). Since these
pictures were taken in the wild rather than under xed

1

Name frequencies have the long tails that occur in natu-
ral language problems. We expect that face images roughly
follow the same distribution. We have hundreds to thou-
sands of images of a few individuals (e.g. President Bush),
and a large number of individuals who appear only a few
times or in only one picture. One expects real applications
to have this property. For example, in airport security cam-
eras a few people, security guards, or airline staff might be
seen often, but the majority of people would appear infre-
quently. Studying how recognition systems perform under
such a distribution is important.

The sheer volume of available data is extraordinary. We
have sharply reduced the number of face images we deal
with by using a face detector that is biased to frontal faces
and by requiring that faces be large and rectify properly.
Even so, we have a dataset that is comparable to, or larger
than, the biggest available lab sets and is much richer in
content. Computing kernel PCA and linear discriminants
for a set this size requires special techniques (section 3.1).
2.2 Rectication
Before comparing images, we automatically rectify all faces
to a canonical pose. Five support vector machines are
trained as feature detectors (corners of the left and right
eyes, corners of the mouth, and the tip of the nose) using
150 hand clicked faces. We use the geometric blur of [5]
applied to grayscale patches as the features for our SVM.
A new face is tested by running each SVM over the image
with a weak prior on location for each feature. We compute
an afne transformation dened by the least squares solu-
tion between maximal outputs of each SVM and canonical
feature locations. We then perform gradient descent to nd
the afne transformation which best maps detected points
to canonical feature locations. Each image is then rectied
to a common pose and assigned a score based on the sum of
its feature detector responses.

Larger rectication scores indicate better feature detec-
tion and therefore better rectication. We lter our dataset
by removing images with poor rectication scores and are
left with 34,623 face images. Each face is automatically
cropped to a region surrounding the eyes, nose and mouth to
eliminate effects of background on recognition. The RGB
pixel values from each cropped face are concatenated into a
vector and used from here on.

3. Discriminant Analysis
We perform kernel principal components analysis (kPCA)
to reduce the dimensionality of our data and linear discrimi-
nant analysis (LDA) to project data into a space that is suited
for the discrimination task.

Kernel Principal Components Analysis: Kernel PCA
[20] uses a kernel function to efciently compute a princi-
pal component basis in a high-dimensional feature space,

Figure 1: Top row shows face detector results, bottom row
shows images returned by the face rectier with rectication
score shown center (larger scores indicate better rectica-
tion performance). The face rectier uses an SVM to detect
feature points on each face. Gradient descent is then used
to nd the best afne transformation to map feature points
to canonical locations.

laboratory conditions, they represent a broad range of indi-
viduals, pose, expression and illumination conditions. In-
dividuals also change over time, which has been shown to
hamper recognition in [12]. Our face recognition dataset is
more varied than any other to date.

Names: We extract a lexicon of proper names from all
the captions by identifying two or more capitalized words
followed by a present tense verb ([8]). Words are classied
as verbs by rst applying a list of morphological rules to
present tense singular forms, and then comparing these to
a database of known verbs (WordNet [25]). This lexicon is
matched to each caption. Each face detected in an image
is associated with every name extracted from the associated
caption (e.g. g 2). Our job is to label each face detector
response with the correct name (if one exists).

Scale: We obtain 44,773 large and reliable face detector
responses. We reject face images that cannot be rectied
satisfactorily, leaving 34,623. Finally, we concentrate on
images associated with 4 or fewer names, leaving 27,742
faces.

2.1 Distinctive Properties
Performance gures reported in the vision literature are
inconsistent with experience of deployed face recognition
systems (e.g., see [17]). This suggests that lab datasets lack
important phenomena. Our dataset differs from typical face
recognition datasets in a number of important ways.

Pose, expression and illumination vary widely. The
face detector tends not to detect lateral views of faces, but
(gure 3) we often encounter the same face illuminated with
markedly different colored light and in a broad range of ex-
pressions. Spectacles and mustaches are common. There
are wigs, images of faces on posters, differences in reso-
lution and identikit pictures. Quite often there are multi-
ple copies of the same picture (this is due to the way news
pictures are prepared, rather than a collecting problem) or
multiple pictures of the same individual in similar congu-
rations. Finally, some individuals are tracked across time.

2

Donald
Rumsfeld

President
George

Kate
Winslet

Sam
Mendes

Gray Davis

President George W. Bush makes a state-
ment in the Rose Garden while Secretary of
Defense Donald Rumsfeld looks on, July 23,
2003. Rumsfeld said the United States would
release graphic photographs of the dead sons
of Saddam Hussein to prove they were killed
by American troops. Photo by Larry Down-
ing/Reuters

British director Sam Mendes and his part-
ner actress Kate Winslet arrive at the London
premiere of The Road to Perdition, Septem-
ber 18, 2002. The lms stars Tom Hanks as
a Chicago hit man who has a separate fam-
ily life and co-stars Paul Newman and Jude
Law. REUTERS/Dan Chung

Incumbent California Gov. Gray Davis
(news - web sites) leads Republican chal-
lenger Bill Simon by 10 percentage points 
although 17 percent of voters are still unde-
cided, according to a poll released October
22, 2002 by the Public Policy Institute of Cal-
ifornia. Davis is shown speaking to reporters
after his debate with Simon in Los Angeles,
on Oct. 7. (Jim Ruymen/Reuters)

World number one Lleyton Hewitt of Aus-
tralia hits a return to Nicolas Massu of Chile
at the Japan Open tennis championships in
Tokyo October 3, 2002. REUTERS/Eriko
Sugita

Lleyton Hewitt

Claudia Schiffer

President
George

State Colin
Powell

German supermodel Claudia Schiffer gave
birth to a baby boy by Caesarian section
January 30, 2003, her spokeswoman said.
The baby is the rst child for both Schif-
fer, 32, and her husband, British lm pro-
ducer Matthew Vaughn, who was at her side
for the birth. Schiffer is seen on the Ger-
man television show Bet It...?!
(Wetten
Dass...?!) in Braunschweig, on January 26,
2002. (Alexandra Winkler/Reuters)
US President George W. Bush (L) makes re-
marks while Secretary of State Colin Pow-
ell (R) listens before signing the US Leader-
ship Against HIV /AIDS , Tuberculosis and
Malaria Act of 2003 at the Department of
State in Washington, DC. The ve-year plan
is designed to help prevent and treat AIDS,
especially in more than a dozen African and
Caribbean nations(AFP/Luke Frazza)

Figure 2: Given an input image and an associated caption (images above and captions to the right of each image), our system
automatically detects faces (white boxes) in the image and possible name strings (bold). We use a clustering procedure to
build models of appearance for each name and then automatically label each of the detected faces with a name if one exists.
These automatic labels are shown in boxes below the faces. Multiple faces may be detected and multiple names may be
extracted, meaning we must determine who is who (e.g., the picture of Cluadia Schiffer).

related to the input space by some nonlinear map. Ker-
nel PCA has been shown to perform better than PCA at
face recognition [23]. Kernel PCA is performed as follows:
Compute a kernel matrix, K, where
is the value of the
kernel function comparing
(we use a
Gaussian kernel). Center the kernel matrix in feature space
(by subtracting off average row, average column and adding
on average element values). Compute an eigendecomposi-
tion of K, and project onto the normalized eigenvectors of
K.









and



Linear Discriminant Analysis: LDA has been shown to
work well for face discrimination [24, 4, 12] because it uses
class information to nd a set of discriminants that push
means of different classes away from each other.
3.1 Nystrom Approximation
Our dataset is too large to do kPCA directly as the kernel
matrix, K will be of size NxN, where N is the the num-
ber of images in the dataset, and involve approximately
image comparisons. Therefore, we instead use an ap-
proximation to calculate the eigenvectors of K. Incomplete
Cholesky Decomposition (ICD [1]) can be used to calcu-
late an approximation to K with a bound on the approxima-
tion error, but involves accessing all N images for each col-
umn computation (where N is the number of images in the



3

dataset). The Nystrom approximation method (cf [22, 11])
gives a similar result, but allows the images to be accessed
in a single batch rather than once for each column com-
putation (thereby being much faster to compute for large
matrices). Nystrom does not give the same error bound on
its approximation to K. However, because of the smoothing
properties of kernel matrices we expect the number of large
eigenvalues of our matrix to be small, where the number of
large eigenvalues should go down relative to the amount of
smoothing. In our matrix we observed that the eigenvalues
do tend to drop off quickly. Because of this, a subset of
the columns of our matrix, should encode much of the data
in the matrix. This implies that the Nystrom method may
provide a good approximation to K.

The Nystrom method computes two exact subsets of K,
A and B, and uses these to approximate the rest of K. Using
this approximation of K, the eigenvectors can be approxi-
mated efciently.

First the N

N kernel matrix, K, is partitioned as

 
!#"

$&%


,! '/)1032546+879-.+ and$:'/)10;2<46+879-603254=+87 .

Here, A is a subset of the images, (in our case 1000 ran-

with('*),+-.+


!
Em@NJcZY
sI
^HIdQCVg
iCVg[}

ZG6IO t
Ig agos

~,MMPe>W
IO
eWNAcZg eep
itIg
CH? or
IKJDJ8JDCJDC

>sQZg

ll

AcZ[CmZ[InHMSW

OUTDMao6I

^MSOQCHW

P`_a@G6Jcb eld

>t@ONu`ADCHOBAK@@BkveHY

xCHOQJtLW

XOY
Z[IKP]\C tions
>?@BADC yyaf

EFMSROUTDCV@W

nMSW
OUTDMo=IW l
I=>uC ssi
>tOQPg

Z on

EzMSROBLNMSW

MSO
Gqg
Yp
>W
^IKb ense
AcIhsag
IKZ3CHg
_a@G=JDb
IW
Thg
IhJ9Y
PIONZSitIhuCmo6CmZY
G e
^HId@NZ3efThg3Y
i,Y
JDZ[IgajFCHW
OY
kg[Y
JKROQC>PlmCHO
{9g[Y
sB_a@NPMSW
dR
{9g3Y
sB_MS?mIg
Z_ udolph
Em@W ie
Ig3?QIg ding
IW3>g
PIONZS^CHOY
IKJ9Y
Thg
CHdfitMSY

AcZg om TR@g3G=MSOQP
>sQZg
IKJDJt_NIKIKJDI
ZRNIg
J9dmM on
~Y

i

IW

P`_a@G6JDb

^IKb
IONJDI,^HMSONCVW
IKJ9Y
C9rYNThg
PIONZ
AcC9P dam Hussein
EFCHG6IKJLNMOQP
I8g>tOY
IKJDJ8EzI8OOY
>sQZg
JcZ on

>g[OQMSW

P]AcsRNo6CHg

|IO egger

iCVg

ZRQCfAcZ[IKo6CHg t

Figure 3: The gure shows a representative set of clusters from our largest threshold series, illustrating a series of important
properties of both the dataset and the method. Note that this picture greatly exaggerates our error rate in order to show
interesting phenomena and all the types of error we encounter. 1: Some faces are very frequent and appear in many different
expressions and poses, with a rich range of illuminations (e.g. clusters labelled State Colin Powell, or Donald Rumsfeld).
These clusters also demonstrate that our clusterer can cope with these phenomena. 2: Some faces are rare, or appear in
either repeated copies of one or two pictures or only slightly different pictures (e.g. cluster labelled Abu Sayyaf or Actress
Jennifer Aniston). 3: Some faces are not, in fact, photographs (Ali Imron). 4: The association between proper names and
faces is still somewhat noisy, because it remains difcult to tell which strings are names of persons (United Nations, which
shows three separate face phenomena that co-occur frequently with this string; Justice Department, which is consistent as to
face but not the name of a person; and President Daniel Arap Moi or John Paul, which show a names associated with the
wrong face). 5: some names are genuinely ambiguous (James Bond, which shows two different faces naturally associated
with the name (the rst is an actor who played James Bond, the second an actor who was a villain in a James Bond lm) .
6: Some faces appear at both low and reasonable resolution (Saddam Hussein). 7: Our cluster merging process is able to
merge clusters depicting the same face but labelled with distinct strings (the clusters in the light gray and dark gray polygons,
respectively). 8: Our cluster merging process is not perfect and could benet from deeper syntactic knowledge of names (Eric
Rudolph and Eric Robert Rudolph), but in cases such as Defense Secretary Rumsfeld, Donald Rumsfeld and Defense Donald
Rumsfeld the mergings produced are correct. 9: Our clustering is quite resilient in the presence of spectacles (Hans Blix),
perhaps wigs (John Bolton) and mustaches (John Bolton).

4

Y
p
g
e
P
P
Y
w
Y
y
w
W
b
w
Proposed Merges

President Bush
Donald Rumsfeld

President George
Defense Secretary
Donald Rumsfeld

State Colin Powell

Colin Powell
Richard Myers
United Nations
Defense Donald Rumsfeld Donald Rumsfeld

President Bush
President Bush

Venezuelan President

Hugo Chavez

Hugo Chavez

Table 1: Multiple names can often refer to the same person.
We link names to people based on images.
If two names
have the same associated face, then they must refer to the
same person. The above pairs are the top name merges pro-
posed by our system. Merges are proposed between two
names if the clusters referring to each name contain similar
looking faces.

domly selected images) compared to themselves, B is the
comparison of each of the images of A, to the rest of
the images in our dataset, and C is approximated by the
Nystrom method. Nystrom gives an approximation for C
. This gives an approximation to K,
as,



Then we form

, the centered version of our approxima-
tion
, by calculating approximate average row, average
column sums (these are equal since K is symmetric), and
average element values. We can approximate the average
row (or column) sum as:

4!

.

4

!!

Then

is diagonalized by:

We center as usual,

We then solve for the orthogonalized approximate eigen-
vectors as follows. First, we replace A and B by their

254=+
+
4!
254=+
+
2:



2]
centered versions. Let*
 be the square root of A, and
4
 . Diagonalize S as
h`a
 


. Given
we proceed as usual for kPCA,
this decomposition of
by normalizing the eigenvectors
onto
the normalized eigenvectors. This gives a dimensionality
reduction of our images that makes the discrimination task
easier.

and

Then we have

and projecting



.

4. Clustering
We view our collection as a semi-supervised dataset with
errors that we wish to clean up. First we form discrim-
inants from faces with only one common extracted name.
While this is a fairly small set of faces and the labels are not
perfect, they let us form an initial discriminant space. We
project all of our images into this space and perform a mod-
ied k-means procedure for clustering. This gives a larger
and less noisy dataset from which to recompute discrimi-
nants. These new discriminants give a better representation
of identity and we use them to re-cluster. This gives a reli-
able set of clusters.
4.1 Modied K-Means Clustering
Each image has an associated vector, given by the kPCA
and LDA processes, and a set of extracted names (those
words extracted using our proper name detector from the
images caption).

The clustering process works as follows: 1. Randomly
assign each image to one of its extracted names 2. For each
distinct name (cluster), calculate the mean of image vec-
tors assigned to that name. 3. Reassign each image to the
closest mean of its extracted names. 4. Repeat 2-3 until
convergence (i.e. no image changes names during an itera-
tion)
4.2 Pruning Clusters
We use a nearest neighbor model to describe our dataset
and throw out points that have a low probability under this
model. We remove clusters with fewer than three images
so that nearest neighbor has some meaning. This leaves
19,355 images. We then remove points with low likelihood
for a variety of thresholds (table 2) to get error rates as low
as 5%, (error rates are calculated by hand labelling pictures
from our dataset). We dene likelihood as the ratio of the
probability that it came from its assigned cluster over the
probability that it did not come from its assigned cluster:

vH

where for a point x in cluster

c/B

is the number of points in cluster

, k is the number of near-
is the number of those
, n is the total number of points in the
. We are us-
as the estimated probability of a cluster. This

c,
a

,
D

est neighbors we are considering,
vH


VcQt=c6
+8

neighbors that are in
set and
ing
gives more weight to smaller clusters.
4.3 Merging Clusters
We would like to merge clusters with different names that
actually correspond to a single person such as Defense Don-
ald Rumsfeld and Donald Rumsfeld or Venezuelan President
Hugo Chavez and Hugo Chavez. This can be extremely hard
to do directly from text, in situations such as Colin Powell

5


$

!
"



!
!
"

$
%







2




!

!
"

!
"

%



2

2


2





2



2






"

"





!
"
%

4





4








"
"



























+

#Images
19355
7901
4545
3920
2417

#Clusters

error rate

2357
1510
765
725
328

26%
11%
5.2%
7.5%
6.6%

Table 2: Dataset sizes, number of clusters and error rates
for different thresholds. The number of people in each set is
approximately the number of clusters and error rate is de-
ned as: given an individual and a face from their associ-
ated cluster, the error rate is the probability of that face be-
ing incorrect. We see that for mid-level pruning we get quite
small error rates. We have turned a large semi-supervised
set of faces into a well supervised set and produced clean
clusters of many people.

and Secretary of State (the names do not share any words).
We propose to merge names that correspond to faces that
look the same. Our system automatically propose merges
between clusters that have similar compositions i.e. if the
clusters have similar faces in them they possibly describe
the same person. We can judge the similarity of clusters
by the distance between their means in discriminant coordi-
nates. Table 1 shows that almost all the top proposed merges
correspond to correct merges (two names that refer to the
same person), except that of Richard Myers and President
Bush.
5. Quantitative Evaluation
We view this method as taking a supervised dataset that con-
tains errors and ambiguities in the supervisory signal and
producing a dataset with an improved (or, ideally, correct)
supervisory signal, possibly omitting some data items. We
must now determine how much better the new dataset is.
Two things can have happened: First, the dataset may be
smaller. Second, the supervisory signal should be more ac-
curate.

But how much more accurate? If we are willing to as-
sume that all errors are equivalent, we can see this issue as
a coding problem. In particular, one must determine how
many bits need to be supplied to make the dataset correct.
We compute this score on a per-item basis, so that the size of
the dataset does not affect the score. The number computed
is necessarily an estimate  we may not have an optimal
coding scheme  but if one uses a reasonably competent
coding scheme should allow us to rank methods against one
another.
5.1 The cost of correcting unclustered data
We have a set of image-text pairs, each of which consists
of an image of one of the individuals, and a list of between
1 and 4 (typically) text labels. For each data item, we must
now determine whether this set of labels contains the correct

s
t
i
b
n



i


e
g
a
m

i

r
e
p

t
s
o
c
g
n
d
o
c

i



5.5

5

4.5

4

3.5

3

2.5

2

1.5

1

0.5

11

11.5

12

Coding Costs

Original data set
Cost given image labels
Cost given clustering

12.5

13

log2(number of images)

13.5

14

14.5

15

Figure 4: The gure shows the approximate cost per item
of correcting each dataset plotted against the size of the
dataset. Note that the original dataset (the cross) is large
and noisy; if one clusters, merges and cleans, then ignores
the clustering structure, the resulting dataset is, in fact,
somewhat noisier (dashed line). Finally, if one looks at the
cluster structure, too, the dataset is much cleaner in par-
ticular one is contributing information to a dataset by clus-
tering it correctly. Finally, increasing settings of our re-
ject threshold leads to datasets that tend to be smaller and
cleaner.

or

represent the random variable that takes on
bits (where
, we can do this with
). If the list
labels contains the correct name, we can tell which it
bits. If it does not, we must supply the correct
bits (the entropy of the label



given



Write

values of



of
is with
name, which will cost
set).

label. Letting$
,
is the conditional entropy of$
8

;q
8
fD
c8a
c
9

that have a correct label in that list, and
portion of those with
item of correcting the original dataset
then

D



8

5.2 The Cost of Correcting Clustered Data
Our clustering procedure introduces two types of structure.
First, it assigns each image from an image-text pair to one
of
clusters. Second, it associates a text to each cluster,
so implicitly labelling each image pair within that cluster.
If the labelling represented in this way is perfect, no further
bits need to be provided.

We compute the additional cost for perfect labelling by
examining how much work (how many bits) are required
to x all the errors in an imperfect clustering and cluster
labelling. We assume the entropy of the label set remains
xed. We split the problem of xing up imperfect clusters
into two steps. In the rst step, we change the name of each
cluster, if necessary, so that it corresponds to the person who
appears most frequently in this cluster. In the second step,
we change the label of each image in a cluster if it does not
correspond to the (now correct) label of the cluster.

6

for the proportion of images with

labels
for the pro-
labels that do not. The total cost per
in this fashion is

fv,
8
v,
83

8Q

N


$

$








$


$





Fixing the cluster labels: Let
be the proportion of
the proportion of
clusters with the correct label and
clusters with an incorrect label. Let
be the random vari-
able representing whether a cluster is labelled correctly or
not and recall our practice of writing the entropy of a ran-
dom variable
The cost per cluster of correcting
the labels for all the clusters is then

fvS
v,

as

c
D

v,Q




D

obtain the correct name, and the cost is

for the total number of clusters per item (we

Fixing incorrect elements within the cluster: We as-
sume for simplicity that, once the labels have been corrected
as above, the proportion of correctly labelled elements in a
cluster
is independent of the cluster. This means that
the cost per item of xing incorrectly labelled elements is
independent of the specic cluster structure. Then to nish
xing the labelling we must pay
bits per item to iden-
bits per incorrect item to

fv
V

Now write
hope
labelling of the data, after clustering, as

D
D
D
f,

v


tify the incorrect items and$
D
 ). We have a total per item cost for the correct

D
f,


Quantitative Evaluation Results
We report results for (a) the original dataset (b) the datasets
resulting from our clustering, merging and cleaning process,
without using cluster information (c) the datasets resulting
from our clustering, merging and cleaning process, includ-
ing their cluster structure. Figure 4 shows the plot. The
original dataset is large and noisy; if one clusters, merges
and cleans, then ignores the clustering structure, the result-
ing dataset is somewhat noisier. Finally, if one looks at the
cluster structure, too, the dataset is much cleaner  this is
because one is contributing information to the dataset by
clustering it correctly and this fact is reected by our score:
in particular many of our clusters have the right face, but the
wrong name (e.g. President Daniel Arap Moi in gure 3),
and so can be corrected quickly. Finally, distinct settings of
our reject threshold lead to datasets that tend to be smaller
and cleaner.
