{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "253030c358d567a5b6a82aa4c12bb84355075b49"
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.models import LdaModel\n",
    "from gensim import models, corpora, similarities\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import time\n",
    "from nltk import FreqDist\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.io.json import json_normalize #package for flattening json in pandas df\n",
    "#from fastai.imports import *\n",
    "#from pandas_summary import DataFrameSummary\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINDATAPATH = \"PAN14/pan14_train_english-essays/\"\n",
    "TESTDATAPATH = \"PAN14/pan14_test01_english-essays/\"\n",
    "FNAMES = ['known01','known02','known03','known04','known05', 'unknown']\n",
    "\n",
    "def train_lda(corpus, dictionary, num_topics=20, passes=2, iterations=100, alpha=1e-2, eta=0.5e-2):\n",
    "    \"\"\"\n",
    "    This function trains the lda model\n",
    "    We setup parameters like number of topics, the chunksize to use in Hoffman method\n",
    "    We also do 2 passes of the data since this is a small dataset, so we want the distributions to stabilize\n",
    "    \"\"\"\n",
    "    #num_topics = 100\n",
    "    #chunksize = 300\n",
    "    \n",
    "    t1 = time.time()\n",
    "    # low alpha means each document is only represented by a small number of topics, and vice versa\n",
    "    # low eta means each topic is only represented by a small number of words, and vice versa\n",
    "    lda = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, \n",
    "                   alpha=alpha, eta=eta, minimum_probability=0.0, passes=passes, iterations=iterations, random_state=1033, dtype=np.float64)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to train LDA model on \", len(docs), \"articles: \", (t2-t1)/60, \"min\")\n",
    "    return lda\n",
    "\n",
    "def data_to_topics(data, dictionary, cols):\n",
    "    df = data.drop(columns=cols)\n",
    "    for col in cols:\n",
    "        df[col]=data[col].apply(lambda x: lda.get_document_topics(dictionary.doc2bow(x)) if x is not None else None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    ds=pd.read_json(path+'/truth.json')\n",
    "    ds=json_normalize(ds['problems'])\n",
    "    ds['known01']=None\n",
    "    ds['known02']=None\n",
    "    ds['known03']=None\n",
    "    ds['known04']=None\n",
    "    ds['known05']=None\n",
    "    ds['unknown']=None\n",
    "    ds.set_index('name', drop=True, inplace=True)\n",
    "    ds=ds[['known01','known02','known03','known04','known05', 'unknown', 'answer']]\n",
    "    dirs = []\n",
    "    docs = []\n",
    "\n",
    "    for i, x in enumerate(os.walk(path)):\n",
    "        if i:\n",
    "            for fname in x[2]:\n",
    "                with open(path+dirs[i-1]+'/'+fname, 'r') as f:\n",
    "                    text = f.read()\n",
    "                    doc = nltk.word_tokenize(text.strip())\n",
    "                    docs.append(doc)\n",
    "                    ds.loc[dirs[i-1],fname[:-4]]=doc\n",
    "        else:\n",
    "            dirs = x[1]\n",
    "\n",
    "    return ds, docs\n",
    "\n",
    "train, docs = read_dataset(TRAINDATAPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "EE001    [﻿, In, the, name, of, Religion, ,, you, can, ...\n",
       "EE004    [﻿, The, Decline, of, the, Birth-rate, in, Swe...\n",
       "EE005    [﻿, ``, Taboo, or, Not, Taboo, '', In, the, ar...\n",
       "EE008    [﻿, Granting, Homosexual, Couples, the, Right,...\n",
       "EE013    [﻿, Politics, and, Education, On, numerous, oc...\n",
       "EE014    [﻿, GIRLS, BEGIN, TO, DIET, AT, THE, AGE, OF, ...\n",
       "EE018    [﻿, THE, RIGHT, SIDE, THERE, SHOULD, BE, MORE,...\n",
       "EE021    [﻿, Stop, women, 's, right, to, an, abortion-,...\n",
       "EE022    [﻿, Evaluation, -, My, English, I, think, that...\n",
       "EE025    [﻿, THE, CAPITAL, PUNISHMENT, IS, NEVER, RIGHT...\n",
       "EE027    [﻿, NEW, AGE, a, Trend, in, Our, Workplaces, ....\n",
       "EE035    [﻿, THE, GROWTH, OF, NAZISM, IN, SOCIETY, Duri...\n",
       "EE038    [﻿, Democracy, ,, a, delusion, ?, A, short, cr...\n",
       "EE040    [﻿, When, Harriet, and, David, meet, they, kno...\n",
       "EE043    [﻿Introduction, Geoffrey, Chaucer, is, one, of...\n",
       "EE044    [﻿, DISCO, 'S, OUT, ,, MURDER, 'S, IN, ., I, h...\n",
       "EE045    [﻿, Would, a, Spelling, Reform, of, the, Engli...\n",
       "EE046    [﻿, THE, SWEDISH, MONARCHY, A, NICE, TRADITION...\n",
       "EE047    [﻿, Why, the, paragraph, that, regulates, the,...\n",
       "EE057    [﻿Looking, back, through, my, years, at, schoo...\n",
       "EE061    [﻿In, this, essay, I, am, going, to, write, ab...\n",
       "EE066    [﻿English, is, one, of, the, major, languages,...\n",
       "EE069    [﻿, Should, the, family, look, after, the, eld...\n",
       "EE070    [﻿, The, Steam, of, Courage, According, to, Ca...\n",
       "EE072    [﻿, Shorter, working, hours, -, Higher, qualit...\n",
       "EE073    [﻿, Give, the, elderly, a, decent, treatment, ...\n",
       "EE075    [﻿, Homosexual, couples, should, have, the, ri...\n",
       "EE078    [﻿, The, Growing, Number, of, Students, In, Pr...\n",
       "EE087    [﻿, English, ,, my, English, For, me, ,, Engli...\n",
       "EE088    [﻿, Evaluation, -, English, ,, My, English, !,...\n",
       "                               ...                        \n",
       "EE547    [﻿This, essay, is, about, my, strengths, and, ...\n",
       "EE549    [﻿, English, ,, My, English, Introduction, To,...\n",
       "EE550    [﻿I, have, been, studying, English, for, many,...\n",
       "EE551    [﻿According, to, the, number, of, years, that,...\n",
       "EE553    [﻿, Subject, :, The, family, ,, not, the, stat...\n",
       "EE555    [﻿, Legal, age, for, buying, alcohol, should, ...\n",
       "EE556    [﻿, Evaluation, English, ,, My, English, I, re...\n",
       "EE557    [﻿, A, modern, monarchy, Sweden, has, been, a,...\n",
       "EE558    [﻿This, essay, is, dealing, with, my, competen...\n",
       "EE560    [﻿, Abolishing, of, the, death, penalty, In, a...\n",
       "EE563    [﻿The, task, for, this, week, is, to, write, d...\n",
       "EE564    [﻿, The, Swedish, purchase, of, Gripen, fighte...\n",
       "EE565    [﻿, What, about, Systembolaget, ?, I, thought,...\n",
       "EE566    [﻿I, think, I, am, rather, good, at, English, ...\n",
       "EE569    [﻿, Park, your, car, Did, you, have, problems,...\n",
       "EE571    [﻿, SMOKING, OR, NON-SMOKING, ?, Imagine, a, n...\n",
       "EE572    [﻿, It, has, been, stated, that, role-playing,...\n",
       "EE576    [﻿, NO, TO, THE, DEVELOPMENT, OF, XENOTRANSPLA...\n",
       "EE578    [﻿I, will, try, to, assess, my, skills, in, th...\n",
       "EE579    [﻿It, all, started, in, fourth, grade, ., I, w...\n",
       "EE582    [﻿, Television, and, our, conception, of, soci...\n",
       "EE584    [﻿y, favourite, subject, in, school, has, alwa...\n",
       "EE585    [﻿, English, ,, My, English, !, This, is, the,...\n",
       "EE589    [﻿, English, ,, My, English, !, I, feel, so, f...\n",
       "EE590    [﻿, NUCLEAR, POWER, vs., NATURAL, SOURCES, OF,...\n",
       "EE591    [﻿, Girls, and, boys, in, separate, classes, ?...\n",
       "EE592    [﻿, English, ,, My, English, !, Introduction, ...\n",
       "EE594    [﻿This, an, essay, about, my, experience, from...\n",
       "EE595    [﻿, Just, a, few, years, ago, I, felt, quite, ...\n",
       "EE599    [﻿When, I, went, to, school, ,, I, was, especi...\n",
       "Name: unknown, Length: 200, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['unknown'].apply(lambda' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-26 04:06:16,050 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-12-26 04:06:16,584 : INFO : built Dictionary(21051 unique tokens: ['\\x03', '%', '&', \"''\", '(']...) from 729 documents (total 680137 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test, _ = read_dataset(TESTDATAPATH)\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-26 04:06:16,998 : INFO : using autotuned alpha, starting with [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
      "2018-12-26 04:06:17,005 : INFO : using serial LDA version on this node\n",
      "2018-12-26 04:06:17,067 : INFO : running online (multi-pass) LDA training, 20 topics, 2 passes over the supplied corpus of 729 documents, updating model once every 729 documents, evaluating perplexity every 729 documents, iterating 100x with a convergence threshold of 0.001000\n",
      "2018-12-26 04:06:17,067 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2018-12-26 04:06:22,768 : INFO : -11.521 per-word bound, 2938.7 perplexity estimate based on a held-out corpus of 729 documents with 680137 words\n",
      "2018-12-26 04:06:22,768 : INFO : PROGRESS: pass 0, at document #729/729\n",
      "2018-12-26 04:06:26,288 : INFO : optimized alpha [0.07924855819519203, 0.04150188029031236, 0.045717044971089686, 0.04001537330797816, 0.03320479442188855, 0.037591621771795085, 0.03258451971932087, 0.04787308347495848, 0.09883181446604969, 0.08618024761661813, 0.03888080504135442, 0.05126984972416385, 0.044016852679833456, 0.04527513573860485, 0.0797078899154284, 0.06712064882851722, 0.034784306984367394, 0.05970347969051978, 0.09268773540065381, 0.036069351551287425]\n",
      "2018-12-26 04:06:26,369 : INFO : topic #6 (0.033): 0.001*\".\" + 0.001*\",\" + 0.001*\"the\" + 0.001*\"to\" + 0.001*\"a\" + 0.001*\"is\" + 0.001*\"that\" + 0.000*\"of\" + 0.000*\"in\" + 0.000*\"and\"\n",
      "2018-12-26 04:06:26,370 : INFO : topic #4 (0.033): 0.004*\"the\" + 0.003*\".\" + 0.002*\"English\" + 0.002*\"to\" + 0.002*\"and\" + 0.002*\"is\" + 0.002*\"in\" + 0.002*\",\" + 0.002*\"a\" + 0.002*\"of\"\n",
      "2018-12-26 04:06:26,371 : INFO : topic #9 (0.086): 0.038*\".\" + 0.036*\"the\" + 0.032*\"to\" + 0.031*\"I\" + 0.026*\",\" + 0.021*\"and\" + 0.020*\"a\" + 0.018*\"that\" + 0.015*\"of\" + 0.015*\"is\"\n",
      "2018-12-26 04:06:26,372 : INFO : topic #18 (0.093): 0.039*\",\" + 0.039*\"the\" + 0.036*\".\" + 0.032*\"and\" + 0.027*\"of\" + 0.019*\"to\" + 0.015*\"is\" + 0.015*\"in\" + 0.014*\"a\" + 0.014*\"that\"\n",
      "2018-12-26 04:06:26,373 : INFO : topic #8 (0.099): 0.045*\"the\" + 0.045*\".\" + 0.036*\",\" + 0.033*\"to\" + 0.023*\"and\" + 0.022*\"of\" + 0.020*\"a\" + 0.019*\"is\" + 0.018*\"in\" + 0.017*\"I\"\n",
      "2018-12-26 04:06:26,375 : INFO : topic diff=12.755441, rho=1.000000\n",
      "2018-12-26 04:06:32,219 : INFO : -6.763 per-word bound, 108.6 perplexity estimate based on a held-out corpus of 729 documents with 680137 words\n",
      "2018-12-26 04:06:32,220 : INFO : PROGRESS: pass 1, at document #729/729\n",
      "2018-12-26 04:06:35,171 : INFO : optimized alpha [0.05923416245083005, 0.03395905950638283, 0.036613949823951816, 0.03300193231409185, 0.028371896025752665, 0.031400306336230734, 0.027930203958025493, 0.037989408145160726, 0.14306286196821405, 0.07219863236104543, 0.03225854023630101, 0.03992994622752583, 0.036916018555512395, 0.03639789917111258, 0.056628546219373466, 0.048210520311247174, 0.029481551747138804, 0.047647585788181436, 0.08483607252216295, 0.030368347350317796]\n",
      "2018-12-26 04:06:35,248 : INFO : topic #6 (0.028): 0.000*\".\" + 0.000*\",\" + 0.000*\"the\" + 0.000*\"to\" + 0.000*\"a\" + 0.000*\"is\" + 0.000*\"that\" + 0.000*\"of\" + 0.000*\"and\" + 0.000*\"in\"\n",
      "2018-12-26 04:06:35,249 : INFO : topic #4 (0.028): 0.001*\"the\" + 0.001*\".\" + 0.001*\"English\" + 0.001*\"to\" + 0.001*\"and\" + 0.001*\"is\" + 0.001*\"in\" + 0.001*\",\" + 0.001*\"a\" + 0.001*\"of\"\n",
      "2018-12-26 04:06:35,250 : INFO : topic #9 (0.072): 0.055*\"I\" + 0.040*\".\" + 0.034*\"to\" + 0.031*\"the\" + 0.026*\",\" + 0.021*\"and\" + 0.020*\"a\" + 0.019*\"that\" + 0.016*\"in\" + 0.015*\"English\"\n",
      "2018-12-26 04:06:35,251 : INFO : topic #18 (0.085): 0.040*\"the\" + 0.040*\",\" + 0.038*\".\" + 0.031*\"and\" + 0.025*\"of\" + 0.021*\"to\" + 0.017*\"is\" + 0.015*\"in\" + 0.015*\"a\" + 0.014*\"that\"\n",
      "2018-12-26 04:06:35,252 : INFO : topic #8 (0.143): 0.045*\"the\" + 0.044*\".\" + 0.036*\",\" + 0.032*\"to\" + 0.023*\"and\" + 0.023*\"of\" + 0.020*\"a\" + 0.018*\"is\" + 0.018*\"in\" + 0.017*\"that\"\n",
      "2018-12-26 04:06:35,253 : INFO : topic diff=2.081286, rho=0.577350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LDA model on  729 articles:  0.3049228628476461 min\n"
     ]
    }
   ],
   "source": [
    "lda = train_lda(corpus, dictionary, num_topics=20, passes=2, iterations=100, alpha='auto', eta='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicsdf=data_to_topics(train, dictionary, FNAMES)\n",
    "testtopicsdf=data_to_topics(test, dictionary, FNAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_topics(topicdata, cols):\n",
    "    df = topicdata.drop(columns=cols)\n",
    "    ptopics=[]\n",
    "    for col in cols:\n",
    "        df[col]=topicdata[col].apply(lambda x: [pair[1] for pair in x] if x is not None else None)\n",
    "        distributions=[t for t in df[col].tolist() if t is not None]\n",
    "        ptopics.extend(distributions)\n",
    "    return df, np.mean([item for sublist in ptopics for item in sublist])\n",
    "\n",
    "realtopics_df, avg_topic_proba = make_topics(topicsdf, FNAMES)\n",
    "testrealtopics_df,avg_topic_proba_test = make_topics(testtopicsdf, FNAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_topics(realtopicdata, cols, avg):\n",
    "    df = realtopicdata.drop(columns=cols)\n",
    "    for col in cols:\n",
    "        df[col]=realtopicdata[col].apply(lambda x: [1 if p > avg else 0 for p in x] if x is not None else None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bintopics_df=binarize_topics(realtopics_df, FNAMES, avg_topic_proba)\n",
    "testbintopics_df=binarize_topics(testrealtopics_df, FNAMES, avg_topic_proba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>known01</th>\n",
       "      <th>known02</th>\n",
       "      <th>known03</th>\n",
       "      <th>known04</th>\n",
       "      <th>known05</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EE001</th>\n",
       "      <td>Y</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE004</th>\n",
       "      <td>Y</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE005</th>\n",
       "      <td>N</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE008</th>\n",
       "      <td>Y</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE013</th>\n",
       "      <td>N</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer                                            known01  \\\n",
       "name                                                              \n",
       "EE001      Y  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "EE004      Y  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "EE005      N  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "EE008      Y  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "EE013      N  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 known02  \\\n",
       "name                                                       \n",
       "EE001  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "EE004                                               None   \n",
       "EE005  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "EE008  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "EE013  [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 known03  \\\n",
       "name                                                       \n",
       "EE001  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "EE004                                               None   \n",
       "EE005                                               None   \n",
       "EE008  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...   \n",
       "EE013  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 known04 known05  \\\n",
       "name                                                               \n",
       "EE001                                               None    None   \n",
       "EE004                                               None    None   \n",
       "EE005                                               None    None   \n",
       "EE008  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...    None   \n",
       "EE013  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...    None   \n",
       "\n",
       "                                                 unknown  \n",
       "name                                                      \n",
       "EE001  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "EE004  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "EE005  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "EE008  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "EE013  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bintopics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_vectors(binarized, knowncols):\n",
    "    df = binarized.drop(columns=FNAMES)\n",
    "    for i, col in enumerate(knowncols):\n",
    "        df['diff' + str(i)] = binarized.apply(lambda row: np.abs(np.subtract(row[col], row.unknown)) if row[col] is not None else None, axis=1)\n",
    "    return df\n",
    "\n",
    "train_df = subtract_vectors(bintopics_df, ['known01','known02','known03','known04','known05'])\n",
    "test_df = subtract_vectors(testbintopics_df, ['known01','known02','known03','known04','known05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, xcols):\n",
    "    X = []\n",
    "    y = []\n",
    "    for col in xcols:\n",
    "        xtemp=data[col].tolist()\n",
    "        ytemp=data[\"answer\"].tolist()\n",
    "        for xx, yy in zip(xtemp, ytemp):\n",
    "            if xx is not None:\n",
    "                X.append(xx)\n",
    "                if yy == \"Y\":\n",
    "                    y.append(1)\n",
    "                elif yy == \"N\":\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    raise AttributeError\n",
    "    assert(len(X) == len(y) and len(X) != 0)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = make_dataset(train_df, ['diff0', 'diff1', 'diff2', 'diff3', 'diff4'])\n",
    "X_test, y_test = make_dataset(test_df, ['diff0', 'diff1', 'diff2', 'diff3', 'diff4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      " c@1:  0.6563706563706564 \n",
      " auc:  0.6638928656645191  \n",
      " score(c@1*auc):  0.43575979599601644\n"
     ]
    }
   ],
   "source": [
    "c=clf.score(X_test, y_test)\n",
    "probas=clf.predict_proba(X_test)\n",
    "auc=roc_auc_score(y_test, probas[:,1])\n",
    "fs = c*auc\n",
    "print('Results:\\n c@1: ', c, '\\n auc: ', auc, ' \\n score(c@1*auc): ', fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "Results:\n",
    " c@1:  0.6563706563706564 \n",
    " auc:  0.6638928656645191  \n",
    " score(c@1*auc):  0.43575979599601644"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "12b4cd7862b680387f32f1cd3a2d818e44d87137"
   },
   "source": [
    "# LDA\n",
    "\n",
    "Latent Dirichlet Allocation, is an unsupervised generative model that assigns topic distributions to documents.\n",
    "\n",
    "At a high level, the model assumes that each document will contain several topics, so that there is topic overlap within a document. The words in each document contribute to these topics. The topics may not be known a priori, and needn't even be specified, but the **number** of topics must be specified a priori. Finally, there can be words overlap between topics, so several topics may share the same words.\n",
    "\n",
    "The model generates to **latent** (hidden) variables\n",
    "1) A distribution over topics for each document\n",
    "2) A distribution over words for each topics\n",
    "\n",
    "After training, each document will have a discrete distribution over all topics, and each topic will have a discrete distribution over all words.\n",
    "\n",
    "It is best to demonstrate this with an example. Let's say a document about the presidential elections may have a high contribution from the topics \"presidential elections\", \"america\", \"voting\" but have very low contributions from topics \"himalayan mountain range\", \"video games\", \"machine learning\" (assuming the corpus is varied enough to contain such articles); the topics \"presidential elections\" may have top contributing words [\"vote\",\"election\",\"people\",\"usa\",\"clinton\",\"trump\",...] whereas the top contributing words in the topic \"himalayan mountain range\" may be [\"nepal\",\"everest\",\"china\",\"altitude\",\"river\",\"snow\",....]. This very rough example should give you an idea of what LDA aims to do.\n",
    "\n",
    "An important point to note: although I have named some topics in the example above, the model itself does not actually do any \"naming\" or classifying of topics. But by visually inspecting the top contributing words of a topic i.e. the discrete distribution over words for a topic, one can name the topics if necessary after training. We will show this more later.\n",
    "\n",
    "There a several ways to implement LDA, however I will speak about collapsed gibbs sampling as I usually find this to be the easiest way to understand it.\n",
    "\n",
    "The model initialises by assigning every word in every document to a **random** topic. Then, we iterate through each word, unassign it's current topic, decrement the topic count corpus wide and reassign the word to a new topic based on the local probability of topic assignemnts to the current document, and the global (corpus wide) probability of the word assignments to the current topic. This may be hard to understand in words, so the equations are below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54cbacefcd1888fab2ed1214d5914bf005783890"
   },
   "source": [
    "### The mathematics of collapsed gibbs sampling (cut back version)\n",
    "\n",
    "Recall that when we iterate through each word in each document, we unassign its current topic assignment and reassign the word to a new topic. The topic we reassign the word to is based on the probabilities below.\n",
    "\n",
    "$$\n",
    "P\\left(\\text{document \"likes\" the topic}\\right) \\times P\\left(\\text{topic \"likes\" the word } w'\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\frac{n_{i,k}+\\alpha}{N_i-1+K\\alpha} \\times \\frac{m_{w',k}+\\gamma}{\\sum_{w\\in V}m_{w,k} + V\\gamma}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$n_{i,k}$ - number of word assignments to topic $k$ in document $i$\n",
    "\n",
    "$n_{i,k}$ - number of assignments to topic $k$ in document $i$\n",
    "\n",
    "$\\alpha$ - smoothing parameter (hyper parameter - make sure probability is never 0)\n",
    "\n",
    "$N_i$ - number of words in document $i$\n",
    "\n",
    "$-1$ - don't count the current word you're on\n",
    "\n",
    "$K$ - total number of topics\n",
    "\n",
    "\n",
    "$m_{w',k}$ - number of assignments, corpus wide, of word $w'$ to topic $k$\n",
    "\n",
    "$m_{w',k}$ - number of assignments, corpus wide, of word $w'$ to topic $k$\n",
    "\n",
    "$\\gamma$ - smoothing parameter (hyper parameter - make sure probability is never 0)\n",
    "\n",
    "$\\sum_{w\\in V}m_{w,k}$ - sum over all words in vocabulary currently assigned to topic $k$\n",
    "\n",
    "$V$ size of vocabulary i.e. number of distinct words corpus wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "acf75ae9276dbcdd9848b20e23c3ba48e863a63c"
   },
   "source": [
    "### Notes and Uses of LDA\n",
    "\n",
    "LDA has many uses; understanding the different varieties topics in a corpus (obviously), getting a better insight into the type of documents in a corpus (whether they are about news, wikipedia articles, business documents), quantifying the most used / most important words in a corpus, and even document similarity and recommendation.\n",
    "\n",
    "LDA does not work well with very short documents, like twitter feeds, as explained here [[1]](https://pdfs.semanticscholar.org/f499/5dc2a4eb901594578e3780a6f33dee02dad1.pdf) [[2]](https://stackoverflow.com/questions/29786985/whats-the-disadvantage-of-lda-for-short-texts), which is why we dropped articles under 40 tokens previously. Very briefly, this is because the model infers parameters from observations and if there are not enough observations (words) in a document, the model performs poorly. For short texts, although yet to be rigoursly tested, it may be best to use a [biterm model](https://pdfs.semanticscholar.org/f499/5dc2a4eb901594578e3780a6f33dee02dad1.pdf).\n",
    "\n",
    "Unlike the word2vec algorithm, which performs extremely well with full structured sentences, LDA is a bag of words model, meaning word order in a document doesnt count. This also means that stopwords and rare words should be excluded, so that the model doesnt overcompensate for very frequent words and very rare words, both of which do not contribute to general topics.\n",
    "\n",
    "#### Hyperparameters\n",
    "\n",
    "LDA has 2 hyperparameters: $\\alpha$ and $\\eta$\n",
    "\n",
    "$\\alpha$ - A low value for $\\alpha$ means that documents have only a low number of topics contributing to them. A high value of $\\alpha$ yields the inverse, meaning the documents appear more alike within a corpus.\n",
    "\n",
    "$\\eta$ - A low value for $\\eta$ means the topics have a low number of contributing words. A high value of $\\eta$ yields the inverse, meaning topics will have word overlap and appear more alike.\n",
    "\n",
    "The values of $\\alpha$ and $\\eta$ really depend on the application, and may need to be tweaked several times before the desired results are found... even then, LDA is non-deterministic since parameters are randomly initialised, so the outcome of any run of the model can never be known in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a80e9a5ebfde9b65425b7107afeb29ee9c1b1b5a"
   },
   "outputs": [],
   "source": [
    "dictionary,corpus,lda = train_lda(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d365bc72b57530fadc20816ef0b404482c041a60"
   },
   "source": [
    "### Let's inspect some topics!\n",
    "\n",
    "Bear in mind, when we see the words they may seem shortened. Recall this is because of our stemming function we previously implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc66c27d1a909fa6d90050f3310be4864082df36"
   },
   "outputs": [],
   "source": [
    "# show_topics method shows the the top num_words contributing to num_topics number of random topics\n",
    "lda.show_topics(num_topics=10, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c274c3ce894e40d867f4ab3d1fa3d4304c63edb2"
   },
   "source": [
    "#### We can inspect individual topics as such\n",
    "\n",
    "Note that if you re run the model again, as it is non-deterministic, word contributions to topics and topic ID's will change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f098f5a165a0c14c155167caedaec80c6e48f67"
   },
   "source": [
    "#### This topic is about court cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbdc6b184807a0cf8d0a0832a150e702ce102e70"
   },
   "outputs": [],
   "source": [
    "lda.show_topic(topicid=4, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3ce8492c016b819d751d69519302e848cbae950"
   },
   "source": [
    "#### This topic is about (supposedly) Illegal Immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31400ff04debbfe4738f9406ced3f2f0de85d61d"
   },
   "outputs": [],
   "source": [
    "lda.show_topic(topicid=85, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "355a1edb9f423920190d03d396d40c3b8fd90a89"
   },
   "source": [
    "#### This topic is about Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afb39e09e8e0bf4d84b6cabe55185922bbcdd3f3"
   },
   "outputs": [],
   "source": [
    "lda.show_topic(topicid=75, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f48593eb8ff3badcc80b770b7712d14446ac468"
   },
   "source": [
    "#### This topic is about Climate Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af43d900ed8f66b680998a18cf3a4e0e03bba214"
   },
   "outputs": [],
   "source": [
    "lda.show_topic(topicid=39, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bcacf7b0b1c937225f128aa140c29772cdb83ace"
   },
   "source": [
    "What the about above means, is that topic 4 has top contributing words [\"judge\",\"case\",\"court\",...], which indicates the topic is about court cases. Topic 75 has top contributing words [\"god\",\"christian\",\"love\",...], which indicates the topic is about religion.\n",
    "\n",
    "Now, not only can we see the word contribution for each topic, but we can also visualise the topic contribution for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f16119e7579d2e524c54c8aa0f1d4042d11766b"
   },
   "outputs": [],
   "source": [
    "# select and article at random from train_df\n",
    "random_article_index = np.random.randint(len(train_df))\n",
    "bow = dictionary.doc2bow(train_df.iloc[random_article_index,7])\n",
    "print(random_article_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5f9d41e31374bf6a4aa5c6401d46c5ea302ad19",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_df.iloc[random_article_index,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f719e07543cab10d54c02cedbd1a8ce517d1be37",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the topic contributions for the document chosen at random above\n",
    "doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=bow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af080e1e63e695756157509ccf055ab17205fcc8"
   },
   "outputs": [],
   "source": [
    "# bar plot of topic distribution for this document\n",
    "fig, ax = plt.subplots(figsize=(12,6));\n",
    "# the histogram of the data\n",
    "patches = ax.bar(np.arange(len(doc_distribution)), doc_distribution)\n",
    "ax.set_xlabel('Topic ID', fontsize=15)\n",
    "ax.set_ylabel('Topic Contribution', fontsize=15)\n",
    "ax.set_title(\"Topic Distribution for Article \" + str(random_article_index), fontsize=20)\n",
    "ax.set_xticks(np.linspace(10,100,10))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b50427ce3cfe5de33b9999686d8fa8a2cd0c6c32"
   },
   "source": [
    "Ok, so clearly this document has various contributions from different topics. But what are these topics? Lets find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1096ddc05022da80eeea33b1ff68a19e3c774460",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print the top 5 contributing topics and their words\n",
    "for i in doc_distribution.argsort()[-5:][::-1]:\n",
    "    print(i, lda.show_topic(topicid=i, topn=10), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97aefd11b71bc7adfd06045f2b5e89a3be556213"
   },
   "source": [
    "Let's interpret this.\n",
    "\n",
    "Topic 9  - Protests\n",
    "\n",
    "Topic 72 - Middl Eastern Countries\n",
    "\n",
    "Topic 36 - Islam\n",
    "\n",
    "Topic 55 - Power (socio political sense)\n",
    "\n",
    "Topic 38 - Peoples actions\n",
    "\n",
    "These are rough interpretations for these topics, most of which make sense. Reading the article we see the it is about riots in the Middle East. So the model seems to have worked well, at least in this one case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5756e67cdf9af09d6dca43f78995aa2412a19a8"
   },
   "source": [
    "# Similarity Queries and Unseen Data\n",
    "\n",
    "We will now turn our attention to the test set of data which the model has not yet seen. Although the articles in *test_df* have been unseen by the model, gensim has a way of infering their topic distributions given the trained model. Of course, the correct approach to yield accurate results would be to retrain the model with these new articles part of the corpus, but this can be timely and infeasable in a real case scenario where results are needed quickly.\n",
    "\n",
    "First, lets show how we can infer document topics for a new unseen article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e7afecbccde4fb17bcdb0ce7539d3cc1c4d104f"
   },
   "outputs": [],
   "source": [
    "# select and article at random from test_df\n",
    "random_article_index = np.random.randint(len(test_df))\n",
    "print(random_article_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "460e5be2729ef3dd7e6ec8f893d32dbc992fe7d1"
   },
   "source": [
    "Here's the important bit. In obtaining the BOW representation for this unseen article, gensim cleverly only considers words in the existing dictionary we used to train the model. So if there are new words in this article, they will not be considered when infering the topic distribution. This is good in that no errors arise for unseen words, but bad in that some words may be cut out, and therefore we could miss out on an accurate topic distribution for this article.\n",
    "\n",
    "However, we mitigate this risk because the training set is very much representative of the entire corpus; 99.9% of the observations are in the training set, with only 0.01% of observations in the test set. So most, if not all, words from the test set should be in the training set's dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0e6e61f1cb84acedea35c0c6dd311abc53fdc0c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_bow = dictionary.doc2bow(test_df.iloc[random_article_index,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91f7b357007722477594b9087ca282ae5b9364c1"
   },
   "outputs": [],
   "source": [
    "print(test_df.iloc[random_article_index,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "754832dc01bb39d1cca21b7bae4ef93bb4d598d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=new_bow)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9ee3321e7fdbe094fa62551411777fcfeda4627"
   },
   "source": [
    "Let's do the same visual analysis as before on this new unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "caf868f7619d8574807445a39da8d94f4cf0495a"
   },
   "outputs": [],
   "source": [
    "# bar plot of topic distribution for this document\n",
    "fig, ax = plt.subplots(figsize=(12,6));\n",
    "# the histogram of the data\n",
    "patches = ax.bar(np.arange(len(new_doc_distribution)), new_doc_distribution)\n",
    "ax.set_xlabel('Topic ID', fontsize=15)\n",
    "ax.set_ylabel('Topic Contribution', fontsize=15)\n",
    "ax.set_title(\"Topic Distribution for an Unseen Article\", fontsize=20)\n",
    "ax.set_xticks(np.linspace(10,100,10))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "690b18b03635c8bb717bccd9ca97c566fb66e8c6"
   },
   "outputs": [],
   "source": [
    "# print the top 8 contributing topics and their words\n",
    "for i in new_doc_distribution.argsort()[-5:][::-1]:\n",
    "    print(i, lda.show_topic(topicid=i, topn=10), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e2edaa8f89dfa2f6a7d6507d0ad814d30d23a30"
   },
   "source": [
    "And there we have it! An accurate topic distribution for an unseen document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1576aa73b17a4d7b250915640506d2db07f2a81f"
   },
   "source": [
    "### Similarity query\n",
    "\n",
    "Ok, now that we have a topic distribution for a new unseen document, let's say we wanted to find the most similar documents in the corpus. We can do this by comparing the topic distribution of the new document to all the topic distributions of the documents in the corpus. We use the [Jensen-Shannon distance](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence) metric to find the most similar documents.\n",
    "\n",
    "What the Jensen-Shannon distance tells us, is which documents are statisically \"closer\" (and therefore more similar), by comparing the divergence of their distributions. Jensen-Shannon is symmetric, unlike Kullback-Leibler on which the formula is based. This is good, because we want the similarity between documents A and B to be the same as the similarity between B and A.\n",
    "\n",
    "The formula is described below.\n",
    "\n",
    "For discrete distirbutions $P$ and $Q$, the Jensen-Shannon divergence, $JSD$ is defined as\n",
    "\n",
    "$$JSD\\left(P||Q\\right) = \\frac{1}{2}D\\left(P||M\\right)+\\frac{1}{2}D\\left(Q||M\\right)$$\n",
    "\n",
    "where $M = \\frac{1}{2}\\left(P+Q\\right)$\n",
    "\n",
    "and $D$ is the Kullback-Leibler divergence\n",
    "\n",
    "$$D\\left(P||Q\\right) = \\sum_iP(i)\\log\\left(\\frac{P(i)}{Q(i)}\\right)$$\n",
    "\n",
    "$$\\Rightarrow JSD\\left(P||Q\\right) = \\frac{1}{2}\\sum_i\n",
    "\\left[\n",
    "P(i)\\log\\left(\\frac{P(i)}{\\frac{1}{2}\\left(P(i)+Q(i)\\right)}\\right)\n",
    "+\n",
    "Q(i)\\log\\left(\\frac{Q(i)}{\\frac{1}{2}\\left(P(i)+Q(i)\\right)}\\right)\n",
    "\\right]$$\n",
    "\n",
    "The square root of the Jensen-Shannon divergence is the Jensen-Shannon Distance: $\\sqrt{JSD\\left ( P||Q\\right )}$\n",
    "\n",
    "**The smaller the Jensen-Shannon Distance, the more similar two distributions are (and in our case, the more similar any 2 documents are)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14d246d018b71919e51a1405b86d27ab4de2492a"
   },
   "source": [
    "We can use the scipy implementation of entropy to do this. Entropy calculates the KL divergence.\n",
    "\n",
    "But first, we need to get all our LDA topic distributions into a dense matrix. This will enable fast and efficient computation.\n",
    "\n",
    "We will create a dense matrix, **doc_topic_dist**, of size $M\\times K$ where $M$ is the number of documents and $K$ is the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5aa8bdf004b17efa3e3a1c6f512deed5ffd6e6e"
   },
   "outputs": [],
   "source": [
    "# we need to use nested list comprehension here\n",
    "# this may take 1-2 minutes...\n",
    "doc_topic_dist = np.array([[tup[1] for tup in lst] for lst in lda[corpus]])\n",
    "doc_topic_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "49330d856acde01162ee1968d1100280e8600b08",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jensen_shannon(query, matrix):\n",
    "    \"\"\"\n",
    "    This function implements a Jensen-Shannon similarity\n",
    "    between the input query (an LDA topic distribution for a document)\n",
    "    and the entire corpus of topic distributions.\n",
    "    It returns an array of length M where M is the number of documents in the corpus\n",
    "    \"\"\"\n",
    "    # lets keep with the p,q notation above\n",
    "    p = query[None,:].T # take transpose\n",
    "    q = matrix.T # transpose matrix\n",
    "    m = 0.5*(p + q)\n",
    "    return np.sqrt(0.5*(entropy(p,m) + entropy(q,m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96d8a5efab892371fc220c8dc158e244afbac5ff"
   },
   "source": [
    "Let's compare the new unseen document, to the corpus, and see which articles are most similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a722a8d097dd1821b68fed471116e4dc693ac406",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_most_similar_documents(query,matrix,k=10):\n",
    "    \"\"\"\n",
    "    This function implements the Jensen-Shannon distance above\n",
    "    and retruns the top k indices of the smallest jensen shannon distances\n",
    "    \"\"\"\n",
    "    sims = jensen_shannon(query,matrix) # list of jensen shannon distances\n",
    "    return sims.argsort()[:k] # the top k positional index of the smallest Jensen Shannon distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecd1f80f12a5ca49b426138c2e969d688e872acd"
   },
   "source": [
    "#### Query time + most similar documents... at last!\n",
    "\n",
    "Ok, let's be 100% clear about what we are doing here.\n",
    "\n",
    "We are comparing the new unseen document above to the entire corpus of ~10k documents to find which one is most similar to the new document.\n",
    "\n",
    "How are we doing that? Well, we have the new documents LDA topic distribution in stored as varibale **new_doc_distribution**, and we have the entire corpus of documents topic distributions stored in the dense matrix **doc_topic_dist**. So now, we pass each row of **doc_topic_dist** through the Jensen-Shannon function above as the Q distribution, while the P distribution remains static as **new_doc_distribution**. Then we get the smallest distances and their corresponding index in the array, which we can pass to the **train_df** dataframe to print out the most similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abf60ca921774f22a50035be37a9bc99e23afc0b"
   },
   "outputs": [],
   "source": [
    "# this is surprisingly fast\n",
    "most_sim_ids = get_most_similar_documents(new_doc_distribution,doc_topic_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43b3f66c3e9c26e5b9f17504f21c8e2a08659e80",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_similar_df = train_df[train_df.index.isin(most_sim_ids)]\n",
    "most_similar_df['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c2154320f890dfc60d697821033ef665458e5d5"
   },
   "source": [
    "I think we can see, the top most similar articles are quite similar indeed to the query article ;)\n",
    "\n",
    "Our query article is about Trump, Huffington Post and the election. The top 10 most similar documents in the corpus also contain these topics, as their title show above. The reader can print out the full articles, or visualise the topic distributions for the most similar document and compare them to the query document to check the overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eef6d26bad60a383994dd59869fda9205e4b341e"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "- After cleaning the corpus and keeping only the top 15,000 words, we reduced the unique words in the corpus by 84%\n",
    "- The average document length is halved to 345 tokens after cleaning, compared to the raw version we saw in our explore notebook using word2vec\n",
    "- The LDA algorithm was explained in detail\n",
    "- The LDA model was able to accurately identify different topics in the fake news corpus. We visually inspected these topics to see that the top words were related\n",
    "- We were able to infer a topic distribution from a new unseen document\n",
    "- We quickly retrieved the most similar documents in the trained corpus when comparing to the new unseen document. These most similar documents were in fact closely related to the query document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
