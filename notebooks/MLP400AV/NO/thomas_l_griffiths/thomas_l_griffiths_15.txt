Abstract

We present a framework for the rational analysis of elemental causal inductionlearning
about the existence of a relationship between a single cause and eectbased upon causal
graphical models. This framework makes precise the distinction between causal structure
and causal strength: the dierence between asking whether a causal relationship exists and ask-
ing how strong that causal relationship might be. We show that two leading rational models of
elemental causal induction, DP and causal power, both estimate causal strength, and we
introduce a new rational model, causal support, that assesses causal structure. Causal support
predicts several key phenomena of causal induction that cannot be accounted for by other
rational models, which we explore through a series of experiments. These phenomena include
the complex interaction between DP and the base-rate probability of the eect in the absence
of the cause, sample size eects, inferences from incomplete contingency tables, and causal

q We thank Russ Burnett, David Lagnado, Tania Lombrozo, Brad Love, Doug Medin, Kevin Murphy,
David Shanks, Steven Sloman, and Sean Stromsten for helpful comments on previous drafts of this paper,
and Liz Bara, Onny Chatterjee, Danny Oppenheimer, and Davie Yoon for their assistance in data
collection. Klaus Melcher and David Shanks generously provided their data for our analyses. Initial
results from Experiment 1 were presented at the Neural Information Processing Systems conference,
December 2000. TLG was supported by a Hackett Studentship and a Stanford Graduate Fellowship. JBT
was supported by grants from NTT Communication Science Laboratories, Mitsubishi Electric Research
Laboratories, and the Paul E. Newton chair.

* Corresponding author. Present address: Department of Cognitive and Linguistic Sciences, Brown

University, Box 1978, Providence RI 02912, USA.

E-mail address: Tom_Griths@brown.edu (T.L. Griths).

0010-0285/$ - see front matter  2005 Elsevier Inc. All rights reserved.
doi:10.1016/j.cogpsych.2005.05.004

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

335

learning from rates. Causal support also provides a better account of a number of existing
datasets than either DP or causal power.
 2005 Elsevier Inc. All rights reserved.

Keywords: Causality; Causal induction; Computational modeling; Rational analysis; Bayesian models

The contagion spread rapidly and before its progress could be arrested, sixteen
persons were aected of which two died. Of these sixteen, eight were under my
care. On this occasion I used for the rst time the ausion of cold water, in the
manner described by Dr. Wright. It was rst tried in two cases. . . The eects
corresponded exactly with those mentioned by him to have occurred in his
own case and thus encouraged the remedy was employed in ve other cases.
It was repeated daily, and of these seven patients, the whole recovered. (James
Currie, 1798/1960, p. 430)

1. Introduction

Statistical methods for evaluating the relationships between variables were only
developed at the end of the 19th century, more than 200 years after the birth of modern
science. The foundations of physics, chemistry, biology, and medicine were all laid be-
fore formal methods for analyzing correlations or contingency tables existed. Even dif-
cult statistical problems like evaluating medical treatments were addressed by early
scientists, as the epigraph illustrates. Its author, Dr. James Currie, was an 18th century
ships surgeon who later went into practice in Liverpool. After having heard a Dr. Wil-
liam Wright give an account of the ecacy of being doused with cold water in treating
an extended fever, Currie conducted his own experiment, with results described above.
He was suciently encouraged that he went on to use the treatment with hundreds of
other patients, publishing a detailed treatise on the matter (Currie, 1798/1960). Wash-
ing the skin of the patient is still used to ease fevers, although modern medicine cautions
against using water cold enough to induce shivering.

While the development of statistical methods for designing and analyzing exper-
iments has greatly streamlined scientic argument, science was possible before statis-
tics: in many cases, the causal relationships between variables that are critical to
understanding our world could be discovered without any need to perform explicit
calculations. Science was possible because people have a capacity for causal induc-
tion, inferring causal structure from data. This capacity is suciently accurate as
to have resulted in genuine scientic discoveries, and provides the basis for the con-
struction of the intuitive theories that express our knowledge about the world. Cur-
ries assessment of the water treatment is directly analogous to the kinds of causal
inferences we perform every day, such as evaluating whether taking vitamins pre-
vents us from getting sick, or whether drinking coee increases our productivity.

The most basic problem of causal induction is learning that a relationship exists
between a single cause and eect. This problem of elemental causal induction has been

336

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

the subject of most previous studies of human causal judgment. This simplest case is
suciently constrained to allow rigorous testing of mathematical models against
peoples judgments of causeeect relations. Recent accounts of elemental causal
induction have emphasized the rational basis of human learning, presenting formal
analyses of how an agent should learn about causal relationships (e.g., Anderson,
1990; Cheng, 1997; Lo pez, Cobos, Cano, & Shanks, 1998). This strategy has resulted
in several distinct mathematical models of causal judgment, none of which explains
all of the phenomena of causal induction. Consequently, there is an ongoing debate
about which model gives a better account of human judgments (e.g., Cheng, 1997;
Lober & Shanks, 2000).

In this paper, we present a framework for analyzing the computational problem of
elemental causal induction, based on causal graphical models. Causal graphical models
are a set of tools for learning and reasoning about causal relationships that has been
developed by computer scientists, statisticians, and philosophers (e.g. Pearl, 2000; Spir-
tes, Glymour, & Schienes, 1993). Our framework claries the assumptions made by
previous rational models, such as DP (Allan, 1980; Jenkins & Ward, 1965; Lo pez
et al., 1998) and causal power (Cheng, 1997), and results in a fundamentally dierent
model of human judgments, which we call causal support. While previous models
view human judgments as reecting the strength of a causal relationship, causal support
addresses the structural question of whether or not a causal relationship exists.

Causal graphical models have recently become the focus of a great deal of interest
among cognitive scientists, with several studies examining the extent to which human
causal reasoning corresponds to the qualitative assumptions of this approach (Danks
& McKenzie, submitted; Gopnik et al., 2004; Glymour, 1998, 2001; Lagnado & Slo-
man, 2002; Waldmann & Martignon, 1998). Our work extends these results by show-
ing that causal graphical models can be used to make quantitative predictions about
human behavior (e.g., Steyvers, Tenenbaum, Wagenmakers, & Blum, 2003; Tenen-
baum & Griths, 2001, 2003). The framework we present here uses causal graphical
models to explicate the roles of structure and strength in the problem of causal
induction, and in dening causal support, our model of human judgments.

Causal support predicts several phenomena that are problematic for other ra-
tional models. Our presentation will be organized around these phenomena. The rst
phenomenon we will consider is the interaction between covariation, measured by
DP, and the base-rate probability of the eect in the absence of the cause in deter-
mining human judgments. This interaction manifests in two curious phenomena,
the frequency illusiona decrease in causal judgments as the base-rate decreases
when DP = 0 (Allan & Jenkins, 1983; Buehner, Cheng, & Cliord, 2003; Shanks, Lo -
pez, Darby, & Dickinson, 1996)and non-monotonic eects of changes in base-rate
at other values of DP (Lober & Shanks, 2000). We will also discuss eects of sample
size (White, 1998, 2002c, 2003c), inferences from incomplete contingency tables, and
causal induction from rates (c.f. Anderson & Sheu, 1995; Wasserman, 1990). No
other rational model of can explain all of these phenomena, or t as wide a range
of datasets as causal support.

The plan of the paper is as follows. First we outline the problem of elemental
causal induction in more detail, describing the experimental paradigms that are

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

337

Table 1
Contingency table representation used in elemental causal induction

Cause present (c+)
)
Cause absent (c

Eect present (e+)
N(e+, c+)
)
N(e+, c

Eect absent (e

)

, c+)
)
, c

N(e
N(e

the focus of our investigation, the two leading rational models, DP and causal power,
and some of the data that has been gathered in support of them. Then, we provide a
brief summary of causal graphical models, present our framework for analyzing the
problem of elemental causal induction, and use this to derive causal support. The
body of the paper discusses the phenomena predicted by causal support but not
by other models, explaining the statistical origins of these predictions. We close by
considering the circumstances under which we expect causal support to be most con-
sistent with human judgments, its relationship with ideas such as reliability (Bueh-
ner & Cheng, 1997; Perales & Shanks, 2003), and how this account of elemental
causal induction can be extended to shed light on other aspects of causal learning.

2. Elemental causal induction

Much psychological research on causal induction has focused upon the problem
of learning a single causal relation: given a candidate cause, C, and a candidate eect,
E, people are asked to assess the relationship between C and E.1 Most studies present
information corresponding to the entries in a 2  2 contingency table, as in Table 1.
People are given information about the frequency with which the eect occurs in the
)
presence and absence of the cause, represented by the numbers N(e+, c+),N(e
and so forth. In a standard example, C might be injecting a chemical into a mouse,
and E the expression of a particular gene. For this case, N(e+, c+) would be the num-
) would be the number of
ber of injected mice expressing the gene, while N(e
uninjected mice not expressing the gene.

, c

, c

This contingency information is usually presented to participants in one of three
modes. Early experiments on causal induction would either explicitly provide partic-
ipants with the numbers contained in the contingency table (e.g., Jenkins & Ward,
1965), which we will refer to as a summary format, or present individual cases
one by one, with the appropriate frequencies (e.g., Ward & Jenkins, 1965), which
we will refer to as an online format. Some more recent experiments use a mode
of presentation between these two extremes, showing a list of all individual cases
simultaneously (e.g., Buehner et al., 2003; White, 2003c), which we will refer to as
a list format.

1 We will represent variables such as C, E with capital letters, and their instantiations with lowercase
 indicating that the cause or eect

letters, with c+, e+ indicating that the cause or eect is present, and c
is absent.

, e

338

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

Experiments also dier in the questions that are asked of the participants.
Participants can be asked to rate the strength of the causal relationship, the
probability of a causal relationship, or their condence that a causal relation-
ship exists. Understanding the eects of question wording is an ongoing task
(e.g., White, 2003b), but one variable that has been shown to have a strong
eect is asking counterfactual questions, such as What is the probability that
a mouse not expressing the gene before being injected will express it after being
injected with the
et al., 2003; Collins & Shanks,
submitted).

chemical?

(Buehner

Causal induction tasks also vary in their treatment of the valence of the potential
cause, and the nature of the rating scale used for responses. Causes can be either
generative, increasing the probability of an outcome (as in our mouse gene exam-
ple), or preventive, reducing its probability (as in the case of Dr. Curries cold
water treatment). Some experiments use exclusively generative or exclusively preven-
tive causes and ask for judgments on a nonnegative scale (e.g., 0100), while others
mix generative and preventive causes and ask for judgments on a scale that has both
positive and negative ends (e.g., 100 to 100).

Given the many ways in which experiments on causal judgment can dier, it
is important to identify the scope of the present analysis. We will discuss exper-
iments that use all three modes of presentation, as each mode captures an aspect
of causal
induction that is important for the development of rational models:
the summary format removes memory demands and allows a deliberative infer-
ence, the online format taps intuitions about causality that are engaged by direct
interaction with data, and the list format falls between these extremes. We will
focus on experiments that require participants to make judgments about poten-
tial causes of a single kind, generative or predictive. Most of the critical datasets
in the current debate about rational models of causal induction are of this form
(e.g., Buehner & Cheng, 1997; Lober & Shanks, 2000). In Section 15, we will
consider how our framework can be extended to shed light on other issues in
causal induction, including learning about multiple potential causes, the dynam-
ics of causal judgments in online tasks, and combining generative and preventive
causes.

2.1. Rational models of elemental causal induction

In the spirit of Marrs (1982) computational level and Andersons (1990) ra-
tional analysis, recent theories have tried to establish the task of causal induction
as a computational problem and use the optimal solution to that problem to ex-
plain human behavior. We will describe two leading rational models of causal
induction which are at the center of a debate about modeling causal judgments:
DP and causal power.

2.1.1. DP and associative strength

One common approach to modeling judgments about causal relationships is to

combine the frequencies from a contingency table in the form

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

339

DP 

Ne; c

Ne; c  Ne; c 

Ne; c

Ne; c  Ne; c  Pejc  Pejc;

1
where P(e+|c+) is the empirical conditional probability of the eect given the pres-
ence of the cause, estimated from the contingency table counts N(). DP thus reects
the change in the probability of the eect occuring as a consequence of the occurence
of the cause. This measure was rst suggested by Jenkins and Ward (1965), subse-
quently explored by Allan (Allan, 1980, 1993; Allan & Jenkins, 1983), and has ap-
peared in various forms in both psychology and philosophy (Cheng & Holyoak,
1995; Cheng & Novick, 1990, 1992; Melz, Cheng, Holyoak, & Waldmann, 1993;
Salmon, 1980). One argument for the appropriateness of DP as a normative model
uses the fact that it is the asymptotic value of the weight given to the cause C when
the causal induction task is modeled with a linear associator trained using the Resc-
orlaWagner (Rescorla & Wagner, 1972) learning rule (Cheng, 1997; Cheng & Holy-
oak, 1995; Chapman & Robbins, 1990; Danks, 2003; Wasserman, Elek, Chatlosh, &
Baker, 1993).

2.1.2. The power PC theory and causal power

Cheng (1997) rejected DP as a measure of causal strength because it is a mea-
sure of covariation, not causality. According to Cheng (1997) and Novick and
Cheng (2004), human judgments reect a set of assumptions about causality that
dier from those of purely covariational measures such as DP and conventional
statistics. Chengs (1997) power PC theory attempts to make these assumptions
explicit, providing an axiomatic characterization of causality and proposing that
human causal judgments correspond to causal power, the probability that C
produces E in the absence of all other causes. Causal power for a generative
cause can be estimated from contingency data, with Cheng (1997) giving the
expression:

power 

DP

1  Pejc .

2

Causal power takes DP as a component, but predicts that DP will have a greater ef-
) is large. Causal power can also be evaluated for preventive causes,
fect when P(e+|c
following from a similar set of assumptions about the nature of such causes. The
causal power for a preventive cause is

power   DP

Pejc .

3

For preventive causes, the eect of P(e+|c+) on causal power is reversed, with DP
having a greater inuence when P(e+|c+) is small.

The measure of causal power in Eq. (2) can be derived from a counterfactual
treatment of sucient cause (Pearl, 2000). Causal power corresponds to the
probability that, for a case in which C was not present and E did not occur,
introduced. This probability depends upon DP,
E would occur

if C was

340

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

corresponding to the raw increase in occurrences of E, but has to be normalized
by the proportion of the cases in which C could actually have inuenced E. If
some of the cases already show the eect, then C had no opportunity to inuence
those cases and they should not be taken into account when evaluating the
introduces
strength
) in the denominator. Pearl (2000) derives DP from a similar
P(e
treatment of necessary and sucient cause.

C.
) = 1P(e+|c

requirement

of

normalization

of

The

|c

To illustrate the dierence between causal power and DP, consider the problem
of establishing whether injecting chemicals into mice results in gene expression.
Two groups of 60 mice are used in two experiments evaluating the eect of dier-
ent chemicals on dierent genes. In each experiment, one group is injected with the
chemical, and the other group receives no injection. In the rst experiment, 30 of
) = 0.5, and 36 of the injected mice
the uninjected mice express the gene, P(e+|c
express it, P(e+|c+) = 0.6. In the second experiment, 54 of the uninjected mice ex-
press the gene, P(e+|c
the injected mice express it,
P(e+|c+) = 1. In each case DP = 0.1, but the second set of results seem to provide
more evidence for a relationship between the chemical and gene expression. In par-
ticular, if we imagine that the frequency of gene expression among the uninjected
mice would be reproduced exactly in the other group of mice prior to injection, it
seems that the rst chemical produces gene expression in only six of the thirty mice
who would not have otherwise expressed the gene, while all of the mice not
expressing the gene in the second experiment have their fates altered by the injec-
tion. This dierence is reected in causal power, which is 0.2 in the rst case and 1
in the second.

) = 0.9, and all 60 of

2.2. The debate over rational models

DP and causal power make dierent predictions about the strength of causal
relationships, and several experiments have been conducted with the aim of deter-
mining which model gives a better account of human data (e.g., Buehner &
Cheng, 1997; Collins & Shanks, submitted; Lober & Shanks, 2000; Perales &
Shanks, 2003; Shanks, 2002; Vallee-Tourangeau, Murphy, Drew, & Baker,
1998). Each model captures some of the trends identied in these experiments,
but there are several results that are predicted by only one of the models, as well
as phenomena that are predicted by neither. These negative results are almost
equally distributed between the two models, and suggest that there may be some
basic factor missing from both. The problem can be illustrated by considering two
sets of experiments: those conducted by Buehner and Cheng (1997) and Lober and
Shanks (2000).

The experiments conducted by Buehner and Cheng (1997; Buehner et al., 2003)
explored how judgments of the strength of a causal relationship vary when DP is held
constant. This was done using an experimental design adapted from Wasserman
et al. (1993), giving 15 sets of contingencies expressing all possible combinations
) and DP in increments of 0.25. Experiments were conducted with both
of P(e+|c
generative causes, for which C potentially increases the frequency of E as in the cases

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

341

described above, and preventive causes, for which C potentially decreases the fre-
quency of E, and with both online and summary formats. For the moment, we will
focus on the online study with generative causes (Buehner & Cheng, 1997, Experi-
ment 1B), where a total of 16 trials gave the contingency information. The results
of this experiment showed that at constant values of DP, people made judgments
). Furthermore, this sensitivity was consis-
that were sensitive to the value of P(e+|c
tent with the role of P(e+|c

) in causal power.

However, as was pointed out by Lober and Shanks (2000), the results also proved
problematic for the Power PC theory. The design used by Buehner and Cheng (1997)
provides several situations in which sets of contingencies give the same value of caus-
al power. The data are shown in Fig. 1, together with the values of DP and causal
power. DP and causal power gave r scores of .889 and .881, respectively, with scaling

P(e+|c+)
P(e+|c)

100

8/8
8/8

6/8
6/8

4/8
4/8

2/8
2/8

0/8
0/8

8/8
6/8

6/8
4/8

4/8
2/8

2/8
0/8

8/8
4/8

6/8
2/8

4/8
0/8

8/8
2/8

6/8
0/8

8/8
0/8

Humans

 P

Power

Support

2

50

0

100

50

0

100

50

0

100

50

0

100

50

0

Fig. 1. Predictions of rational models compared with the performance of human participants from
Buehner and Cheng (1997, Experiment 1B). Numbers along the top of the gure show stimulus
contingencies, error bars indicate one standard error.

342

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

parameters c = 0.98, 1.05.2 As can be seen from the gure, both DP and causal
power predict important trends in the data, but since these trends are orthogonal,
neither model provides a full account of human performance. The only sets of con-
tingencies for which the two models agree are those where DP is zero. For these
cases, both models predict negligible judgments of the strength of the causal relation-
ship. In contrast to these predictions, people give judgments that seem to decrease
) decreases. Similar eects with DP = 0 have been observed
systematically as P(e+|c
in other studies (e.g., Allan & Jenkins, 1983; Shanks et al., 1996), where the phenom-
enon is referred to as the frequency illusion.

In a further test of the two theories, Lober and Shanks (2000) conducted a series
of experiments in which either causal power or DP was held constant while the other
varied. These experiments used both online (Experiments 13) and summary (Exper-
iments 46) formats. The results showed systematic variation in judgments of the
strength of the causal relationship at constant values of causal power, in a fashion
consistent with DP. The results of Experiments 46 are shown in Fig. 2, together with
the values of DP and causal power. The models gave r scores of .980 and .581,
respectively, with c = 0.8, 1.1. While DP gave a good t to these data, the human
)} of {30/30, 18/30}, {24/30, 12/
judgments for contingencies with {P(e+|c+),P(e+|c
30}, {12/30, 0/30} are not consistent with DP: they show a non-monotonic trend,
with smaller judgments for {24/30,12/30} than for either of the extreme cases. The
quadratic trend over these three sets of contingencies was statistically signicant,
but Lober and Shanks (2000) stated that . . . because the eect was non-linear, it
probably should not be given undue weight (p. 209). For the purposes of Lober
and Shanks, this eect was not important because it provided no basis for discrim-
ination between DP and causal power: neither of these theories can predict a non-
monotonic change in causal judgments as a function of the base-rate probability
P(e+|c

).

The results of Buehner and Cheng (1997) and Lober and Shanks, 2000 illustrate
that neither DP nor causal power provides a full account of peoples judgments in
causal induction tasks. These are not isolated results: DP and causal power cannot
explain several other phenomena of human causal induction. One of these phenom-
ena is the eect of sample size: both DP and causal power are dened using the con-
ditional probabilities P(e|c), and are thus insensitive to the number of observations
expressing those probabilities. However, human judgments change as the number
of observations contributing to a contingency table varies (White, 1998, 2002c,
2003c). Another is inferences from incomplete data: people can assess causal rela-
tionships in circumstances where there is not enough information to compute the

2 In each case where we have t a computational model to empirical data, we have used a scaling
transformation to account for the possibility of non-linearities in the rating scale used by participants. This
is not typical in the literature, but we feel it is necessary to separate the quantitative predictions from a
dependency on the linearity of the judgment scalean issue that arises in any numerical judgment task.
We use the transformation y = sign(x) abs(x)c, where y are the transformed predictions, x the raw
predictions, and c a scaling parameter selected to maximize the linear correlation between the transformed
predictions and the data. This power law transformation accommodates a range of non-linearities.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

343

27/30
20/30

24/30
10/30

21/30
0/30

28/28
21/28

28/28
14/28

28/28
7/28

28/28
0/28

30/30
18/30

24/30
12/30

12/30
0/30

27/30
25/30

Humans

 P

Power

Support

2

P(e+|c+)
P(e+|c)
100

50

0

100

50

0

100

50

0

100

50

0

100

50

0

Fig. 2. Predictions of rational models compared with the performance of participants from Lober and
Shanks (2000, Experiments 46). Numbers along the top of the gure show stimulus contingencies.

conditional probabilities of the eect in the presence and the absence of the cause. In
the early stages of both everyday and scientic inferences, we might be presented
with an incomplete contingency table. Neither DP nor causal power can explain
the judgments that people make from such data. Finally, people are able to learn
about causal relationships from data other than contingencies, such as the rate at
which an eect is observed in the presence and absence of a cause (e.g., Anderson
& Sheu, 1995). DP and causal power are not dened for rate data, even though it
is extremely similar to contingency data.

In the remainder of the paper, we will use a computational framework based on
causal graphical models to provide insight into the problems of DP and causal
power, and to derive a new model of causal induction. We will argue that the di-
culties faced by DP and causal power arise because people are often sensitive to the
structural question of whether or not a causal relationship exists, and both DP and

344

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

causal power model human judgments purely in terms of the strength of a causal
relationship. Our framework makes the distinction between structure and strength
precise, and allows us to dene a new model, causal support, which addresses this
structural question. We will show that causal support accurately predicts human
judgments in all of the settings mentioned above.

3. Causal graphical models

Our framework for analyzing elemental causal induction will use causal graphical
models, a formalism for learning and reasoning about causal relationships that is a
current topic of research in computer science and statistics (e.g., Pearl, 2000; Spirtes
et al., 1993) and is beginning to be applied in cognitive science (Danks & McKenzie,
submitted; Gopnik et al., 2004; Glymour, 1998, 2001; Lagnado & Sloman, 2002;
Rehder, 2003; Steyvers et al., 2003; Tenenbaum & Griths, 2001, 2003; Waldmann
& Martignon, 1998). Causal graphical models, also known as causal Bayesian net-
works or causal Bayes nets, provide a means of specifying the causal relationships
that hold among a set of variables. Our brief summary of causal graphical models
will touch on three important issues: causal structure, functional causal relation-
ships, and the dierence between learning structure and estimating parameters.

3.1. Causal structure

A graphical model provides an intuitive representation for the causal structure
relating a set of variables. Nodes in the graph represent variables, and directed edges
represent causal connections between those variables (Glymour, 1998, 1999; Pearl,
2000; Spirtes et al., 1993). The result is a directed graph, with parent nodes having
arrows to their children. For example, consider the directed graphs denoted
Graph 0 and Graph 1 in Fig. 3, which we will later use in describing our framework
for elemental causal induction. Both graphs are dened over three binary variables
an eect E, a potential cause C, and a background cause B, capturing the combined

Graph 0

Graph 1

B

C

B

C

E

E

Fig. 3. Directed graphs involving three variables, B, C, and E, relevant to elemental causal induction. B
represents background variables, C a potential causal variable, and E the eect of interest. Graph 1, is
assumed in computing DP and causal power. Computing causal support involves comparing the structure
of Graph 1 to that of Graph 0, in which C and E are independent.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

345

eect of all other causes of E. Each graph represents a hypothesis about the causal
relations that could hold among these variables. In Graph 0, B causes E, but C has
no relationship to either B or E. In Graph 1, both B and C cause E.

3.2. Functional causal relationships

The graph structure used in a causal graphical model identies the causal relation-
ships among variables, but says nothing about the precise nature of these relation-
shipsthey could be deterministic or probabilistic, and multiple causes of an
eect could act independently or interact strongly. The functional form of a causal
relationship encodes all of this information, and translates a causal structure into
a probability distribution over the variables that form its nodes.

Any causal graphical model with variables {X1, . . . , Xn} implies a probability dis-
tribution of the form P(X1, . . . , Xn) = i P(Xi|Pa(Xi)), where Pa(Xi) is the set of par-
ents of the node associated with Xi. This factorization of the probability distribution
follows from the assumption that each variable Xi is independent of all of its non-de-
scendants in the graph when conditioned upon its causes, Pa(Xi). This assumption is
called the causal Markov condition, and the relationship between statistical depen-
dence and causation that it implies forms the basis of many algorithms for learning
causal structure (e.g., Pearl, 2000; Spirtes et al., 1993).

While causal structure determines the dependencies expressed in a distribution,
the actual probability distribution depends upon the choice of the conditional
probabilities P(Xi|Pa(Xi)). Specifying these probabilities requires choosing a param-
eterization for each node, stating how the probability distribution over that vari-
able depends upon the values of its parents. This parameterization determines
the functional form of the causal relationship. Sometimes the parameterization is
trivialfor example, in Graph 0, we need to specify only P0(E|B), where the sub-
script indicates that this probability is associated with Graph 0. This can be done
using a single numerical parameter w0 which provides the probability that the eect
will be present in the presence of the background cause, P0(e+|b+; w0) = w0. How-
ever, when a node has multiple parents, there are many dierent ways in which the
functional relationship between causes and eects could be dened. For example,
in Graph 1 we need to account for how the causes B and C interact in producing
the eect E.

The conditional probability distribution associated with a node can be any prob-
abilistically sound function of its parents, including a deterministic function. Dier-
ent assumptions about the kinds of mechanisms in a domain naturally lead to
dierent functional forms for this dependency, so there will not be a single function-
al form that can be used to characterize all settings in which causal learning takes
place. Here, we consider three simple functional forms for the relationship between
B, C, and E: noisy-OR, noisy-AND-NOT, and linear. These functional forms char-
acterize some of the dierent ways in which causes combine to inuence their eects,
and will be used in our analysis of previous accounts of causal induction. All three
parameterizations assume that E is a binary random variableon each trial, E
either occurs or does not. Later in the paper, in Section 12, we will introduce a

346

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

Poisson parameterization that can be used when the available data concern the rate
at which the eect occurs in an interval.

The noisy-OR parameterization (Pearl, 1988) results from a natural set of
assumptions about the relationship between cause and eect. For Graph 1, these
assumptions are that B and C are both generative causes, increasing the probability
of the eect; that the probability of E in the presence of just B is w0, and in the pres-
ence of just C is w1; and that, when both B and C are present, they have independent
opportunities to produce the eect. This gives

 = c

P 1ejb; c; w0; w1  1  1  w0b1  w1c.

4
where w0, w1 are parameters associated with the strength of B, C, respectively, and
 = 0 for the purpose of arithmetic operations. This expression
b+ = c+ = 1,b
gives w0 for the probability of E in the presence of B alone, and w0 + w1w0w1 for
the probability of E in the presence of both B and C. This parameterization is called
a noisy-OR because if w0 and w1 are both 1, Eq. (4) reduces to the logical OR function:
the eect occurs if and only if B or C are present. With w0 and w1 in the range [0, 1] it
generalizes this function to allow probabilistic causal relationships.

An analogous parameterization for preventive causes can be derived from a set of
assumptions similar to those made in the noisy-OR. In the case of Graph 1, these
assumptions are that B has the opportunity to produce E with probability w0, and
C independently prevents E from occurring with probability w1. The resulting
noisy-AND-NOT generalizes the logical statement that E will occur if B occurs
and not C, allowing the inuence of these factors to be probabilistic. The conditional
probability can be written as
P 1ejb; c; w0; w1  wb

5
which gives w0 for the probability of E in the presence of just B, and w0(1w1) when
both B and C are present. As with the noisy-OR, both w0 and w1 are constrained to
lie in the range [0,1].

01  w1c;

Finally, a linear parameterization of Graph 1 assumes that the probability of E
occuring is a linear function of B and C. This corresponds to assuming that the pres-
ence of a cause simply increases the probability of an eect by a constant amount,
regardless of any other causes that might be present. There is no distinction between
generative and preventive causes. The result is

P 1ejb; c; w0; w1  w0  b  w1  c.

6
This parameterization requires that we constrain w0 + w1 to lie between 0 and 1 to
ensure that Eq. (6) results in a legal probability distribution. Because of this depen-
dence between parameters, this parameterization is not normally used for causal
graphical models. A similar set of assumptions can be captured using the more stan-
dard logistic parameterization (e.g., Neal, 1992), in which the parameters for dier-
ent causes can vary independently from strongly positive (generative) to strongly
negative (preventive). We consider the linear parameterization here because, as we
show in the next section, it implicitly underlies one of the leading psychological mod-
els of causal judgment.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

347

3.3. Structure learning and parameter estimation

Constructing a causal graphical model from a set of observed data involves two
kinds of learning: structure learning and parameter estimation. Structure learning re-
fers to identication of the topology of the causal graph, while parameter estimation
involves determining the parameters of the functional relationships between causes
and eects for a given causal structure. Structure learning is arguably more funda-
mental than parameter estimation, since the parameters can only be estimated once
the structure is known. Learning the causal structure among many variables is a dif-
cult computational problem, as the number of possible structures is a super-expo-
nential function of the number of variables.

There are several approaches to parameter estimation in graphical models (e.g.,
Heckerman, 1998). The simplest approach is maximum-likelihood estimation. For
a particular graphical structure and parameterization, the likelihood of a set of
parameters given data D is the probability of D under the distribution specied by
that structure, parameterization, and choice of parameter values. For example, if
D is summarized by contingencies N(e, c), the likelihood for the parameters w0, w1
in Graph 1 is given by

Y

P 1Djw0; w1; Graph 1 

P 1ejc; b; w0; w1Ne;c

;

e;c

7

where the product is taken over all pairs of e+, e
estimate is a choice of values for w0, w1 that maximizes P1(D|w0, w1, Graph 1).

 and c+, c

. A maximum-likelihood

Structure learning attempts to identify the causal structure underlying a set of ob-
served data. There are two major approaches to structure learning: constraint-based
learning, and Bayesian inference. In constraint-based learning, constraints on possi-
ble causal structures are inferred by evaluating the statistical dependencies among
variables, and sets of causal structures that satisfy these constraints are logically de-
rived from these constraints (e.g., Pearl, 2000; Spirtes et al., 1993). In contrast, the
Bayesian approach to structure learning evaluates each causal structure in terms
of the probability it assigns to a dataset. By integrating over the values that param-
eters could assume, it is possible to compute the probability of a dataset given a
graphical structure without committing to a particular choice of parameter values
(e.g., Cooper & Herskovits, 1992). This computation provides P(D|Graph i), and
a posterior probability distribution over graphs, P(Graph i|D) can be obtained by
applying Bayes rule:

PGraph ijD / PDjGraph iPGraph i;

8

where P(Graph i) is a prior probability distribution over graphs. Often, priors are
either uniform (giving equal probability to all graphs), or give lower probability
to more complex structures. Bayesian structure learning proceeds by either
searching the space of structures to nd that with the highest posterior probabil-
ity (Friedman, 1997; Heckerman, 1998), or evaluating particular causal relation-
ships by integrating over the posterior distribution over graphs (Friedman &
Koller, 2000).

348

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

4. A framework for elemental causal induction

Framing the problem of causal induction in terms of causal graphical models re-
veals that it has two components: structure learning and parameter estimation. Giv-
en an always-present background variable B, a potential cause C, and a potential
eect E, together with contingency information about the co-occurrence of C and
E, the structure learning component is the assessment of whether or not a causal
relationship in fact exists between C and E. This can be formalized as a decision be-
tween the structures Graph 1 and Graph 0 in Fig. 3. The parameter estimation com-
ponent is the assessment of the strength of this relationship: assuming Graph 1 is
appropriate, and determining the value of the parameter describing the relationship
between C and E.

The distinction between causal structure and causal strength is important in sci-
entic inference. When scientists investigate a phenomenon, they are typically inter-
ested in two questions: whether an eect exists, and how strong this eect might be.
Dierent statistical tools are used for answering these questions. In the frequentist
approach to statistics commonly used in psychological experimentation, statistical
hypothesis testing is applied to the former, and measures of eect size to the latter.
Statistical signicance is a function of both eect size and sample size. As a conse-
quence, there is no logically necessary relationship between causal structure and
apparent causal strength: small eects can be statistically signicant, and large eects
in small samples may not be supported by sucient data to guarantee rejection of a
null hypothesis.

In this section, we will show that the distinction between structure and strength
can be used to shed light on rational models of human causal induction. Both DP
and causal power address only the parameter estimation component of elemental
causal induction, providing measures of the strength of a causal relationship. We will
describe a rational model that addresses the structure learning component, which we
term causal support.

4.1. Causal induction as parameter estimation: DP and causal power

The two rational models at the heart of the current theoretical debate about ele-
mental causal induction address the same component of the underlying computa-
tional problem in fundamentally similar ways. Both DP and causal power are
maximum-likelihood estimates of the causal strength parameter w1 in Graph 1,
but under dierent parameterizations (Tenenbaum & Griths, 2001). As shown in
Appendix A, DP corresponds to the linear parameterization (Eq. (6)), whereas causal
power for generative causes corresponds to the noisy-OR parameterization (Eq. (4))
and for preventive causes corresponds to the noisy-AND-NOT parameterization
(Eq. (5)). Glymour (1998) also showed that causal power corresponds to a direct esti-
mate for the strength parameter in a noisy-OR. Since they are estimates of the
parameters of a xed graphical structure, DP and causal power both measure the
strength of a causal relationship, based upon the assumption that the relationship
exists.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

349

As point estimates of a parameter, DP and causal power share several properties.
Firstly, they do not answer the question of whether or not a causal relationship ex-
ists. Large values of DP or causal power are likely to be associated with genuine
causal relationships, but small values are non-diagnostic. Shanks (1995a, p. 260)
notes this, pointing out that while DP for the eect of smoking on lung cancer is
small, around 0.00083, no one would deny that the relationship between smoking
and lung cancer is an important one. This relates to a second property of both
DP and causal power: these measures contain no information about uncertainty in
the estimates involved. This uncertainty is crucial to deciding whether a causal rela-
tionship actually exists. Even a small eect can provide strong evidence for a causal
relationship, provided its value is estimated with high certainty. The insensitivity to
sample size exhibited by DP and causal power is one consequence of not incorporat-
ing uncertainty.

Identifying both DP and causal power as maximum-likelihood parameter esti-
mates also helps to illustrate how these measures dier: they make dierent
assumptions about the functional form of a causal relationship. The linear relation-
ship assumed by DP seems less consistent with the intuitions people express about
causality than the noisy-OR, an important insight which is embodied in Chengs
(1997) power PC theory. Chengs (1997) distinction between causal and covari-
ational measures turns on this fact: she views the noisy-OR parameterization as
resulting from the correct set of assumptions about the nature of causality, and
it is the use of this parameterization that distinguishes the Power PC theory from
covariation-based accounts. We suspect that the appropriate parameterization for
the relationship between a cause and its eects will depend upon an individuals
beliefs about the causal mechanism by which those eects are brought about.
For some causal mechanisms, other parameterizations may be more appropriate
than the noisy-OR.

4.2. Causal induction as structure learning: causal support

In terms of the graphical models in Fig. 3, DP and causal power are both con-
cerned with the problem of estimating the parameters of Graph 1. However, much
of human causal induction seems to be directed at the problem of inferring the qual-
itative causal structure responsible for a set of observations. In the case of elemental
causal induction, this problem reduces to deciding whether a set of observations were
generated by Graph 0, in which C does not cause E, or Graph 1, in which C causes E.
This binary decision is a result of the deterministic nature of the existence of causal
relationshipseither a relationship exists or it does nota property of causality that
is not captured by considering only the strength of a causal relationship (c.f. Gold-
varg & Johnson-Laird, 2001).

The structural inference as to whether the data were generated by Graph 0 or
Graph 1 can be formalized as a Bayesian decision. Making this decision requires
evaluating the evidence the data provide for a causal relationship between C and
Edetermining the extent to which those data are better accounted for by Graph
1 than Graph 0. Having specied two clear hypotheses about the source of a set

350

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

of contingency data D, we can then compute the posterior probabilities of Graphs 0
and 1 by applying Bayes rule. The posterior probability of Graph 1 indicates the ex-
tent to which a rational learner should believe in the existence of a causal relation-
ship after observing D, but it may be more appropriate to model human judgments
using a directly comparative measure, such as the log posterior odds (c.f. Anderson,
1990; Shirin & Steyvers, 1997). In log odds form, Bayes rule is

PGraph 1jD
PGraph 0jD  log

PDjGraph 1
PDjGraph 0  log

PGraph 1
PGraph 0 ;

log

9

10

where the left-hand side of the equation is the log posterior odds, and the rst and
second terms on the right-hand side are the log likelihood ratio and the log prior
odds, respectively.

Bayes rule stipulates how a rational learner should update his or her beliefs given
new evidence, with the log posterior odds combining prior beliefs with the implica-
tions of the evidence. The eect of data D on the belief in the existence of a causal
relationship is completely determined by the value of the log likelihood ratio. The log
likelihood ratio is thus commonly used as a measure of the evidence that data pro-
vide for a hypothesis, and is also known as a Bayes factor (Kass & Raerty, 1995).
We will use this measure to dene causal support, the evidence that data D pro-
vide in favor of Graph 1 over Graph 0

support  log

PDjGraph 1
PDjGraph 0 .

To evaluate causal support, it is necessary to compute P(D|Graph 1) and P(D|Graph 0).
Using a procedure described in Appendix A, it is possible to compute these proba-
bilities without committing to particular values of the parameters w0 and w1 by inte-
grating over all possible values these parameters could assume.

In computing causal support for binary-valued eects, we use the noisy-OR
parameterization (Eq. (4)) for generative causes, and the noisy-AND-NOT param-
eterization (Eq. (5)) for preventive causes. This choice of parameterizations seems
appropriate for capturing the assumptions behind problems like evaluating the
inuence of chemicals on gene expression, where each cause should have an inde-
pendent opportunity to inuence the eect. Since causal power is a maximum-like-
lihood estimator of w1 under this parameterization, this results in a relationship
between causal support and causal power. Speaking loosely, causal support is
the Bayesian hypothesis test for which causal power is an eect size measure: it
evaluates whether causal power is signicantly dierent from zero. Causal support
can also be dened for models with dierent functional dependencies and with dif-
ferent kinds of variables, a fact that we will exploit in Section 12 when we consider
causal learning from rates.

As illustrated in Fig. 4, the major determinant of causal support is the extent to
which the posterior distribution over w1 places its mass away from zero. The contin-
gency data for the top three cases shown in the gure all result in the same estimate
of causal power (approximately the peak of the posterior distribution on w1), but
increasing the number of observations contributing to these contingencies decreases

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

351

2/4
0/4

10/20
0/20

25/50
0/50

0/4
0/4

0/20
0/20

0/50
0/50

30/30
18/30

24/30
12/30

12/30
0/30

Support

y
t
i
l
i

b
a
b
o
r
p


r
o
i
r
e

t
s
o
p


l

i

a
n
g
r
a
M

0

0.5
w1

1

Fig. 4. Marginal posterior distributions on w1 and values of causal support for six dierent sets of
contingencies. The rst three sets of contingencies result in the same estimates of DP and causal power, but
dierent values of causal support. The change in causal support is due to the increase in sample size, which
reduces uncertainty about the value of w1. As it becomes clear that w1 takes on a value other than zero, the
evidence for Graph 1 increases, indicated by the increase in causal support. The second set of three
contingencies shows that increasing sample size does not always result in increased causal support, with
greater certainty that w1 is zero producing a mild decrease in causal support. The third set of three
contingencies illustrates how causal support and causal power can dier. While the peak of the distribution
over w1, which will be close to the value of causal power, decreases across the three examples, causal
support changes in a non-monotonic fashion.

uncertainty about the value of w1. It thus becomes more apparent that w1 has a value
greater than zero, and causal support increases. However, higher certainty does not
always result in an increase in causal support, as shown by the next three cases in the
gure. Causal power is zero for all three cases, and once again the posterior distri-
bution shows higher certainty when the number of observations is large. Greater
condence that w1 should be zero now results in a decrease in causal support,
although the eect is weaker than in the previous case. The last three cases illustrate
how causal support can dier from causal power. The contingencies {30/30,18/30}
suggest a high value for w1, with relatively high certainty, and consequently strong
causal support; {24/30,12/30} suggest a lower value of w1, with less certainty, and
less causal support; and {12/30, 0/30} produces an even lower value of w1, but the
higher certainty that this value is greater than zero results in more causal support.

352

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

4.3. Approximating causal support with v2

The standard frequentist analysis of contingency tables is Pearsons (1904/1948)
v2 test for independence, or the related likelihood ratio test G2 (e.g., Wickens,
1989). The use of the v2 test as a model for human causal judgment was suggested
in the psychological literature (e.g., Allan, 1980), but was rejected on the grounds
that it neglects the kind of asymmetry that is inherent in causal relationships, provid-
ing information solely about the existence of statistical dependency between the two
variables (Allan, 1980; Lopez et al., 1998; Shanks, 1995b). v2 also makes no commit-
ment about the functional form of the relationship between cause and eect: it sim-
ply detects any kind of statistical dependency between C and E. These weak
assumptions are important for v2 to be useful as a statistical test across a wide range
of settings, but they produce problems for it as a model of human causal judgments.
As a measure of the evidence for a particular dependency structure, v2 is related to
causal support. In Appendix A, we show that under certain conditions causal sup-
port can be approximated by Pearsons v2 test for independence. This approximation
only holds when the contingency table contains a large number of observations, and
the potential cause has a weak eect. v2 should be treated with caution as a model of
causal induction, for exactly the reasons identied above: it is a symmetric test of sta-
tistical dependency, while causal support postulates a specic form and direction for
a causal relationship. The dierent assumptions behind these two approaches can re-
sult in quite dierent predictions.

4.4. Summary

Causal induction involves two problems: evaluating whether or not a causal rela-
tionship exists, and establishing the strength of that relationship. Causal graphical
models provide the tools for treating both of these problems formally, in terms of struc-
ture learning and parameter estimation. In the remainder of the paper, we will argue
that the focus on parameter estimation in previous models of elemental causal induc-
tion is responsible for the inability of these models to account for several trends in hu-
man judgments, and we will show that causal support fares better in explaining these
phenomena. We will examine in detail ve phenomena that are problematic for existing
models, but are predicted by causal support. These phenomena were introduced in Sec-
tion 2.2: the interaction between DP and the base-rate probability of the eect,
), as demonstrated in Buehner and Cheng (1997); non-monotonic judgments
P(e+|c
as a result of changes in base-rate, as seen by Lober and Shanks (2000); eects of sample
size (e.g., White, 1998, 2002c, 2003c); inferences from contingency tables with empty
cells; and causal induction from rates (cf. Wasserman, 1990; Anderson & Sheu, 1995).

5. Interaction between DP and P(e+|c
)

In Section 2.2, we discussed results from Experiment 1B of Buehner and Cheng
(1997; later published in Buehner et al., 2003) which are shown in Fig. 1. This

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

353

experiment used an online format, and produced trends that were independently
problematic for both DP and causal power, as well as a trend that neither model
could predict: peoples judgments at DP = 0 decrease as the base-rate probability
), decreases. The fundamental problem in explaining the results
of the eect, P(e+|c
of Buehner and Cheng (1997) is accounting for the interaction between DP and the
base-rate probability in producing human judgments. DP predicts no interaction,
and causal power predicts the simple relationship given in Eq. (2), but neither of
these predictions matches human judgments. We will show that causal support is
able to correctly predict this interaction, demonstrating that the model can capture
the trends found by Buehner and Cheng (1997).

Causal support correctly predicts the interaction between DP and P(e+|c

Fig. 1 shows the data from Buehner and Cheng (1997, Experiment 1B) together
with predictions of four models: DP, causal power, causal support, and v2. As noted
in Section 2.2, both DP and causal power capture some trends in the data, but miss
others, resulting in correlations of r = .889 and r = .881. Causal support provides the
best quantitative account of this dataset, r = .968, c = .668, and accounts for all of
the major trends in human judgments, including those at DP = 0. Due to the small
samples, v2 gives a poor approximation to causal support, and a correlation of
r = .889, c = .596.
) in
inuencing peoples judgments. In particular, it is the only model that predicts hu-
man judgments at DP = 0. The explanation for these predictions is not that there
) decreases, but rather that
is decreasing evidence for a causal relationship as P(e+|c
) = 1, and
there is little evidence for or against a causal relationship when P(e+|c
) decreases. This account
increasing evidence against a causal relationship as P(e+|c
depends on the assumption that the causal relationshipif it existsis generative
(increasing the probability of the eect, rather than preventing it). At one extreme,
)} = {8/8, 8/8}, all mice expressed the gene irrespective of
when {P(e+|c+), P(e+|c
treatment, and intuitively there should be no evidence for a causal relationship.
But there can also be no evidence against a (generative) causal relationship, because
of a complete ceiling eect: it is impossible for the cause to increase the probability
) = 1. This uncertainty in causal
of E occurring above its baseline value when P(e+|c
) = 1 and DP = 0 is predicted by both causal support, which
judgment when P(e+|c
is near 0, and also (as Cheng, 1997, points out) by causal power, which is undened
there.
)
decreases. Causal support becomes increasingly negative as the ceiling eect weakens
and the observation that DP = 0 provides increasing evidence against a generative
) = 0/8, no untreated mice
causal relationship. At the other extreme, when P(e+|c
expressed the gene, and there are eight opportunities for a causal relationship to
manifest itself in the treated mice if such a relationship in fact exists. The fact that
the eect does not appear in any treated mice, P(e+|c+) = 0/8, strongly suggests that
the drug does not cause gene expression. The intermediate cases provide intermediate
evidence against a causal relationship. The contingencies {2/8, 2/8} oer six chances
for the treatment to have an eect, and the fact that it never does so is slightly weaker
evidence against a relationship than in the {0/8, 0/8} case, but more compelling than

Only causal support, however, predicts the gradient of judgments as P(e+|c

354

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

for {6/8, 6/8}, where the cause only has two chances to manifest itself and the obser-
vation that DP = 0 could easily be a coincidence. This gradient of uncertainty shapes
the Bayesian structural inference underlying causal support, but it does not impact
the maximum-likelihood parameter estimates underlying causal power or DP.
), showing
the posterior distribution on w1 for each set of contingencies. Greater certainty in the

Fig. 5 reveals why causal support is sensitive to the change in P(e+|c

y
t
i
l
i

b
a
b
o
r
p

r
o
i
r
e
t
s
o
p

l
a
n
g
r
a
M

i

8/8
8/8

6/8
6/8

4/8
4/8

2/8
2/8

0/8
0/8

8/8
6/8

6/8
4/8

4/8
2/8

2/8
0/8

8/8
4/8

6/8
2/8

4/8
0/8

8/8
2/8

6/8
0/8

8/8
0/8

0

0.5
w1

1

0

50

Support

100

Fig. 5. Marginal posterior distributions on w1 and values of causal support for the contingencies used in
Buehner and Cheng (1997, Experiment 1B).

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

355

value of w1 is reected in a more peaked distribution, and causal support becomes
larger as it becomes more apparent that w1 is greater than zero. The top ve plots
show the cases where DP = 0. Despite the fact that DP is the same in these ve cases,
the posterior distributions on w1 look quite dierent. Four of the distributions have a
maximum at w1 = 0, consistent with the estimate of causal power for these contin-
gencies, but they dier in the certainty of the estimate, reected in the breadth of
) increases, fewer observations contribute
the posterior about this point.3 As P(e+|c
to the estimate of w1, and the posterior becomes more diuse, being almost uniform
for P(e+|c

) = 1.

This explanation can also be applied to a similar trend that emerges with preven-
tive causes. The results of Experiment 1A of Buehner and Cheng (1977; also pub-
lished in Buehner et al., 2003), are shown in Fig. 6. This experiment followed a
design analogous to Experiment 1B, but with preventive causes. Here, peoples judg-
) increases. Causal support, parameterized with
ments for DP = 0 decrease as P(e+|c
a noisy-AND-NOT (Eq. (5)) rather than a noisy-OR, provides the best account of
these data, including the trend at DP = 0, with r = .922, c = 0.537. Causal power
performs similarly, r = .912, c = 1.278, while DP gives r = .800, c = 0.943 and v2
gives r = .790, c = 0.566. The explanation for the predictions of causal power is sim-
ilar to the generative case, although now the ceiling eect is a oor eect: as
) increases there is more opportunity for a non-zero value of w1 to be
P(e+|c
demonstrated.

6. Non-monotonic eects of P(e+|c

)

Accounting for the interaction between DP and the base-rate probability,
), is fundamental to explaining the results of Buehner and Cheng (1997). It
P(e+|c
is also important in explaining other phenomena of causal induction. The second
dataset discussed in Section 2.2 was Experiments 46 from Lober and Shanks
(2000), shown in Fig. 2. DP accounts for these data quite well, reected in the high
correlation coecient, r = .980, c = 0.797, while causal power does poorly, r = .581,
c = 1.157. However, neither of these models can predict the non-monotonic eect of
)} pairs {30/30, 18/30}, {24/30, 12/30}, {12/
P(e+|c
30, 0/30}. A similar, but weaker, trend can be seen in the online data of Buehner and
Cheng (1997, Experiment 1B), shown in Fig. 1, for the contingencies {8/8,4/8},{6/
8,2/8},{4/8,0/8}. These non-monotonic trends cannot even be predicted by models
that form linear combinations of the entries in a contingency table, such as those
of Anderson and Sheu (1995) and Schustack and Sternberg (1981), despite their
many free parameters and great exibility.

) seen with the {P(e+|c+),P(e+, c

3 The distribution for w1 when P(e+|c+) = P(e+|c

) = 1 is mostly at but has a very slight peak at w1 = 1,
despite causal power being undened for this case. This is because there is also uncertainty in the value of
w0. If w0 actually takes on any value less than 1, and the large number of occurrences of the eect in the
absence of the cause is just a coincidence, then the large number of occurrences of the eect in the presence
of the cause still needs to be explained, and the best explanation is that w1 is high.

356

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

P(e+|c+)
P(e+|c)

100

8/8
8/8

6/8
6/8

4/8
4/8

2/8
2/8

0/8
0/8

6/8
8/8

4/8
6/8

2/8
4/8

0/8
2/8

4/8
8/8

2/8
6/8

0/8
4/8

2/8
8/8

0/8
6/8

0/8
8/8

Humans

 P

Power

Support

2

50

0

100

50

0

100

50

0

100

50

0

100

50

0

Fig. 6. Predictions of rational models compared with the performance of human participants from
Buehner and Cheng (1997, Experiment 1A). Numbers along the top of the gure show stimulus
contingencies, error bars indicate one standard error.

Causal support gives the best quantitative t to this dataset, r = .994, c = 0.445,
with v2 performing similarly, r = .993, c = 0.502. Both causal support and v2 predict
non-monotonic trends, as shown in Fig. 2. The intuitive reasons for these predictions
were mentioned when discussing Fig. 4, which uses exactly the same set of contingen-
cies: while {24/30, 12/30} suggests a higher value of causal power than {12/30, 0/30},
such a dierence in contingencies is more likely to arise by chance. As with the expla-
nation of predictions for DP = 0 given in Section 5, the high certainty in the value of
w1 for {12/30, 0/30} results partly from the low value of P(e+|c

).

The non-monotonic trend observed in Experiments 46 of Lober and Shanks
(2000) did not appear in their Experiments 13, despite the use of the same contin-
gencies, as shown in Fig. 7. The only dierence between these two sets of experiments

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

357

27/30
20/30

24/30
10/30

21/30
0/30

28/28
21/28

28/28
14/28

28/28
7/28

28/28
0/28

30/30
18/30

24/30
12/30

12/30
0/30

27/30
25/30

Humans

 P

Support

2



P(e+|c+)
P(e+|c)
100

50

0

100

50

0

100

50

0

100

50

0

Fig. 7. Predictions of rational models compared with the performance of participants from Lober and
Shanks (2000, Experiments 13). Numbers along the top of the gure show stimulus contingencies, but the
results are constructed by averaging over the blocks of trials seen by individual subjects, in which
contingencies varied.

was the presentation format, with an online format being used in Experiments 13,
and a summary format in Experiments 46. This presents a challenge for the expla-
nation based on causal support given above. However, we will argue that this dis-
crepancy can be resolved through a ner-grained analysis of these experiments.

Catena, Maldonado, and Candido (1998) and Collins and Shanks (2002) both
found that peoples judgments in online experiments are inuenced by response fre-
quency. Specically, people seem to make judgments that are based upon the infor-
mation presented since their last judgment, meaning that primacy or recency
eects can be produced by using dierent response schedules (Collins & Shanks,
2002). Lober and Shanks (2000) used a procedure in which participants made judg-
ments after blocks of trials, with six blocks of length 10 in Experiment 1, two blocks
of length 18, and one of length 20 in Experiment 2, and 3 blocks of length 20 in
Experiment 3. The actual trials presented in each block were selected at random.
Thus, while the overall contingencies might match those used in Experiments 46,
the contingencies contributing to any individual judgment varied. This may account
for the dierence between the results of the two experiments. In particular, the small-
er sample sizes contributing to the contingencies may aect peoples judgments.

358

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

Table 2
Correlations of rational models with results from Lober and Shanks (2000)

Experiment 1
Experiment 2
Experiment 3
Overall means

DP

0.354
0.462
0.336
0.695

Support

0.350
0.465
0.382
0.895

v2

0.354
0.471
0.303
0.829

Note. Boldface indicates highest correlation in each row.

To test this hypothesis, we used the records of the individual trials seen by the par-
ticipants in these experiments to establish the contingencies each participant saw in
each block, and evaluated the performance of dierent models in predicting the judg-
ments of individual participants for each block from these contingencies.4 The results
of these analyses are given in Table 2. The correlations are lower than those reported
elsewhere in the paper because they concern the responses of individual participants
rather than average scores. While all models did equally well in predicting the results
of Experiments 1 and 2, causal support gave a better account of the results of Exper-
iment 3, with a correlation of r = .382 as compared to r = .336 for DP, and r = .303
for v2. The model predictions, averaged across blocks and participants in the same
fashion as the data, are shown in Fig. 7. The mean values of causal support do
not show any predicted non-monotonicity, in accord with the data. As shown in Ta-
ble 2, the mean causal support correlates better with the mean human judgments
than the mean predictions of any other model, with r = .895 for causal support,
r = .695 for DP, and r = .829 for v2.

There are two reasons why causal support does not predict a non-monotonic
trend for Experiments 13: smaller samples, and variation in observed contingencies.
The eect of sample size is simple: causal support predicts a non-monotonic trend for
contingencies derived from 30 trials in each condition, but this trend is almost com-
pletely gone when there are only 10 trials in each condition. Small samples provide
weaker evidence that the strength of the cause is dierent from zero in all conditions,
with {12/30, 0/30} and {24/30, 12/30} giving equivalently weak support for a causal
relationship. The eect of variation in observed contingencies is more complex. Since
both DP and causal power are estimated from the conditional probabilities P(e|c),
and the empirical probabilities give unbiased estimates of the true probabilities, aver-
aging across many sets of contingencies generated according to those probabilities
gives mean values that approximate the true DP and causal power. Causal support
is a more complex function of observed contingencies, and averaging causal support
across a set of samples produces dierent results from computing causal support
from the average contingencies. In particular, variation in the contingencies within

4 The raw data from Lober and Shanks (2000) were supplied by Klaus Melcher. The models compared in
this section were t using the same scaling parameter for all participants within the same experiment.
Causal power was not computed for this comparison, as the presence of extreme contingencies in several
cases resulted in undened values of causal power, interfering with correlations and averaging.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

359

blocks results in some blocks providing very weak evidence for a causal relationship
(for example, in the {12/30, 0/30} condition, one participant saw a block in which the
cause was present on eight trials, but the eect occurred on only one of these trials).
Such results have the greatest eect in the {12/30, 0/30} condition, and the mean
causal support in this condition consequently ends up slightly lower than causal sup-
port estimated from mean contingencies.
) appears in both Lober and Shanks
(2000, Experiments 46) and Buehner and Cheng (1997), it has not been the principal
target of any experiments. Since no existing model of elemental causal induction can
predict this phenomenon, conrming its existence would provide strong evidence in
favor of causal support. Experiment 1 was designed to explore this non-monotonic
eect further.

Although a non-monotonic eect of P(e+|c

7. Experiment 1

7.1. Method

7.1.1. Participants

One hundred and eight Stanford undergraduates participated for course credit.

7.1.2. Stimuli

The contingencies used in the experiment are shown in Fig. 8. They included three
), and
sets of three contingencies at xed values of DP but dierent values of P(e+|c
several distractors. The sets of contingencies with xed DP used DP = 0.40,
) within these sets, so
DP = 0.07 and DP = 0.02. DP predicts no eect of P(e+|c
any eect provides evidence against this model. Causal power predicts a monotonic
) increases, and causal support predicts a
increase in peoples judgments as P(e+|c
non-monotonic trend in the rst two sets of contingencies, and a monotonic increase
) in the third. Finding non-monotonic eects in the rst two sets of con-
with P(e+|c
tingencies would thus provide evidence for causal support over causal power.

7.1.3. Procedure

The experiment was conducted in survey form. The instructions placed the prob-

lem of causal induction in a medical context:

Imagine that you are working in a laboratory and you want to nd out whether
certain chemicals cause certain genes to be expressed in mice. Below, you can see
laboratory records for a number of studies. In each study, a sample of mice were
injected with a certain chemical and later examined to see if they expressed a par-
ticular gene. Each study investigated the eects of a dierent chemical on a dier-
ent gene, so the results from dierent studies bear no relation to each other.
Of course, these genes may sometimes be expressed in animals not injected with
a chemical substance. Thus, a sample of mice who were not injected with any
chemical were also checked to see if they expressed the same genes as the

360

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

100
60

70
30

40
0

100
93

53
46

7
0

100
98

51
49

2
0

10
10

100
100

74
72

90
83

7
93

Humans

 P

Power

Support

2

N(e+,c+)
N(e+,c)

20

10

0

20

10

0

20

10

0

20

10

0

20

10

0

Fig. 8. Predictions of rational models compared with results of Experiment 1. Numbers along the top of
the gure show stimulus contingencies. These numbers give the number of times the eect was present out
of 100 trials, for all except the last column, where the cause was present on 7 trials and absent on 193. The
rst three groups of contingencies are organized to display non-monotonicities in judgments, the last
group contains distractor stimuli. Error bars indicate one standard error.

injected mice. Also, some chemicals may have a large eect on gene expression,
some may have a small eect, and others, no eect.

Participants were then asked for ratings on a total of 14 dierent contingency

structures. The instructions for producing the ratings were:

For each study, write down a number between 0 and 20, where 0 indicates that
the chemical DOES NOT CAUSE the gene to be expressed at all, and 20 indi-
cates that the chemical DOES CAUSE the gene to be expressed every time.

Each participant completed the survey as part of a booklet of unrelated

experiments.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

361

7.2. Results and discussion

p<.005,

for

DP = 0.07,

The results are shown in Fig. 8. As predicted, there was a statistically signicant
) in all three sets of contingencies with xed DP. For DP = 0.40,
eect of P(e+|c
F(2,214) = 6.61, MSE = 17.43,
F(2,214) = 3.82,
MSE = 26.93, p<.05, for DP = .02, F(2,214) = 6.06, MSE = 11.27, p < .005. Since
a quadratic trend analysis would only test deviation from linearity, and not non-
) in each of these sets of contingen-
monotonicity, we evaluated the eect of P(e+|c
). The response
cies by testing each pair of means with neighboring values of P(e+|c
for {40/100, 0/100} was signicantly greater than that
for {70/100, 30/100},
t(107) = 3.00, p < .005, and {70/100,30/100} was signicantly less than {100/
100, 60/100},
trend at
DP = .40. The response for {7/100, 0/100} was signicantly greater than that for
{53/100, 46/100}, t(107) = 2.13, p < .05, and {53/100, 46/100} was signicantly less
than {100/100, 93/100}, t(107) = 2.70, p < .01, indicating a non-monotonic trend at
DP = 0.07. At DP = .02, {2/100, 0/100} was greater
than {51/100, 49/100},
t(107) = 4.05, p < .001, but there was no signicant dierence between {51/100, 49/
100} and {100/100, 98/100}, t(107) = 0.55, p = .58, providing no evidence for non-
monotonicity.

indicating a non-monotonic

t(107) = 3.81, p < .001,

The results of this experiment suggest that the non-monotonicitic trend seen by
Lober and Shanks (2000) is a robust aspect of human judgments, even though it
may be a small eect. Such trends can be used to assess models of causal induction.
Causal support, v2, and DP gave similarly high correlations with the experimental
results, with r = .952, c = .604, r = .965, c = .446, and r = .943, c = .568, respective-
ly. Causal power performed far worse, with r = .660, c = .305. The statistically sig-
) in the three sets of contingencies with xed DP are
nicant eects of P(e+|c
contrary to the predictions of DP. Only causal support and v2 predicted the observed
non-monotonic trends.

8. Sample size eects

In explaining the results of Lober and Shanks (2000, Experiments 13), we
touched upon the issue of sample size. Sample size is an important factor that aects
structure learning but not parameter estimation:
larger samples provide better
grounds for assessing the evidence for a causal relationship, but do not aect param-
eter estimation. Both DP and causal power are computed using the conditional prob-
abilities P(e|c), rather than the number of observations contributing to these
probabilities. Consequently, they predict no variation in judgments as the number
of trials on which the cause was present or absent is varied. In contrast, both causal
support and v2 are sensitive to sample size.

There are two dimensions along which sample size might be varied: the ratio of
)),
the number of trials on which the cause is present or absent (N(c+) and N(c
) has been
and the total number of trials (N). Variation of the ratio of N(c+) to N(c
explored extensively by White (1998, 2002c, 2003c). These experiments revealed

362

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

several eects of sample size, inconsistent with the predictions of DP and causal
power, and were taken to support Whites (2002c) proportion of Conrming Instanc-
). We will discuss the
es (pCI) model, which diers from DP only when N(c+)  N(c
pCI model further in Section 15. We applied all ve modelsDP, causal power, pCI,
causal support, and v2to the results of these experiments, producing the correla-
tions shown in Table 3. For several of these experiments, DP was constant for all
stimuli, resulting in a correlation of 0 between DP and human judgments. We also
present the results of the ve models on Experiment 1 of Anderson and Sheu
(1995), in which the entries in single cells of the contingency table were varied sys-
tematically, resulting in some sample size variation as well as other eects. The ob-
served eects of sample size were broadly consistent with causal support, which gave
either the best or close to the best account of 10 of the 12 datasets. There was no
systematic relationship between the format in which contingency information was
presented and the performance of the models, although causal support gave the best
correlations with the three online datasets.

Variation of the total number of trials producing a set of contingencies, N, has
been studied less extensively. White (2003c, Experiment 4), conducted an experiment
in which this quantity was varied, and found no statistically signicant eect on hu-
man ratings. As shown in Fig. 4, causal support makes clear predictions about the
eect of N on the evidence for a causal relationship, and the demonstration of such
an eect would provide evidence for the involvement of structure learning in human
causal induction. One possible explanation for the lack of a sample size eect in
Whites (2003c) experiment is the use of ratings as a dependent measure: the eect
of sample size might be concealed by allowing people the possibility of giving equal
ratings to dierent stimuli. Consequently, we decided to explore this phenomenon
further, using a more sensitive response measure: Experiment 2 was designed to

Table 3
Correlations of rational models with sample size experiments

Paper

White (1998)

White (2002c)

White (2003c)

Anderson and Sheu (1995)

Experiment

Format

3 (seeds)
3 (contentless)
1
2
3
1
2
3
4
5
6
1

Summary (16)
Summary (16)
List (8)
List (12)
List (6)
List (8)
Online (8)
Summary (8)
List (8)
List (8)
Online (4)
Online (80)

DP

0.907
0.922
0.956
0.772
0
0.200
0.070
0.392
0
0
0
0.884

Power

pCI

Support

v2

0.902
0.867
0.765
0.852
0.760
0.389
0.409
0.383
0.037
0.373
0
0.816

0.929
0.933
0.956
0.760
0.941
0.818
0.706
0.467
0.860
0.788
0.425
0.877

0.924
0.935
0.938
0.916
0.837
0.854
0.812
0.677
0.679
0.803
0.676
0.894

0.865
0.885
0.936
0.830
0.146
0.791
0.640
0.586
0.729
0.631
0
0.329

Note. Boldface indicates highest correlation in each row. Number in parentheses in format column
indicates number of stimuli.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

363

examine whether sample size aects peoples assessment of causal relationships,
using a rank ordering task.

9. Experiment 2

9.1. Method

9.1.1. Participants

Participants were 20 members of the MIT community who took part in the exper-

iment in exchange for candy.

9.1.2. Stimuli

We used nine stimuli, each composed of dierent contingency data. The two crit-
ical sets of contingencies were a set for which DP = 0, consisting of {0/4, 0/4}, {0/
20, 0/20}, and {0/50, 0/50}, and a set for which DP = 0.5, {2/4, 0/4}, {10/20, 0/20},
and {25/50, 0/50}. DP, pCI, and causal power are constant for these sets of stimuli,
and any ordering should thus be equally likely. v2 predicts an increase in judgments
with sample size for the DP = 0.5 set, but is constant for the DP = 0 set. Causal sup-
port predicts sample size should result in an increase in judgments with DP = 0.5,
and a decrease with DP = 0, as shown in Fig. 4. The experiment also included three
distractors, to conceal our manipulation: {3/4, 1/4}, {12/20, 8/20}, and {50/50, 0/50}.

9.1.3. Procedure

Participants read a description of an imaginary laboratory scenario, similar to
that used in Experiment 1, and were shown nine cards that expressed the stimulus
information described above. They were given the following instructions:

Each of the cards in front of you summarizes the results of a dierent study.
Look these summaries over carefully, and then place them in order from the
study from which it seems LEAST LIKELY that the chemical causes the gene
to be expressed, to the study in which it seems MOST LIKELY that the chem-
ical causes the gene to be expressed.

The wording of the question in terms of likelihood followed the procedure report-
ed by White (2003c). If participants asked whether cards could be ranked equally,
they were told that they could order them randomly.

9.2. Results and discussion

Analysis of the orderings produced by the participants showed that 17 out of 20
ordered the stimuli with DP = 0.5 by increasing sample size (binomial test, p < .001),
while 16 out of 20 ordered the stimuli with DP = 0 by decreasing sample size (bino-
mial test, p < .001). We computed rank-order correlations with the responses of indi-
vidual participants for each of the ve models. We computed the rank-order
correlations with the ve models for each participant, averaging these correlations

364

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

to result in scores for each model.5 Causal support and v2 performed equivalently,
q = 0.948 and q = 0.945, respectively, followed by DP, q = 0.905, and causal power,
q = 0.859. Causal support gave the highest correlation with the responses of eleven
participants, causal power and v2 with four participants each, and DP with only one
participant.

The results indicate that people are sensitive to sample size when making causal
judgments. Specically, increasing sample size increases judgments when eects are
large, but decreases judgments for zero eects. Only causal support can explain this
pattern of results. Sensitivity to sample size is a property of structure learning, not
parameter estimation, and thus provides evidence that people approach problems
of causal induction as structure learning problems.

10. Inferences from incomplete contingency tables

We began this paper by observing that everyday causal induction has several
commonalities with the reasoning of early scientists. Among these commonalities
is the need to make inferences from limited data. In many settings where people
infer causal relationships, they do not have all of the information that is typically
provided in causal
induction tasks. Specically, without a carefully designed
experiment, we often do not know the frequency of the eect in the absence of
the cause, leaving some of the cells in a contingency table empty. While our epi-
graph indicates the attention that James Currie paid to the number of patients
who recovered both with and without treatment, such reporting was the exception
rather than the rule prior to the development of modern experimentation. Many
early medical texts, such as Jenners (1798) famous treatise on the smallpox vac-
cine, consist of a description of a number of cases in which the treatment proved
successful, providing only N(e+, c+). To make an inference from such data, his
readers had to use their expectations about the frequency of infections in the ab-
sence of treatment.

DP and causal power are both undened when there are no trials on which the
) cannot be computed. This is a problem, as people
cause was absent, since P(e+|c
readily make causal judgments under such circumstances. For example, suppose that
a doctor claims to have invented a treatment that will cure a rare illness, Hopkins
Francis syndrome. He tells you that he has given this treatment to one patient with
HopkinsFrancis syndrome, and after one month, all the patients symptoms are
gone. How much evidence does this provide for the treatments eectiveness? It
may provide some evidence, but not strong evidence, since we do not know how
many patients would recover spontaneously in this interval.

5 Correlations were averaged using the Fisher z transformation. These results include only 19 of the 20
participants, since causal support perfectly predicted the ordering given by one participant, resulting in an
innite z score. The reported mean correlation is thus an underestimate for causal support. While the other
models do not predict an ordering for the two critical sets, they do predict an ordering among the full set of
nine stimuli, hence q > 0.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

365

A few months later, the doctor tells you that he has now given the treatment
to three patients, and after one month all of their symptoms are gone. These
data provide stronger evidence, but not that much stronger. The evidence is
strengthened once more when, a few months later, the doctor tells you that
he has given the treatment to twenty patients, and after one month all of their
symptoms are gone. Finally, the doctor tells you that he has also seen twenty
patients over the same time period who received a placebo instead of the new
treatment, and all people in this group still had symptoms after a month of
observation. Moreover, the people who received the treatment or the placebo
were chosen at random. Now this provides very strong evidence for the treat-
ments eectiveness.

We can identify ve stages in the accumulation of evidence in this example.
The rst stage is the baseline, with no information, and the contingencies {0/
0, 0/0}. After a single observation, we have {1/1, 0/0}. Two more observations
provide {3/3, 0/0}, and 17 more successful treatments give {20/20, 0/0}. Finally,
the control condition provides {20/20,0/20}. DP and causal power can only be
computed for this last case, where they both indicate strong evidence for a caus-
al relationship, DP = power = 1.00. They are undened for the other contingency
tables, and thus cannot capture the weak but growing evidence these tables pro-
vide. Causal support is 0 for {0/0, 0/0}, reecting the lack of evidence for or
against a causal relationship (negative values of causal support indicate evidence
for Graph 0, while positive values indicate evidence for Graph 1). Causal sup-
port then gradually increases as the observations accumulate, taking values of
0.41, 0.73, and 1.29, before jumping dramatically to 23.32 for when the control
condition is added. Unlike DP or causal power, causal support thus predicts our
intuitive ordering of the strength of evidence provided by these ve stimuli. In
Experiment 3, we examined whether this ordering matched the judgments of na-
ive participants.

11. Experiment 3

11.1. Method

11.1.1. Participants

Participants were 20 members of the MIT community who took part in the exper-

iment in exchange for candy.

11.1.2. Stimuli

We used the ve stimuli described above: {0/0, 0/0}, {1/1, 0/0}, {3/3, 0/0}, {20/

20, 0/0}, and {20/20, 0/20}.

11.1.3. Procedure

The procedure was identical to that of Experiment 2, with the stimuli being pre-

sented on cards and participants being asked to provide an ordering.

366

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

11.2. Results and discussion

Analysis of the orderings produced by the participants showed that 15 out of 20
perfectly reproduced the ordering predicted by causal support (binomial test,
p < .001). The other ve participants still showed some conformity to the predictions
of causal support, with a mean correlation of q = 0.51. DP and causal power are
undened for all but one of these stimuli, preventing the computation of any
correlations.

Causal support is the only model we have considered that is capable of capturing
peoples inferences from incomplete contingency tables. The ability to infer causal
relationships from limited data is an extremely important part of causal induction
in both everyday and scientic settings. Even today, many medical treatments are
initially tested with small samples and incomplete contingency tables. Many doctors
say they do not believe in a drugs eectiveness until it passes large-scale studies with
appropriate controls, in part because standard statistical practice does not provide a
rigorous way to evaluate treatment eectiveness with such limited data. However,
the researchers who are actually coming up with and testing new treatments need
to have some way of evaluating which treatments are promising and which are
not, or they would never make any progress. Causal support provides an account
of the rational basis of these intuitions.

12. Learning from rates

Several studies of elemental causal induction have gone beyond inferences from
contingency table data, examining how people learn about causal relationships from
rate data (e.g., Anderson & Sheu, 1995; Wasserman, 1990). Rates are closely related
to contingencies, being the number of times the eect occurs in a continuous interval
rather than the number of times the eect occurs on a set of discrete trials. Despite
this relationship, previous models of causal induction such as DP and causal power
have not been assessed using rate data. In this section, we will show how these mod-
els can be extended to allow inferences from rate data, and evaluate their predictions
about human judgments. This novel setting provides an opportunity to test the gen-
erality of our framework, as the distinction between structure and strength holds
whether the observed data are rates or contingencies.

Anderson and Sheu (1995, Experiment 2) conducted an experiment in which par-
ticipants learned whether clicking on a ute icon caused a change in the rate of mu-
sical notes produced by the ute. They found that their results were poorly predicted
by the dierence in rates, dened as

DR  Nc  Nc;

11
where N(c+) is the number of events in the interval when the cause, in this case click-
) is the number of events when the cause was
ing on the ute, was present, and N(c
absent. Anderson and Sheu (1995) found that performance could be better predicted
by grating contrast, which they dened as

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

contrast  Nc  Nc
Nc  Nc

367

12

and justied by its use as a measure of contrast in psychophysical research. They
gave no theoretical motivation for using this measure.

In the remainder of this section, we will develop a rational account of causal induc-
tion from rates. This account makes explicit the relationship between DR, DP, and
causal power, revealing that DR is the maximum-likelihood parameter estimate of
the strength of a causal relationship, and allows us to dene causal support for rate
data. The rst step in this analysis is dening a parameterization for Graph 0 and
Graph 1 that is appropriate for outcomes that are rates rather than discrete trials.

The Poisson distribution is commonly used in statistics for modeling the number
of events that occur within a xed interval. Under this distribution, the number of
events N occurring in a single unit of time will have probability

;

PN  ek kN
N !

13
where k is the rate parameter. We can use the Poisson distribution to dene a param-
eterization for Graph 0 and Graph 1 that is an extension of the linear and noisy-OR
parameterizations to continuous time. Under a noisy-OR parameterization where
the event E has parents B and C, the probability of E if just B is present is w0, and
the probability of E with both B and C present is w0 + w1w0w1, where the last term
corrects for double-counting the cases in which both B and C would have produced
E. Extending this model to the case where events are emitted over a continuous interval,
the probability of an event at any point in time is simply the sum of the probabilities for
each of the parents, as in the linear parameterization, since the probability of two events
from a Poisson process occurring simultaneously is zero. The resulting process is the
sum of the Poisson processes associated with the parents, and the sum of two indepen-
dent Poisson processes is a Poisson process with a rate equal to the sum of the rates of
the original processes. This gives us the parameterization

PNjb; c; k0; k1  ebk0ck1 bk0  ck1N

N !

.

14

where k0 is the rate associated with B, and k1 is the rate associated with C.

Under the model specied by Eq. (14), DR is the maximum likelihood parameter
estimate for k1. The correspondence to DP and causal power can be seen by taking
the rate information as just the positive events in a contingency table where the total
) for unknown
sample size is unknown, so N(c+) = NP(e+|c+) and N(c
N. If we assume that N is xed across dierent experiments, we can obtain estimates
consistent with the ordering and magnitude implied by DP using DR = N(c+)  N(c
)
= NDP. If we make the further assumption that N is very large, DR will also correspond
to causal power, since P(e

) will tend to 1.

) = NP(e+|c

|c

Using the parameterization given in Eq. (14), we can dene causal support as in
Eq. (10), where Graph 0 is the model in which B is the only parent of E, and Graph 1
is the model in which both B and C are parents of E. The details of this model are
provided in Appendix A, where we also justify the approximation

368

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

r  Nc  Nc2

v2

Nc

.

15

This approximation bears the same relationship to causal support for rates as the
Pearson v2 test for independence does for contingency data: it is a frequentist inde-
pendence test that will be asymptotically equivalent to causal support. Computing v2
r
involves dividing the squared dierence between the observed rates by the variance
of the rate in the absence of the cause, comparing the magnitude of the eect of
introducing the cause to the variation that should arise by chance. This may account
for the ecacy of the grating contrast model used by Anderson and Sheu (1995),
which involves a similar ratio.

Our analysis provides a set of models that generalize DP, causal power, causal sup-
port, and v2 to allow causal induction from rates. Unfortunately, the procedure used in
previous experiments exploring causal induction from rates (Anderson & Sheu, 1995;
Wasserman, 1990) prevents modeling of their data without detailed information about
the performance of individual participants. These experiments used a procedure in
which participants interacted with objects, and then observed whether there was an
alteration in the rate of the eect after their interaction. The models described in this
section cannot be applied to these data without a record of the number of periods of
interaction and non-interaction. To address this issue we conducted our own experi-
ments, in which participants were provided with information about the rate of occur-
rence of the eect in the presence and absence of the cause directly, using both summary
(Experiment 4) and online (Experiment 5) formats.

13. Experiment 4

13.1. Method

13.1.1. Participants

Eighty-two Stanford University undergraduates took part in the study.

13.1.2. Stimuli

A questionnaire presented a summary of nine experiments involving dierent
chemical compounds and electrical elds, giving the number of particle emissions in-
side and outside the electrical eld. The number of particle emissions in each example
)} pairs):
was selected to give three critical sets of rates (expressed as {N(c+),N(c
{52, 2}, {60, 10}, {100, 50}, for which DR = 50, {12, 2}, {20, 10}, {60, 50} for which
DR = 10, and {4, 2}, {12, 10}, {52, 50}, for which DR = 2.

13.1.3. Procedure

The instructions outlined a hypothetical laboratory scenario:

Imagine that you are working in a laboratory and you want to nd out whether
electrical elds inuence the radioactive decay of certain chemical compounds.
Below, you can see laboratory records for a number of studies. In each study, a

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

369

sample of some particular compound was placed inside a particular kind of
electrical eld for one minute, and the rate of radioactive decay was measured
(in number of particles emitted per minute). Each study investigated the eects
of a dierent kind of eld on a dierent kind of chemical compound, so the
results from dierent studies bear no relation to each other.
Of course, the chemical compounds can emit particles even when not in an elec-
trical eld, and they do so at dierent rates. Some compounds naturally decay
at a fast rate, while others naturally decay at a slow rate. Thus, the decay rate
of each compound was also measured for one minute in the absence of any
electrical eld. For each study below, you can see how many particles were
emitted during one minute inside the electrical eld, and during one minute
outside of the electrical eld. What you must decide is whether the electrical
eld increases the rate of particle emissions for each chemical compound.

Participants were instructed to provide ratings in response to a question like that of
Experiment 2. Ratings were made on a scale from 0 (the eld denitely does not cause
the compound to decay) to 100 (the eld denitely does cause the compound to decay).
Each participant completed the survey as part of a booklet of unrelated experiments.

13.2. Results and discussion

The results are shown in Fig. 9, together with the model predictions. There was a
) at DR = 50 (F(2,162) = 12.17, MSE = 257.27,
statistically signicant eect of N(c
p < .001), DR = 10 (F(2,162) = 42.07, MSE = 468.50, p < .001), and DR = 2
(F(2,162) = 29.87, MSE = 321.76, p < .001). Causal support and v2
r gave equivalent
quantitative ts, r = .978, c = 0.35, and r = .980, c = .01, respectively, followed by
grating contrast, r = .924, c = 0.43, and DR, r = .899, c = 0.05. Causal power as-
sumes the wrong statistical model for this kind of data, but might be applied if we
assumed that participants were comparing the rates to some hypothetical maximum
number of particles that might be emitted, N. As N approaches innity, causal power
converges to DR. The trends predicted by causal power do not vary with the choice
of N, so the value N = 150 was chosen to allow these trends to be illustrated. The
predicted trends are clearly at odds with those observed in the data, reected in
the correlation r = .845, c = 0.06.

Since DR predicts that responses within each of the critical sets should be con-
) is inconsistent with this model. This
stant, the statistically signicant eect of N(c
trend is, however, predicted by causal support and v2
r . These predictions reect the
) increases: if the eect oc-
fact that the certainty in the value of k1 decreases as N(c
curs at a high rate in the absence of the cause, it becomes more dicult to determine
if an increase in the number of times the eect is observed when the cause is present
) is thus a sign that people
actually reects a causal relationship. The eect of N(c
are attempting to determine the causal structure underlying their observations. To
demonstrate that these results generalize to cases where rates are supplied perceptu-
ally rather than in summary format, we replicated this experiment using online pre-
sentation in Experiment 5.

370

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

N (c+)
N (c)
100

100
50

60
10

52
2

60
50

20
10

12
2

50

0

100

50

0

100

50

0

100

50

0

100

50

0

100

50

0

52
50

12
10

4
2

Humans

 R

Power (N = 150)

Contrast

Support

2
r

Fig. 9. Predictions of rational models compared with results of Experiment 4. Numbers along the top of
the gure show stimulus rates, error bars indicate one standard error.

14. Experiment 5

14.1. Method

14.1.1. Participants

Participants were 40 members of the MIT Brain and Cognitive Sciences Depart-

ment subject pool.

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

371

14.1.2. Stimuli

The stimuli were the same as those for Experiment 4, with the addition of three
)} pairs

stimuli used for an initial practice phase. These stimuli used the {N(c+), N(c
{20, 28}, {10, 70}, and {16, 16}.

14.1.3. Procedure

The experiment was administered by computer. Participants were provided with
instructions similar to those for Experiment 4, establishing the same laboratory cover
story. The experiment consisted of three practice trials, followed by nine trials that used
the same rate information as Experiment 3. In each trial, participants saw a picture of a
novel mineral substance, and observed it for 30 s while it emitted particles, indicated by
a beep and the temporary appearance of a mark on a particle detector shown on
screen. They then clicked a button to turn on a magnetic eld for another 30 s, and ob-
served the particle emissions in the presence of the magnetic eld. After having ob-
served the mineral both in and out of the magnetic eld, they rated the causal
relationship between the magnetic eld and particle emissions using a slider, with the
same instructions as used in Experiment 4. The actual times of the particle emissions
on each trial were generated from a uniform distribution over 30 s, with a minimum
of 250 ms between emissions to ensure that they were perceptually distinct.

14.2. Results and discussion

The results are shown in Fig. 10, together with the model predictions. The results
reproduced the trends found in Experiment 3, correlating with the previous data at
) at DR = 50
r = .975. There was a statistically signicant eect of N(c
(F(2,78) = 5.82, MSE = 116.81,
(F(2,78) = 23.18,
MSE = 503.18, p < .001), but not at DR = 2 (F(2,78) = .97, MSE = 725.56,
r , and DR all showed similar quantitative t, r = .951,
p = .385). Causal support, v2
c = 0.416, r = .944, c = 0.018, and r = .948, c = 0.085, respectively, followed by grat-
ing contrast, r = .832, c = 0.561. Causal power, computed with N = 150, fared better
on these data than on Experiment 4, r = .912, c = 0.047.

and DR = 10

p < .005)

The statistically signicant dierences among sets of rates for which DR is constant
provides evidence against peoples responses being driven by parameter estimation.
The trends predicted by causal support are slightly less pronounced in these data than
in Experiment 4, which we suspect may be a consequence of the more perceptual pre-
sentation format. In particular, the results for DR = 2 may be a result of greater per-
) increases: for {4, 2} and {12, 10}, it is quite easy to count the
ceptual noise as N(c
number of particle emissions in the presence and absence of the cause, and to make
an inference informed by these counts. For {52, 50}, it is easy to lose count, and people
may be less certain that the dierence is small. Despite these small discrepancies, the
results generally reproduce the trends observed in Experiment 4, and support the same
conclusion: that people are making a structural inference when asked to assess a caus-
al relationship, regardless of whether the data are discrete contingencies or dynamic
rates. Our framework makes it possible to explain these results, and only causal sup-
port predicts human judgments for both of these kinds of data.

372

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

N (c+)
N (c)
100

100
50

60
10

52
2

60
50

20
10

12
2

50

0

100

50

0

100

50

0

100

50

0

100

50

0

100

50

0

52
50

12
10

4
2

Humans

 R

Power (N = 150)

Contrast

Support

2
r

Fig. 10. Predictions of rational models compared with results of Experiment 5. Numbers along the top of
the gure show stimulus rates, error bars indicate one standard error.

15. General discussion

We have presented a rational computational framework for analyzing the prob-
lem of elemental causal induction, using causal graphical models to emphasize the
two components of this problem: parameter estimationestimation of the strength
of a causal relationshipand structure learningevaluation of whether a causal
relationship actually exists. Two leading rational models of elemental causal

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

373

induction, DP and causal power, both address the problem of parameter estimation.
We have described ve phenomena that suggest that, in many circumstances, people
are approaching causal induction as structure learning. Causal support, a rational
solution to the problem of learning causal structure, provides the best account of
the two datasets at the center of the current debate about rational modelsBuehner
and Cheng (1997) and Lober and Shanks (2000)and gives either the best or close to
the best account of 10 out of the 12 other experiments we have analyzed (Anderson
& Sheu, 1995; White, 1998, 2002c, 2003c). It also predicts several eects that no exist-
ing models can account for, in online, summary, and list formats, and in contingency
and rate data, which we have validated through our own experiments.

Our results provide strong evidence that human judgments in causal induction
tasks are often driven by the problem of structure learning, and that causal support
provides an appropriate model of these judgments. We will close by discussing some
issues raised by our analysis. First, we will describe some other models that address
the problem of structure learning. We will then consider the circumstances under
which we expect accounts based upon structure learning and parameter estimation
to be most consistent with human judgments, before going on to clarify the relation-
ship between causal support and ideas such as reliability (Buehner & Cheng, 1997;
Perales & Shanks, 2003). Finally, we will sketch some ways in which our framework
for elemental causal induction can be extended to shed light on other aspects of caus-
al learning.

15.1. Structure learning in other models of causal induction

Our framework can be used to show that the leading models of elemental causal
induction are both based upon parameter estimation. It also makes it possible to
reinterpret several other psychological models in terms of structure learning. These
models dier from causal support in terms of how they approach the issue of infer-
ring causal structure, and in their assumptions about the functional form of the caus-
al relationship between cause and eect. We will briey discuss two models:
Andersons (1990; Anderson and Sheu, 1995) rational model, and Whites (2002c,
2002b) proportion of Conrming Instances model.

15.1.1. Andersons rational model

Anderson (1990) presented a Bayesian analysis of the problem of elemental causal
induction. The model was quite complex, with seven free parameters, and a simpler
model, with four free parameters, was presented by Anderson and Sheu (1995). The
central idea of both models is that causal induction requires evaluating the hypoth-
esis that the cause inuences the eect. In our framework, this is a decision between
Graph 0 and Graph 1, just as in causal support. Under Andersons approach, these
structures have a dierent parameterization from that used in causal support. In-
stead of the noisy-OR parameterization, a separate parameter is used to represent
the probability of the eect for each set of values its causes take on. Either these
parameters (Anderson & Sheu, 1995) or the prior on these parameters Anderson
(1990) are chosen to provide the best t to human data. As noted by Anderson

374

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

and Sheu (1995), this procedure results in predictions that are only slightly more
restricted than linear regression using the cell counts from the contingency table
(cf. Schustack & Sternberg, 1981). In contrast, causal support involves no free
parameters, with the model predictions being computed directly from contingencies,
as with DP and causal power.

15.1.2. The proportion of conrming instances

White (2000, 2002b, 2002a, 2002c, 2003a, 2003c) has also argued that people make
judgments in causal induction tasks by assessing the evidence that a causal relation-
ship exists. White (2002c) dened a measure of evidence termed the proportion of
Conrming Instances (pCI), subsequently modied by White (2003a) to give the
expression

pCI  Ne; c  Ne; c  Ne; c  Ne; c
Ne; c  Ne; c  Ne; c  Ne; c .

16

This equation also appears in other models of elemental causal induction (e.g., Cate-
na et al., 1998), was originally proposed by Inhelder and Piaget (1958, p. 234), and is
). The numerator of Eq. (16) has
monotonically related to DP when N(c+) = N(c
been explored as a model of causal induction in itself, being referred to as DD in
the literature (e.g., Allan, 1980; Allan & Jenkins, 1983; Ward & Jenkins, 1965),
and we show in Appendix A that it can be motivated from the perspective of struc-
ture learning. pCI produces the same predictions as DP for the majority of our exper-
iments, and suers many of the same problems. The exception is its sensitivity to
sample size: as shown in Section 8, it does reasonably well in predicting the eect
), although it cannot account for the results of our Exper-
of varying N(c+) and N(c
iments 2 or 3. When learning from rates, the grating contrast measure dened by
Anderson and Sheu (1995), given in Eq. (12), corresponds exactly to pCI.

15.2. Parameter estimation and structure learning in human judgments

Having distinguished between parameter estimation and structure learning as
components of causal induction, it is natural to ask when we might expect one or
the other to dominate human judgments. We have shown that across many experi-
ments, causal support gives a better account of peoples judgments than the maxi-
mum likelihood parameter estimate for the same model, causal power. These
experiments all used tasks for which a structure-learning interpretation is reasonable.
However, several recent studies have begun to use a dierent question format, asking
people to give a counterfactual conditional probability, for which a strength estimate
is appropriate (Buehner et al., 2003; Collins & Shanks, submitted). For example,
rather than asking Do injections cause gene expression?, we could ask What is
the probability that a mouse not expressing the gene before being injected will ex-
press it after being injected with the chemical?. Such questions elicit responses that
are more consistent with causal power. These results can be explained using the
framework we have established in this paper: causal power gives the maximum like-
lihood estimate of parameter w1 in Eq. (4). The counterfactual questions used in

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

375

these experiments ask for the probability that, for a case in which C was not present
and E did not occur, E would occur if C was introduced. Using the axiomatic treat-
ment of counterfactuals developed by Pearl (2000), this probability is just w1. Con-
sequently, the appropriate way to answer counterfactual questions is via parameter
estimation, and responses should correspond more closely to causal power than to
causal support.

15.3. Causal support and reliability

Buehner and Cheng (1997) appealed to the notion of reliability in trying to ex-
plain aspects of their results that deviated from the predictions of the Power PC theory.
To account for some of the data discussed above, they claimed that people sometimes
conate condence in their estimates of causal power with the estimates themselves.
Shanks and colleagues (Collins & Shanks, submitted; Perales & Shanks, 2003) have fur-
ther explored this reliability hypothesis. Our framework can be used to make the no-
tion of reliability precise, and to explain why it might inuence peoples judgments.

Buehner and Cheng seem to consider reliability of secondary importance in eval-
uating causal relationships, acting something like the error bars on the estimate of
causal power. Perales and Shanks (2003) convey a similar impression, equating reli-
ability with condence in assessments of the strength of a causal relationship. This
notion of reliability thus seems to correspond to the certainty associated with a
parameter estimate. Our framework provides a formal means of distinguishing be-
tween an estimate and its certainty, based upon the posterior distribution on w1,
as shown in Figs. 4 and 5. The location of the peak of this distribution indicates
the strength of a relationship, and the width of this peak indicates the certainty in
that estimate. Viewing causal induction as a structural inference makes it apparent
that neither strength nor reliability should be considered primary: rational causal
inferences should combine both factors. Causal support evaluates the evidence that
w1 diers from zero. This evidence generally increases as the peak of the posterior on
w1 moves away from zero (increasing strength), and as that peak becomes narrower
(increasing reliability).

Our framework explains human judgments as a rational combination of strength
and certainty, rather than the result of strength estimates being confounded by reli-
ability. It also provides some suggestions about the circumstances in which the cer-
tainty in an estimate should be relevant. The results of Buehner et al. (2003) and
Collins and Shanks (submitted) with counterfactual questions, summarized in Sec-
tion 15.2, illustrate that certainty seems to inuence judgments less when a task
explicitly involves parameter estimation. Without the rational explanation provided
by our framework, it is dicult to explain why judgments should be confounded less
by reliability when people are asked counterfactual questions.

15.4. Limitations and extensions

The framework we have described in this paper, and the model of human judg-
ments that we derived from it, causal support, address only the simplest cases of

376

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

causal induction. We have not discussed the dynamics of causal judgments in online
studies, or more complex inductive tasks such as those involving multiple causes. We
will briey consider these limitations, and some potential directions for extending the
framework.

15.4.1. The dynamics of causal judgments

The online presentation format makes it possible to ask participants to provide
responses at several dierent points in the presentation of contingency information,
providing the opportunity to measure the dynamics of causal judgments. Shanks
et al. (1996) and Lo pez et al., 1998 discuss several phenomena involving changes
in judgments over time, and trial order eects have been reported in several other
studies (e.g.,Catena et al., 1998; Collins & Shanks, 2002). Specifying how structure
learning and parameter estimation interact in peoples judgments over time presents
a particularly interesting problem for future research. We have conducted some pre-
liminary work in this direction (Danks, Griths, & Tenenbaum, 2003), using a sim-
ple Bayesian formalism to provide a structure-sensitive strength estimate. This model
also deals naturally with the distinction between generative and preventive causes,
simultaneously updating a probability distribution over underlying models (genera-
tive, preventive, and no relationship) and distributions over the parameters of those
models. This model provides an account of some of the qualitative features of learn-
ing curves from online experiments presented in Shanks et al. (1996).

15.4.2. Multiple causes

Many important phenomena in causal induction, such as backwards blocking
Shanks (1985) and other retrospective revaluation eects (Shanks & Dickinson,
1987; Shanks et al., 1996) involve simultaneously learning about multiple causes.
The framework for elemental causal induction that we have outlined in this paper
can naturally be extended to accommodate multiple causes. The connection with
causal graphical models claries how this extension should be made, as well as iden-
tifying some of the options for dierent modeling approaches. Steyvers et al. (2003)
have shown that this kind of approach can be applied to situations involving multi-
ple causes. We have also demonstrated that an approach based on causal graphical
models can provide an explanation for backwards blocking phenomena in particular
causal induction tasks (Tenenbaum & Griths, 2003).

15.4.3. Non-probabilistic causes

One of the consequences of distinguishing between parameter estimation and
structure learning is a better understanding of causal induction with non-probabilis-
tic causes. Approaches to causal induction based upon strength estimation only pro-
duce meaningful predictions when causes are probabilistic: if a causal relationship is
deterministic, with the cause always producing the eect, the strength of the cause is
1.00. As a consequence, parameter estimation cannot be used to explain how people
draw causal inferences about deterministic systems. Studies of causal induction from
contingency data almost exclusively employ probabilistic causes, so this has not been
identied as an issue for DP or causal power. However, in many studies in the

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

377

broader literature on causal induction people make graded inferences about non-
probabilistic causes (e.g., Gopnik et al., 2004; Tenenbaum, Sobel, Griths, & Gopnik,
submitted). Such inferences can be addressed within our framework: the decision be-
tween causal structures can be made regardless of causal strength, and the degree of
evidence for a causal relationship can vary even with deterministic causes. Our ap-
proach to causal induction produces predictions consistent with peoples judgments
in several settings involving deterministic causes (e.g., Tenenbaum & Griths, 2003).

15.5. Conclusion

We have used causal graphical models to identify two components of the problem
of causal induction: structure learning and parameter estimation. We have shown
that previous rational models of causal induction only address the problem of
parameter estimation. By emphasizing the role of structure learning in human causal
induction, we have been able to explain a variety of phenomena that were problem-
atic for previous models, and to understand the inference that underlies the discovery
that a causal relationship actually exists. Our approach explains not only lay peoples
fundamental intuitions about cause and eect, but also the intuitions that drove dis-
covery for early scientists, such as Dr. James Currie of the epigraph, and that con-
tinue to be important in the early stages of much contemporary scientic research.
Looking beyond the simple setting of elemental causal induction, our Bayesian
approach provides a method for explaining how prior knowledge and statistical
inference might be combined in causal learning. Human judgments about causality
draw upon a rich body of knowledge about the mechanisms mediating between caus-
es and eects, which relationships are plausible, and what functional forms particu-
lar relationships might take. The simple Bayesian inference that underlies our
account of elemental causal induction can be augmented to capture the role of this
knowledge, via constraints on the prior probabilities of particular causal relation-
ships, and constraints on the functional form of the probability distributions dened
on those structures. This capacity to capture the interaction between top-down
knowledge and bottom-up statistical cues is one of the greatest strengths of our
framework, and we are currently exploring how it might explain a broader range
of causal inferences, including those that involve sparse data, hidden causes, and
dynamical physical systems.

Appendix A.

A.1. DP and causal power are maximum likelihood parameter estimates

Both DP and causal power are maximum likelihood estimates of the causal
strength parameter for C in Graph 1 of Fig. 3(A), but under dierent parameteriza-
tions. For any parameterization of Graph 1, the log likelihood of the data is given by
17

Ne; c log P 1ejc;

log PDjw0; w1 

X

e;c

P

378

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

where D is contingency data N(e, c), P1(e|c) is the probability distribution implied by
the model, suppressing its dependence on w0, w1, and
e;c denotes a sum over all
. Eq. (17) is maximized whenever w0 and w1 can be chosen
pairs of e+, e
to make the model probabilities equal to the empirical probabilities:

 and c+, c

P 1ejc; b; w0; w1 Pejc;
P 1ejc; b; w0; w1 Pejc.

). Eq. (6) then reduces to P(e+|c+) for the case c = c+ and to P(e+|c

18
19
To show that DP corresponds to a maximum likelihood estimate of w1 under a linear
parameterization of Graph 1, we identify w1 in Eq. (6) with DP (Eq. (1)), and w0 with
) for the
P(e+|c
, thus satisfying the sucient conditions in Eqs. (18) and (19) for w0 and
case c = c
w1 to be maximum likelihood estimates. To show that causal power corresponds to a
maximum likelihood estimate of w1 under a noisy-OR parameterization, we follow
the analogous procedure: identify w1 in Eq. (4) with causal power (Eq. (2)), and
) for
w0 with P(e+|c
, again satisfying the conditions for w0 and w1 to be maximum likelihood
c = c
estimates.

). Then Eq. (4) reduces to P(e+|c+) for c = c+ and to P(e+|c

A.2. DD, pCI, and structure learning

DD is approximately proportional to the log likelihood ratio in favor of Graph 1
be
2  for small e, and the parameterization of

Graph

the

of

to

1

2. This choice of parameters gives

we

dene

if
parameterization
P 1ejc; b  P 1ejc; b  1
2  1
Graph 0 to be P 0ejb  1
P 1ejc; b
P 0ejb  P 1ejc; b
P 1ejc; b
P 0ejb  P 1ejc; b

P 0ejb  1  ;
P 0ejb  1  

and since log1  x  x, for values of x near 0, it follows that:

PDjGraph 1
PDjGraph 0   Ne; c  Ne; c  Ne; c  Ne; c
.



log

However, the assumptions under which this unweighted combination of counts is an
appropriate measure of the evidence for a causal relationship are overly restrictive:
the background probability of the eect has to be 0.5, and the cause must be asymp-
totically weak. The denition of pCI, which normalizes this quantity by the sum of
all entries in the contingency table, cannot be motivated from the perspective of
structure learning, since it removes the eect of overall sample size.

A.3. Evaluating causal support

Causal support is dened as the log likelihood ratio in favor of Graph 1 over

Graph 0:

20

21

22

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

support  log

PDjGraph 1
PDjGraph 0 .

379

23

We obtain the likelihoods P(D|Graph 1),P(D|Graph 0) by integrating out the param-
eters w0, w1. This means that each value of the parameters is assigned a prior prob-
ability, and this probability is combined with the likelihood of the data given the
structure and the parameters to give a joint distribution over data and parameters
given the structure. We can then sum over all values that the parameters can take
on, to result in the probability of the data given the structure. Thus, if we want to
compute the probability of the observed data for the structure depicted by Graph
1, we have

Z

Z

PDjGraph 1 

1

1

0

0

P 1Djw0; w1; Graph 1Pw0; w1jGraph 1dw0 dw1

and the equivalent value for Graph 0 is given by

Z

PDjGraph 0 

1

0

P 0Djw0; Graph 0 Pw0jGraph 0 dw0;

24

25

where the likelihoods P(D|w0, w1, Graph 1), P(D|w0, Graph 0) are specied by the
parameterization of the graph, and the prior probabilities P(w0, w1|Graph 1),
P(w0|Graph 0) are set a priori. Integrating over all values of the parameters penalizes
structures that require more parameters, simply because the increase in the dimen-
sionality of the space over which the integrals are taken is usually disproportionate
to the size of the region for which the likelihood is improved.

For generative causes, P(D|Graph 1) is computed using the noisy-OR parameter-
ization, and for preventive causes, it is computed using the noisy-AND-NOT. We
also need to dene prior probabilities P(w0, w1|Graph 1) and P(w0|Graph 0), to which
we assign a uniform density. Because causal support depends on the full likelihood
functions for both Graph 1 and Graph 0, we may expect causal support to be mod-
ulated by causal power, but only in interaction with other factors that determine how
much of the posterior probability mass for w1 in Graph 1 is bounded away from zero
(where it is pinned in Graph 0). In the model for rate data, k0 and k1 are both positive
real numbers, and priors for these parameters require dierent treatment. We take a
joint prior distribution in which Pk0 / 1
is an uninformative prior, and P(k1|k0) is
Gamma(1,k0).

k0

A.4. An algorithm for computing causal support

Eq. (25) can be evaluated analytically. If w0 denotes the probability of the eect
occurring regardless of the presence or absence of the cause and we take a uniform
prior on this quantity, we have

Z

PDjGraph 0 

1

wNe

0

0

1  w0Ne

dw0  BNe  1; Ne  1;

26

380

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

where B(r, s) is the beta function, and N(e+) is the marginal frequency of the eect.
For integers r and s, B(r, s) can be expressed as a function of factorials, being
r1!s1!
rs1! . In general Eq. (24) cannot be evaluated analytically, but it can be approx-
imated simply and eciently by Monte Carlo simulation. Since we have uniform pri-
ors on w0 and w1, we can obtain a good approximation to P(D|Graph 1) by drawing
m samples of w0 and w1 from a uniform distribution on [0,1] and computing

X

m

PDjGraph 1  1
m

i1

P 1Djw0i; w1i; Graph 1;

27

where w0i and w1i are the ith sampled values of w0 and w1. We thus need only com-
pute the probability of the observed scores D under this model for each sample,
which can be done eciently using the counts from the contingency table. This prob-
ability can be written as

Y

P 1Djw0i; w1i; Graph 1 

P 1ejc; b; w0i; w1iNe;c

;

28

e;c

 and c+, c

, and P1(e|c;w0i, w1i) reects the cho-
where the product ranges over e+, e
sen parameterizationnoisy-OR for generative causes, and noisy-AND-NOT for
preventive. As with all Monte Carlo simulations, the accuracy of the results im-
proves as m becomes large. For the examples presented in this paper, we used
m = 100,000. Matlab code for evaluating causal support via Monte Carlo simulation
can be obtained by writing to the corresponding author, or from the authors
webpages.

A.5. The v2 approximation

For large samples and weak causes we can approximate the value of causal sup-
port with the familiar v2 test for independence. There are both intuitive and formal
reasons for the validity of the v2 approximation. Intuitively, the relationship holds
because the v2 statistic is used to test for the existence of statistical dependency be-
tween two variables, and C and E are dependent in Graph 1 but not in Graph 0. A
large value of v2 indicates that the null hypothesis of independence should be reject-
ed, and that Graph 1 is favored. However, v2 assumes a dierent parameterization of
Graph 1 from causal support, and the two will only be similar for large samples and
weak causes.

The formal demonstration of the relationship between v2 and causal support is as
follows. When the likelihood P(D|w0, w1) is extremely peaked (e.g., in the limit
N  1), we may replace the integrals in Eq. (24) with supremums over w0, w1. That
is, the marginal likelihood essentially becomes the maximum of the likelihood, and
causal support reduces to the ratio of likelihood maximaor equivalently, the dif-
ference in log likelihood maximafor Graph 1 and Graph 0. Under these circum-
stances causal support reduces to the frequentist likelihood ratio statistic, equal to
half of the G2 statistic (e.g., Wickens, 1989). Correspondingly, Pearsons v2 for
independence

T.L. Griths, J.B. Tenenbaum / Cognitive Psychology 51 (2005) 334384

381

29

P

X

v2  N

e;c



Pe; c  PePc

2

;

PePc
P
ipi log pi
qi

can be shown to approximate twice causal support by a Taylor series argument: the
second-order Taylor series of
(Cov-
er & Thomas, 1991). The v2 approximation only holds when DP is small and N is
large.

, expanded around p = q, is 1
2

piqi2

qi

i

For learning with rates, the likelihood ratio statistic for comparing Graphs 0 and

1 under the parameterization given in Eq. (14) is

r Nc log Nc  Nc log Nc  Nc  Nc log
v2

;
30
which, by essentially the same argument as that given above for G2, will approximate
the value of causal support in the large sample limit. Using the Taylor series argu-
ment employed in the contingency case, we obtain the v2 approximation given in
Eq. (15), which holds only when the dierence in rates is small.

2

Nc  Nc

