Abstract

for example,

Markov Chain Monte Carlo (MCMC) al-
gorithms are routinely used to draw sam-
ples from distributions with intractable nor-
malization constants. However, standard
MCMC algorithms do not apply to doubly-
intractable distributions in which there are
additional parameter-dependent normaliza-
tion terms;
the posterior
over parameters of an undirected graphi-
cal model. An ingenious auxiliary-variable
scheme (Mller et al., 2004) oers a solution:
exact sampling (Propp and Wilson, 1996) is
used to sample from a MetropolisHastings
proposal for which the acceptance probabil-
ity is tractable. Unfortunately the accep-
tance probability of these expensive updates
can be low. This paper provides a generaliza-
tion of Mller et al. (2004) and a new MCMC
algorithm, which obtains better acceptance
probabilities for the same amount of exact
sampling, and removes the need to estimate
model parameters before sampling begins.

1 Introduction

Markov Chain Monte Carlo (MCMC) methods draw
correlated samples from a distribution of interest,

(1)

p(y|) = f(y; )/Z(),

normalization Z() = R f(y; ) dy is often unknown;

and use these samples to construct estimators. The

standard MCMC methods are designed for use with in-
tractable distributions. The Markov-chain update rule
restricts each move to a manageable subset of the ys
state space: in MetropolisHastings only two settings
are considered, the current setting y and a randomly
chosen proposal, y0; Gibbs sampling changes only one

component of y at a time. Metropolis requires an abil-
ity to evaluate f(y; ) for various y, and Gibbs sam-
pling requires the ability to sample from the condi-
tional distributions dened by f, but neither method
needs to know the normalizing constant Z().
We now consider sampling from the posterior over pa-
rameters, , rather than the variables, y. Given a prior
p(), the posterior is

(cid:18) f(y; )p()

(cid:19).

Z()

p(|y) =

p(y).

(2)

For many models of interest Z() cannot be computed.
This includes learning in many interesting models,
e.g. large-tree-width undirected graphical models and
some spatial point processes. Although p(y) is not
needed, the normalizing constant Z() can not be
ignored as it is a function of the parameters.1 Al-
most all known valid MCMC algorithms for  require
an ability to compute values or ratios of Z() for the
parameter settings considered at each iteration. As
MCMC estimators are approximations unless an in-
nite number of iterations are performed, and each
iteration requires an infeasible computation, we call
p(|y) a doubly-intractable distribution.
In previous work we conjectured that for general undi-
rected models, there are no tractable MCMC schemes
giving the correct equilibrium distribution over param-
eters (Murray and Ghahramani, 2004). Our pragmatic
solution was to explore a variety of approximations for
the unknown normalizers and their ratios. Such ap-
proximations can give useful results, but will not lead
to a Markov chain with the correct stationary distri-
bution. This can cause problems in practice.
An ingenious approach by Mller et al.
(2004)
describes an ecient Markov chain Monte Carlo
method for distributions with intractable normalising
constants, which we will refer to as the single aux-

1This potential source of confusion suggests favoring the

statistical physics term partition function.

iliary variable method (SAVM). Here ecient means
that in some situations the algorithm will be feasible,
unlike all other valid MCMC methods of which we are
aware. Our conjecture still stands, but SAVM oers
an exciting way out for distributions in which exact
sampling is possible. Here, we generalize SAVM and
then construct a new method which is easier to apply
and has better performance.
In section 2 we review the SAVM method from Mller
et al. (2004). Our interpretation suggests a general-
ization, described in section 3, which should improve
acceptance at a modest cost (section 5). We then in-
troduce a new family of algorithms in section 4, which
seem preferable to the SAVM variants.

2 The Single Auxiliary Variable

Method

In this section we describe the SAVM method due to
Mller et al. (2004). We focus our attention on a joint
distribution of the form (gure 1(a)):
p(y, ) = p(y|)p() = f(y; )

(3)

Z() p().

Here we assume that p() is a simple distribution and
that y is a vector containing all variables with soft mu-
tual constraints (e.g. the state of an undirected graph-
ical model). We will assume that the y are observed.
Note that unobserved y, or children of y would not
cause any special dicultly: unlike  these variables
could be sampled with standard MCMC and would
otherwise behave like the y that are observed. See
Mller et al. (2004) for a more detailed discussion of
special cases.
The standard MetropolisHastings (MH) algorithm
(Hastings, 1970) constructs a Markov chain through
proposals drawn from an arbitrary distribution q.

MetropolisHastings Algorithm
Input: initial setting , number of iterations T

Propose 0  q(0; , y)
Compute a = p(0|y)q(;0,y)
p(|y)q(0;,y)

1. for t = 1 . . . T
2.
3.
4. Draw r  Uniform[0, 1]
5.
6. end for

if (r < a) then set  = 0.

Ideal proposals, q(0; , y), would be constructed for
rapid exploration of the posterior p(0|y). However,
simple perturbations such as a Gaussian with mean
 are commonly chosen. The accept/reject step, 5 in
the algorithm, corrects for the mismatch between the
proposal and target distributions.

(a)

(b)

Figure 1:
(a) the original model, unknown parameters
 generated observed variables y, (b) the SAVM aug-
mented model. The conditional distribution of x must
have a tractable  dependence.
In existing approaches
this distribution is only a function of one of y or , e.g.
f (x; (y))/Z() or a normalizable function of (x, ).

q(; 0, y)
q(0; , y)

= f(y; 0)p(0)q(; 0, y)
f(y; )p()q(0; , y)

There appears to be no practical way to implement the
standard MH algorithm for doubly-intractable distri-
butions. The acceptance ratio becomes
a= p(0|y)
p(|y)

 Z()
Z(0) .
(4)
Perhaps the requirement to compute Z() can be re-
moved? We are not free to change f, which denes our
model. In theory the proposals could be dened to re-
move explicit Z dependence from (4), but in practice
this does not seem to help: e.g. q(0; , y) =Z()g(0)
or q(0; , y)  1/Z(0) would be dicult to construct
without knowing Z, and would be terrible proposals.
Instead Mller et al. (2004) extend the joint distribu-
tion to include an auxiliary variable, x, which shares
the same state space as y (gure 1(b)):

p(x, y, ) = p(x|, y) f(y; )

Z() p().

(5)

The joint distribution p(y, ) is unaected. No known
method of dening auxiliary variables removes Z()
from the joint distribution. However, through careful
choice of q, explicit Z() dependence can be removed
from the MH ratio for this distribution:
a = p(x0, 0|y)q(x, ; x0, 0, y)
p(x, |y)q(x0, 0; x, , y) .

(6)

A convenient form of proposal distribution is
q(x0, 0; x, , y) = q(0; , y)q(x0; 0),

(7)

which corresponds to the usual change in parameters
  0, followed by a choice for the auxiliary variable.
If this choice, which happens to ignore the old x, uses

q(x0; 0) = f(x0; 0)/Z(0) ,

(8)

yyxq(; 0, y)
q(0; , y)
f(x; )Z(0)
f(x0; 0)Z()

q(; 0, y)
q(0; , y)

where f and Z are the same functions as in p(y|),
equation (1), then the MH acceptance ratio becomes
a = p(x0|0, y)
p(x|, y)

q(x; x0, )
q(x0; x, 0)

p(0|y)
p(|y)

Z()f(y; 0)p(0)
Z(0)f(y; )p()

= p(x0|0, y)
p(x|, y)
= f(y; 0)p(0)
f(y; )p()

q(; 0, y)
q(0; , y)

 p(x0|0, y)
p(x|, y)

f(x; )
f(x0; 0) .

(9)

Now every term can be computed. The big assump-
tion is that we can draw independent, exact sam-
ples from the proposal distribution (8). Surprisingly
this is possible for some interesting distributions over
large numbers of variables with undirected constraints
(Propp and Wilson, 1996). The algorithms typically
require tracking sets of states through a random, possi-
bly large, number of Markov chain steps; see (Wilson,
1998) for reviews and examples.
The missing part of this description was the condi-
tional distribution of the auxiliary variable p(x|, y).
This choice is not key to constructing a valid MH al-
gorithm but our choice will have a strong impact on
the eciency of the Markov chain. Normally we have a
choice over the proposal distribution. Here that choice
is forced upon us and instead we choose the target dis-
tribution p(x|y, ) to match the proposals as closely as
possible. We can not maximize the acceptance rate by
choosing p(x|y, ) = f(x; )/Z(), as that would rein-
troduce explicit Z() terms into the MH ratio. Two
possibilities are 1) use a normalizable approximation
to the ideal case, 2) replace  with a xed value

p(x|, y) = p(x|y) = p(x|(y)) = f(x; )
Z()

,

(10)

where  is a point estimate of the parameters, such
as the maximum pseudo-likelihood estimate based on
the observations y. When the normalization is xed,
it will cancel in (9). The broken lines in gure 1(b)
indicate that while x could be a child of  and y,
in practice all previous methods have used only one
of the possible parents. For concreteness we assume
p(x|, y) = f(x|)/Z() for some xed (y) in all that
follows, but our results are applicable to either case.

3 A tempered-transitions renement

The MH rule using the acceptance rate (9) must im-
plicitly estimate the relative importance of pairs of
states; in some sense it is using the additional ran-
dom variables to approximate the acceptance ratio (4).
This becomes apparent by identifying two unbiased

one-sample importance-sampling estimators:

x0  f(x; 0)/Z(0)

(11)

Z()
Z(0)
Z()
Z()

 f(x0; )
f(x0; 0)
 f(x; )
f(x; )

x  f(x; )/Z()

(12)
A biased estimate of Z()/Z(0) is obtained by divid-
ing (11) by (12). The unknown constant Z() fortu-
itously cancels. Unlike previous attempts, substituting
this elementary approximation into the MH rule (4)
leads to a valid algorithm.
Given the simple nature of SAVMs importance sam-
pling estimators, or equivalently the mismatch be-
tween p(x|, y) and q(x; , y), the MH algorithm can
suer a high rejection rate. Annealed importance sam-
pling (AIS) (Neal, 2001; Jarzynski, 1997) is a natu-
ral way to make the target and proposal distributions
closer to improve estimators of normalizing constants.
Linked importance sampling (Neal, 2005) could also
be used as a drop-in replacement. We now show that
this is a valid extension of SAVM.
We notionally extend the auxiliary variables x to an
ensemble of similar variables X = {x1, x2, ...xK+1}
(gure 2). We give x1 the same conditional distribu-
tion (10) as the single auxiliary variable x in SAVM.
The distribution over the remaining variables is de-
ned by a sequence of Markov chain transition opera-
tors Tk(xk+1; xk) with k = 1 . . . K:

p(x2|x1, , y)  T1(x2; x1, , (y))
p(x3|x2, , y)  T2(x3; x2, , (y))



p(xK+1|xK, , y)  TK(xK+1; xK, , (y)).

(13)

Transition operator Tk is chosen to leave a distribution
pk stationary. The sequence of stationary distribu-
tions should bridge from the approximate or estimator-
based distribution p(x1|, y) towards the distribution
f(x; )/Z() from which are forced to draw an ex-
act sample as part of the proposal. One interpolation
scheme is:
pk(x; , )  f(x; )k f(x; )(1k)  fk(x; , ). (14)

The sequence

k = K  k + 1

K + 1

(15)

is used in Neal (2004) as a default choice. Note that
as with AIS, the nal stationary distribution, pK, is
nearly the same as f(x; )/Z() for large K. Other sets
of bridging distributions may perform better, although
nding them may be dicult (Meng and Wong, 1996).
We now perform MH sampling on the new joint dis-
tribution p(, X|y). First we propose a change in pa-
rameters, 0  q(0; , y), as before. Then a change in

cancel. We call this method with K  1 the multiple
auxiliary variable method (MAVM).
While we were motivated by improving the impor-
tance sampling like estimators using AIS, it turns out
MAVM is more closely related to Tempered Transi-
tions (Neal, 1996). Our approach has cheaper moves
than standard tempered transitions, which would re-
generate x1 . . . xK+1 from p(X|, y) before every M
H proposal. This trick could be applied to tempered
transitions in general; the trade-o with acceptance
rate will be explored in future work.
In reviewing SAVM it appeared that the auxiliary pro-
posal distribution had to consist of a single exact sam-
ple. Our extension allows us to augment the sample
with a xed number of additional steps. This allows
us to improve the implicit normalization constant es-
timation and improve the acceptance rate, for some
additional cost. However, no further expensive exact
sampling, on top of that needed by the original algo-
rithm, is required per iteration. The performance as a
function of K is explored in section 5.
We have also provided an answer to an open question
in Mller et al. (2004) on how to use both  and y
in p(x|, y). We use y in coming up with the point
estimate of the parameters to get the distribution in
roughly the right place. Then we bridge towards a
better t for  using tempered transitions.

We know the SAVM algorithm is valid, as it is an
implementation of MH. And we have a pseudo-
explanation in terms of importance sampling, which
motivated MAVM. However, the meaning of the aux-
iliary variables has been left unexplained. It is tempt-
ing to draw parallels with alternative algorithms, e.g.
the Boltzmann machine learning rule (Ackley et al.,
1985) also involves generating variables that exist in
the same state space as the observed variables. How-
ever, it seems dicult to attach any general meaning to
the auxiliary variable settings visited by the Markov
chain. The correlated samples come asymptotically

fromR p(x|y, )p() d, which can be arbitrary. In this

section we derive a method which draws more mean-
ingful variables. In section 5 we will see that our sim-
pler method leads to an improvement in performance.
It was unclear why two normalizing constant ratio esti-
mates were needed as a proxy for Z()/Z(0). A more
direct estimate is obtained from a single one-sample
unbiased importance sampler:

Z()
Z(0)

 f(x; )
f(x; 0)

x  f(x; 0)/Z(0).

(19)

(16)

4 Simpler, more direct methods

Figure 2: The joint distribution for the annealing-based
multiple auxiliary variable method (MAVN). Here it is as-
sumed that p(x1|, y) is based only on a data-driven pa-
rameter estimate as in (10). The auxiliary variables bridge
towards the distribution implied by . The gray-level and
thickness of the arrows from y and  indicate the strengths
of inuence, k, on the auxiliary variables in (14).

X is proposed in reverse order: xK+1 is drawn by
exact sampling from the same distribution as in SAVM
and xK . . . x1 are proposed using transition operators
that bridge towards p(x1|0, y):

q(xK+1; 0, y) = f(xK+1; 0)/Z(0)
 pK+1(xK+1|0, (y))

q(xK; xK+1, 0, y)  TK(xK; xK+1, 0, (y))
q(xK1; xK, 0, y)  TK1(xK1; xK, 0, (y))



q(x1; x2, 0, y)  T1(x1; x2, 0, (y)) ,

where Tk are the corresponding reverse transition op-
erators to those used to dene p(X|, y), such that

Tk(x0; x)pk(x) = Tk(x; x0)pk(x0) .

(17)

1, x0

The MH ratio for accepting the whole move (, X =
2, ...}) is still free of any
{x1, x2, ...})  (0, X0 ={x0
explicit Z()-dependence. Substituting equations (13)
and (16) into (6), eliminating T with (17), rearranging
and cancelling gives:
a = f(y; 0)p(0)
f(y; )p()
fk(x0
fk+1(x0

fk+1(xk+1; , )
fk(xk+1; , )

k+1; 0, )
k+1; 0, )

q(; 0, y)
q(0; , y)



KY

k=0

(18)

.

The terms have been arranged to make it clear that
all ratios involving the auxiliary variables can be com-
puted online as the transitions T are generated. As in
SAVM (K = 0), all unknown normalization constants

yx1x2xKxK+1=

to ensure that wj = y, we deterministically swap the
settings of wi and wj. The new and old states of the
Q
joint model have probability ratio:
Q
p(j)f(y; j)f(wj; i)(((((((
p({w0
l}, j)
l6=i,j f(wl; l)
p(i)f(y; i)f(wj; j)(((((((
p({wl}, i)
l6=i,j f(wl; l) .
As all terms involving wl6=i,j cancel, we need only know
the initial setting of wj. Under the joint model p(wj)=
f(wj; j)/Z(j); we can generate wj when required by
exact sampling. This is not part of the proposal, which
was deterministic after the change of index i  j. We
simply deferred nding out what wj was until it was
needed. The MH ratio becomes
a = q(i; j)p(j)f(y; j)
q(j; i)p(i)f(y; i)

 f(wj; i)
f(wj; j)

(21)

for which all terms are tractable. Loosely speaking the
second term acts as the importance sampling estimate
suggested at the beginning of the section. Compare
this to the last term of (9) for SAVM.
Despite the underlying innite model, the resulting
algorithm is slightly simpler than the original SAVM:

Single-variable Exchange algorithm
Input: initial , number of iterations T

4.

1. for t = 1 . . . T
2.
3.

Propose 0  q(0; , y)
generate an auxiliary variable,
w  f(w; 0)/Z(0)
Compute
a = q(; 0, y)p(0)f(y; 0)
q(0; , y)p()f(y; )
5. Draw r  Uniform[0, 1]
if (r < a) then set  = 0.
6.
7. end for

 f(w; )
f(w; 0)

(22)

We call this the exchange algorithm. Each step tries
to take the data y from the current parameter set-
ting . We speculate that a better parameter setting
is 0, which was generated by q(0; , y). How can we
persuade  to give up the data to the rival parameter
setting 0? We oer it a replacement data set w from
0s distribution.
If f(w; )/f(y; ) > 1 then this re-
placement is preferred by  to the real data y, which
is a good thing. We have to consider both sides of
the exchange: the ratio f(y; 0)/f(w; 0) measures how
much 0 likes the trade in data sets. The other terms
in (22) respect any disparity between the frequency
with which we propose swaps and our prior preference
over the parameter that should own the data.
The exchange algorithm is a valid MCMC method be-
cause it is the MH algorithm for a joint system with
the correct posterior distribution p(i|y). We now out-
line a more direct mathematical proof; see Neal (2004,

Figure 3: An alternative representation of the generative
model for observations y. All possible parameter settings,
l, are instantiated, xed and used to generate a set of data
variables wl. The indicator i is used to set y = wi. The
posterior over i, the parameter chosen by the indicator
variable i, is identical to p(|y) in the original model.

In this section we provide a proof that using this direct
estimator leads to a valid algorithm. The work in this
section was originally inspired by relating Carlin and
Chib (1995) to SAVM. The joint model we use is also
related to parallel or replica tempering methods in the
physics literature, e.g. Swendsen and Wang (1986).
Consider a huge model in which all possible parameter
settings l exist. Each parameter setting generates its
own setting of variables

wl  f(wl; l)/Z(l).

(20)

To generate the data, y, we choose an index using the
same prior over parameters as in our original model
i  p(i) = p(i) , and copy y from wi: p(y) = (ywi).
This generative model is illustrated in gure 3. The
marginal distribution over y is identical to that of the
original model. Also the prior and posterior over which
parameter i generated the data is equivalent to the
distributions over the original . All that is dierent
is that we also choose to generate a lot of unobserved
data, {wl6=i}, which does not aect the marginal dis-
tribution over the variables of interest.
If the parameters take on a nite number of possi-
ble settings, standard MCMC would now apply. All
normalizing constants, Zl(l), appear in the joint dis-
tribution for all choices of the index i and therefore
cancel in MH ratios. However, all the variables wl
must be instantiated and sampled for suciently long
to reach equilibrium. Navely it seems this is a very
costly or impossible approach. However, we now out-
line how, through judicious use of exact sampling, it
is possible to deal with this model even in the limit of
an innite number of possible parameter settings.
Consider starting a chain with index i and proposing
a change to index j with probability q(j; i). In order

=1=2=3=4w1w2w3w4yip3) for the details of a similar proof. It is easily shown
that detailed balance holds for any particular interme-
diate exact sample w by checking that the probability
of starting at i (under the intended equilibrium dis-
tribution p(i|y)) and then moving to j via the exact
sample w is symmetric in i and j. Summing over the
intermediate quantity w gives detailed balance overall.

4.1 Reinterpreting SAVM

Seen in the light of the joint distribution in gure 3, the
SAVM method appears slightly strange. The SAVM
method can be reproduced by augmenting the joint
model in gure 3 with the SAVM auxiliary variable,
x, and using the following proposal:
1. Draw j  q(j; i)
2. Deterministically perform the three-way swap x =

wj, wi = x and wj = y.

The acceptance factor for this proposal is precisely the
MH ratio in (9). If we want to take y from i and
give it to rival setting j why involve a third parameter
? In section 5 we see that the third party can make
the transaction harder (gure 6) or mediate it (gure
4). In the next section we add auxiliary variables to
the exchange algorithm that are specically designed
to make the swap more palatable.

4.2 Bridging

In section 3 we improved SAVMs proposal distribu-
tion by bridging between the original proposal and tar-
get distributions. A similar renement can be applied
to the exchange algorithm. After taking the new pa-
rameters data we take steps to make it more appealing
to the current parameter. The general exchange algo-
rithm with bridging is shown opposite; K = 0 recovers
the previous single-variable version.
This bridging method is slightly less general than our
extension to SAVM, as the transition operators R must
satisfy detailed balance:

Rk(x0; x, , 0)pk(x; , 0)

= Rk(x; x0, , 0)pk(x0; , 0),

(25)

where the stationary distributions pk and correspond-
ing fk are dened as before in equations (14) and (15),
i.e. pk(x; , 0)  fk(x; , 0) = f(x; 0)k f(x; )1k.
For clarity the details of the motivating innite model,
section 4, have been omitted from the algorithm. The
correspondence is as follows: the exact sample x0 
p0(x0; , 0) is the current setting of w0 corresponding
to 0, which we then make more attractive to  through
a sequence of transitions before proposing to set w =
xK and w0 = y.

Exchange algorithm with bridging
Input: initial , #iterations T , #bridging levels K

1. for t = 1 . . . T
2.
3.

Propose 0  q(0; , y)
generate K + 1 auxiliary variables:

x0  p0(x0; , 0)

 f(x0; 0)/Z(0)
x1  R1(x1; x0, , 0)
x2  R2(x2; x1, , 0)



xK  RK(xK; xK1, , 0)

(23)

4.

Compute
a = q(; 0, y)p(0)f(y; 0)
q(0; , y)p()f(y; )
5. Draw r  Uniform[0, 1]
6.
7. end for

if (r < a) then set  = 0.

 KY

k=0

fk+1(xk; , 0)
fk(xk; , 0)
(24)

Sketch:

The proof of validity is again a strong detailed bal-
ance condition.
the probability of being
in state i at equilibrium, obtaining the numbers
(x0, x1, x2, . . . , xK) and transitioning to state j is the
same as the probability of being in state j at equilib-
rium, obtaining the numbers (xK, . . . , x2, x1, x0) and
transitioning to state i. Summing over all possible
settings of intermediate auxiliary variables gives de-
tailed balance overall.

5 Comparison of the algorithms

We consider a concrete example for which all com-
putations are easy. This allows comparison with ex-
act partition function evaluation as in (4) and av-
eraging over chains starting from the true posterior.
We consider sampling from the posterior of a sin-
gle precision parameter , which has likelihood corre-
sponding to N i.i.d. zero-mean Gaussian observations
y = {y1, y2, . . . yN}, with a conjugate prior:
p(yn|)=N (0, 1/), p(|, )=Gamma(, ). (26)

The corresponding posterior is tractable

p(|y) = Gamma(cid:0)N/2 + , P

n/2 + (cid:1) ,

n y2

(27)

but we pretend that the normalizing constant in the
likelihood is unknown. We compare the average accep-
tance rate of the algorithms for two choices of proposal
distribution q(0; , y).

All of the algorithms require N exact Gaussian sam-
ples, for which we used standard generators. We also
draw directly from the stationary distributions, pk, in
the bridging algorithms. This simulates an ideal case
where the energy levels are close, or the transition op-
erators mix well. More levels would be required for
the same performance with less ecient operators. We
now report results for =1,  =1, N =1 and y =1.
The rst experiment uses proposals drawn directly
from the parameter posterior (27). The MH accep-
tance probability in (4) becomes a  1; all propos-
als would be accepted if Z() were computed exactly.
Therefore any rejections are undesirable by-products
of the auxiliary variable scheme, which can (implic-
itly) obtain only noisy estimates of the normalizing
constants. Figure 4 shows that both MAVM and the
exchange algorithm improve over the SAVM baseline.
It appears that a large number, K, of bridging levels
are required to bring the acceptance rate close to the
attainable a = 1. However, signicant benet is ob-
tained from a relatively small number of levels, after
which there are diminishing returns. As each algo-
rithm requires an exact sample, which in applications
can require many Markov chain steps, the improve-
ment from a few extra steps (K >0) can be worth the
cost (see section 5.1).
In this articial situation the performance of MAVM
was similar to the exchange algorithm. This result fa-
vors the exchange algorithm, which has a slightly sim-
pler update rule and does not need to nd a maximum
(pseudo)-likelihood estimate before sampling begins.
In gure 4 we had set  = 1. Figure 5 shows that the
performance of MAVM falls o when this estimate is of
poor quality. For moderate K, the exchange algorithm
automatically obtains an acceptance rate similar to the
best possible performance of MAVM; only for K = 0
was performance considerably worse than SAVM. For
this simple posterior  sometimes manages to be a use-
ful intermediary, but by K =1 the exchange algorithm
has caught up with MAVM.
More importantly, the exchange algorithm performs
signicantly better than SAVM and MAVM in a
more realistic situation where the parameter proposal
q(0; , y) is not ideal. Figure 6 shows results using
a Gaussian proposal centred on the current param-
eter value. The exchange algorithm exploits the lo-
cal nature of the proposal, rapidly obtaining the same
acceptance rate as exactly evaluating Z(). MAVM
performs much worse, although adding bridging lev-
els does rapidly improve performance over the original
SAVM algorithm. SAVM is now hindered by , which
is more rarely between  and 0.
The posterior distribution over , equation (27), be-

Figure 4: Average acceptance rate as a function of K for
the Gaussian example (section 5). MAVM with K = 0
corresponds to SAVM, the method of Mller et al. (2004).
Exact normalizing constant evaluation in (4) would give an
acceptance rate of one.

Figure 5: Average acceptance rate under the example in
section 5 as a function of the initial parameter estimate
required by SAVM (K = 0) and our extended version,
MAVM. Horizontal bars show the results for the exchange
algorithm, which has no , for K = 0, 10, 100.

Figure 6: As in gure 4 but with a Gaussian proposal
distribution of width 0.1 centered on the current parameter
setting. The horizontal line shows the maximum average
acceptance rate for a reversible transition operator, this is
obtained by exact normalizing constant evaluation in (4).

0.750.80.850.90.951050100150200250300ave.acceptanceprobabilityKExchangeMAVMSAVM0.60.650.70.750.80.850.90.9510.1110ave.acceptanceprobabilityMAVM,K=100MAVM,K=10SAVM0.820.840.860.880.90.920.940.96050100150200250300ave.acceptanceprobabilityKExchangeMAVMSAVMonly recover a = 1 as K  . This is because the
third party in the proposed swap (see section 4.1) is
not necessarily close to . Even in a simple unimodal
1-dimensional posterior distribution, gure 6, this is
a signicant disadvantage in comparison with the ex-
change algorithm. We found the exchange algorithm
performs better than the only other existing MCMC
method for this problem and is simpler to implement.
Acknowledgements: We thank Radford Neal for
useful comments.

