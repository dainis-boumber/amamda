Abstract

This paper presents a Support Vector
Method for optimizing multivariate non-
linear performance measures like the F1-
score. Taking a multivariate prediction ap-
proach, we give an algorithm with which such
multivariate SVMs can be trained in poly-
nomial time for large classes of potentially
non-linear performance measures, in partic-
ular ROCArea and all measures that can be
computed from the contingency table. The
conventional classication SVM arises as a
special case of our method.

1. Introduction

Depending on the application, measuring the success
of a learning algorithm requires application specic
performance measures.
In text classication, for ex-
ample, F1-Score and Precision/Recall Breakeven Point
(PRBEP) are used to evaluate classier performance
while error rate is not suitable due to a large imbal-
ance between positive and negative examples. How-
ever, most learning methods optimize error rate, not
the application specic performance measure, which is
likely to produce suboptimal results. How can we learn
rules that optimize measures other than error rate?
Current approaches that address this problem fall into
three categories. Approaches of the rst type aim
to produce accurate estimates of the probabilities of
class membership of each example (e.g. (Platt, 2000;
Langford & Zadrozny, 2005)). While based on these
probabilities many performance measures can be (ap-
proximately) optimized (Lewis, 1995), estimating the
probabilities accurately is a dicult problem and ar-
guably harder than the original problem of optimiz-
ing the particular performance measure. A second
class of approaches circumvents this problem by op-

Appearing in Proceedings of the 22 nd International Confer-
ence on Machine Learning, Bonn, Germany, 2005. Copy-
right 2005 by the author(s)/owner(s).

timizing many dierent variants of convenient and
tractable performance measures, aiming to nd one
that performs well for the application specic per-
formance measure after post-processing the resulting
model (e.g. (Lewis, 2001; Yang, 2001; Abe et al., 2004;
Caruana & Niculescu-Mizil, 2004)). However, in par-
ticular for non-linear performance measures like F1-
score or PRBEP, the relationship to tractable mea-
sures is at best approximate and requires extensive
search via cross-validation. The nal category of ap-
proaches aims to directly optimize the application spe-
cic performance measure. Such methods exist for
some linear measures. In particular, most learning al-
gorithms can be extended to incorporate unbalanced
misclassication costs via linear loss functions (e.g.
(Morik et al., 1999; Lin et al., 2002) in the context of
SVMs). Also, methods for optimizing ROCArea have
been proposed in the area of decision trees (Ferri et al.,
2002), neural networks (Yan et al., 2003; Herschtal &
Raskutti, 2004), boosting (Cortes & Mohri, 2003; Fre-
und et al., 1998), and SVMs (Herbrich et al., 2000;
Rakotomamonjy, 2004). However, for non-linear per-
formance measures like F1-score, the few previous at-
tempts towards their direct optimization noted their
computational diculty (Musicant et al., 2003).
In this paper, we present a Support Vector Method
that can directly optimize a large class of performance
measures like F1-score, Precision/Recall Breakeven
Point (PRBEP), Precision at k (Prec@k), and ROC-
Area. One diculty common to most application spe-
cic performance measures is their non-linear and mul-
tivariate nature. This results in decision theoretic risks
that no longer decompose into expectations over indi-
vidual examples. To accommodate this problem, we
propose an approach that is fundamentally dierent
from most conventional learning algorithms:
instead
of learning a univariate rule that predicts the label
of a single example, we formulate the learning prob-
lem as a multivariate prediction of all examples in the
dataset. Based on the sparse approximation algorithm
for structural SVMs (Tsochantaridis et al., 2004), we
propose a method with which the training problem
can be solved in polynomial time. We show that the

A Support Vector Method for Multivariate Performance Measures

method applies to any performance measure that can
be computed from the contingency table, as well as to
the optimization of ROCArea. The new method can
be thought of as a direct generalization of classication
SVMs, and we show that the conventional classica-
tion SVM arises as a special case when using error rate
as the performance measure. We present experiments
that compare our algorithm to a conventional classi-
cation SVMs with linear cost model and observe good
performance without dicult to control heuristics.

2. Multivariate Performance Measures

In this section we rst review the typical assumptions
(often implicitly) made by most existing learning al-
gorithms (Vapnik, 1998). This gives insight into why
they are not suitable for directly optimizing non-linear
performance measures like the F1-Score.
Most learning algorithms assume that the training
data S = ((x1, y1), ..., (xn, yn)) as well as the test data
S0 is independently identically distributed (i.i.d.) ac-
cording to a learning task Pr(X, Y ). The goal is to
nd a rule h  H from the hypothesis space H that
optimizes the expected prediction performance on new
samples S0 of size n0.
 ((h(x0

R(h) =

1), ..., h(x0

n0)) d Pr(S0)

Z

If the loss function  over samples decomposes linearly
into a sum of a loss function  over individual examples
((h(x0

(h(x0

1), ..., h(x0

n0)), (y0

i), y0

i) (1)

n0))=

n0)), (y0
1, ..., y0
n0X

1
n0

i=1

and since the examples are i.i.d., this expression can
be simplied to

R(h) = R(h) =

 (h(x0), y0) d Pr(x0, y0)

i=1

1
n

S(h) =

nX

 (h(xi), yi)

Discriminative learning algorithms approximate this
expected risk R(h) using the empirical risk on the
training data S.
R

(2)
S(h) is an estimate of R(h) for each h  H. Select-
R
ing a rule with low empirical risk R
S(h) (e.g. training
error) in this decomposed form is the strategy followed
by virtually all discriminative learning algorithms.
However, many performance measures (e.g.
F1,
PRBEP) do not decompose linearly like in Eq. (1).
They are a non-linear combination of the individ-
An example is the F1 score
ual classications.
P rec+Rec , where
F1
P rec and Rec are the precision and the recall of h

((h(x1), ..., h(xn)), (y1, ..., yn)) = 2 P rec Rec

1, ..., y0
Z

on the sample (x1, y1), ..., (xn, yn). There is no known
example-based loss function  which can be used to de-
compose . Therefore, learning algorithms restricted
to optimizing an empirical risk of the kind in Eq. (2)
are of questionable validity. What we need instead are
learning algorithms that directly optimize an empirical
risk that is based on the sample loss .

R

S (h) =  ((h(x1), ..., h(xn)), (y1, ..., yn))

Clearly, at least if the size n of the training set and
the size n0 of the test set are equal, R
S (h) is again an
estimate of R(h) for each h  H. Note that R
S (h)
does not necessarily have higher variance than a de-
composed empirical risk R
S(h) just because it does
not average over multiple examples. The key factor
is the variance of  with respect to samples S drawn
from Pr(X, Y ). This variance can be low.
To design learning algorithms that do discriminative
training with respect to R
S (h), we need algorithms
that nd an h  H that minimizes R
S (h) over the
training sample S. Since  is some non-linear function
of S, this can be a challenging computational problem.
We will now present a general approach to this prob-
lem based on Support Vector Machines.

3. SVM Approach to Optimizing

Non-Linear Performance Measures

Support Vector Machines (SVMs) were developed by
Vapnik et al. (Boser et al., 1992; Cortes & Vapnik,
1995; Vapnik, 1998) as a method for learning linear
and, through the use of Kernels, non-linear rules. For
the case of binary classication with unbiased hyper-
planes1, SVMs learn a classier

h(x) = sign(cid:2)wT x(cid:3)
nX

by solving the following optimization problem.
Optimization Problem 1. (Unbiased SVMorg)

min
w,0

s.t.:

1
w  w + C
2
n
i=1 : yi[w  xi]  1  i

i=1

i

(3)

(4)

sponding i is greater than 1. ThereforePn

The i are called slack variables. If a training example
lies on the wrong side of the hyperplane, the corre-
i=1 i is an
upper bound on the number of training errors. This
means that the SVM nds a hyperplane classier that

1Unbiased hyperplanes assume a threshold of 0 in the
classication rule. This is not a substantial restriction,
since a bias can be introduced by adding an articial fea-
ture to each example.

A Support Vector Method for Multivariate Performance Measures

optimizes an approximation of the training error reg-
ularized by the L2 norm of the weight vector. The
factor C in (3) controls the amount of regularization.
To dierentiate between dierent types of SVMs, we
will denote this version as SVMorg.
In the following, we will use the same principles used
in SVMorg to derive a class of SVM algorithms that
optimize a broad range of non-linear performance mea-
sures. The key idea is to treat the learning problem as
a multivariate prediction problem. Instead of dening
our hypotheses h as a function from a single feature
vector x to a single label y  {1, +1},

h : X  Y

we will consider hypotheses h that map a tuple x  X
of n feature vectors x = (x1, ..., xn) to a tuple y  Y
of n labels y = (y1, ..., yn)

h : X  Y,

where X = X  ...  X and Y  {1, +1}n is the
set of all admissible label vectors2. To implement this
multivariate mapping, we will use linear discriminant
functions of the following form.

(cid:8)wT (x, y0)(cid:9)

hw(x) = argmax
y0 Y

(5)

1, ..., y0

Intuitively, the prediction rule hw(x) returns the tu-
ple of labels y0 = (y0
n) which scores highest
according to a linear function. w is a parameter
vector and  is a function that returns a feature
vector describing the match between (x1, ..., xn) and
(y0
1, ..., y0
n). Whether this argmax can be computed ef-
ciently hinges on the structure of . For the purposes
of this paper, we can restrict  to be of the following
simple form:

nX

(x, y0) =

y0
ixi

i=1

For this (x, y) and Y = {1, +1}n, the argmax is
achieved when y0
i is assigned to h(xi). So, in terms
of the resulting classication rule, this is equivalent to
SVMorg. But did we gain anything from the reformu-
lation of the prediction rule?
Thinking about the prediction problem in term of a
multivariate rule h instead of a univariate rule h al-
lows us to formulate the SVM optimization problem
in a way that enables inclusion of a sample-based loss
function  instead of the example-based loss function
in SVMorg. Following (Tsochantaridis et al., 2004), we
formulate the following alternative optimization prob-
lem for non-negative .

2Note that Y can be a strict subset for some measures,
e.g. for Prec@k it is restricted to label vectors with k pos-
itive predictions.

Optimization Problem 2. (Multivar. SVM

)

multi

min
w,0
s.t.

1
kwk2 + C 
2
y0 Y\ y : wT [(x, y)  (x, y0)](y0,y)

Like for the SVMorg, this optimization problem is a
convex quadratic program. In contrast to the SVMorg,
however, there is one constraint for each possible y 
Y. Due to the exponential size of Y, this may seem like
an intractably large problem. However, by adapting
the sparse approximation algorithm of (Tsochantaridis
et al., 2004) implemented in SVMstruct3, we will show
that this problem can be solved in polynomial time for
many types of multivariate loss functions . Unlike in
the SVMorg optimization problem there is only one
slack variable  in this training problem. Similar to

P i in SVMorg, the value of this slack variable is an

upper bound on the training loss.

the

solution w, 
multi optimization problem on the

Theorem 1. At
of
the
training
SVM
data x with labels y, the value of  is an upper bound
on the training loss (hw(x), y).
Proof. Let y0 = hw(x) be the prediction of the
learned multivariate hypothesis on the training data
itself. Following from the denition of h, this is the la-
beling y0 that minimizes wT [(x, y)  (x, y0)], and
this quantity will be less than zero unless y0 = y.
Therefore   (y0, y)  wT [(x, y)  (x, y0)] 
(y0, y).
This shows that the multivariate SVM
multi is similar
to the original SVMorg in the sense that it optimizes
a convex upper bound on the training loss regularized
by the norm of the weight vector. We will later show
that, in fact, both formulations are identical if  is the
number of training errors.
straightforward to extend the multivariate
It
is
SVM
multi to non-linear classication rules via the dual
representation of h. Similar to the univariate SVMorg,
the Wolfe dual of Optimization Problem 2 can be ex-
pressed in terms of inner products between feature vec-
tors, allowing the use of kernels. We omit this exten-
sion for brevity.

4. Ecient Algorithm

How can the optimization problem of the multivariate
SVM
multi be solved despite the huge number of con-
straints? This problem is a special case of the mul-
tivariate prediction formulations in (Tsochantaridis
et al., 2004) as well as in (Taskar et al., 2003). The

3http://svmlight.joachims.org

A Support Vector Method for Multivariate Performance Measures

multi.

y0  argmaxy0 Y(cid:8)(y0, y) + wT (x, y0)(cid:9)

Algorithm 1 Algorithm for solving quadratic pro-
gram of multivariate SVM
1: Input: x = (x1, . . . , xn) y = (y1, . . . , yn), C, , Y
2: C  
3: repeat
4:
5:
6:
7:
8:
9:
10: until C has not changed during iteration
11: return(w)

  max{0, (y0, y)  wT [(x, y)  (x, y0)]}
if (y0, y)wT [(x, y)(x, y0)] > + then

C  C  {y0}
w  optimize SVM

multi objective over C

end if

algorithm proposed in (Taskar et al., 2003) for solving
these types of large quadratic programs is not applica-
ble to non-linear loss functions , since it assumes that
the loss decomposes linearly. The sparse approxima-
tion algorithm of (Tsochantaridis et al., 2004) does not
have this restriction, and we will show in the following
how it can be used to solve Optimization Problem 2 in
polynomial time for a large class of loss functions .
Algorithm 1 is the sparse approximation algorithm
adapted to the multivariate SVM
multi. The algorithm
iteratively constructs a sucient subset of the set of
constraints in Optimization Problem 2. The algorithm
starts with an empty set of constraints C and adds the
currently most violated constraint in each iteration,
i.e. the constraint corresponding to the label that max-

imizes H(y) =(cid:8)(y0, y) + wT (x, y0)(cid:9). The next ap-

proximation to the solution of Optimization Problem 2
is then computed on the new set of constraints. The
algorithm stops when no constraint of Optimization
Problem 2 is violated by more than . It is easy to see
that the solution w returned by Algorithm 1 fullls all
constraints up to precision , and that the norm of w
is no bigger than the norm of the exact solution of Op-
timization Problem 2. Furthermore, Tsochantaridis
et al. (2004) show that the algorithm terminates after
a polynomial number of iterations. We restate the the-
orem adapted to the SVM
multi optimization problem.
Theorem 2. For any  > 0 and a training sample x =
(x1, . . . , xn) and y = (y1, . . . , yn) with R = maxi ||xi||
and L = maxy0 Y (y0, y), Algorithm 1 terminates af-
ter incrementally adding at most

(cid:26)2L

max

8Cn2R2L

2

,



(cid:27)

constraints to the working set C.

The bound is rather lose. In our experiments we ob-
serve that the algorithm often converges after a few

hundred iterations even for large problems.
search for the most violated constraint

(cid:8)(y0, y) + wT (x, y0)(cid:9)

argmax

y0 Y

If the

(7)

can be performed in polynomial time, the overall algo-
rithm has polynomial time complexity. We will show
in the following that solving the argmax eciently is
indeed possible for a large class of multivariate loss
functions . We will rst consider multivariate loss
functions that can be computed from the contingency
table, and then consider the case of ROC Area.

4.1. Loss Functions Based on Contingency

Table

An exhaustive search over all y0  Y is not feasible.
However, the computation of the argmax in Eq. (7)
can be stratied over all dierent contingency tables,

y=1

y=-1

h(x)=1
h(x)=-1

a
c

b
d

so that each subproblem can be computed eciently.
Algorithm 2 is based on the observation that there
are only order O(n2) dierent contingency tables for a
binary classication problem with n examples. There-
fore, any loss function (a, b, c, d) that can be com-
puted from the contingency table can take at most
O(n2) dierent values.
Lemma 1. Algorithm 2 computes the solution of

(cid:8)(a, b, c, d) + wT (x, y0)(cid:9)

(8)

argmax

y0 Y

in polynomial time for any loss function (a, b, c, d)
that can be computed from the contingency table in
polynomial time.
Proof. By iterating over all possible contingency ta-
bles, the algorithm iterates over all possible values l
of (a, b, c, d). For each contingency table (a, b, c, d) it
computes the argmax over all Yabcd, which is the set
of y that correspond to this contingency table.

yabcd = argmax
y0 Yabcd

= argmax
y0 Yabcd

(cid:8)wT (x, y0)(cid:9)
( nX

y0
i(wT xi)

)

i=1

(9)

(10)

(6)

Since the objective function is linear in y0, the solution
can be computed by maximizing y0 element wise. The
maximum value for a particular contingency table is
achieved when the a positive examples with the largest
value of (wT xi) are classied as positive, and the d
negative examples with the lowest value of (wT xi) are

A Support Vector Method for Multivariate Performance Measures

Algorithm 2 Algorithm for computing argmax with
loss functions that can be computed from the contin-
gency table.
1: Input: x = (x1, . . . , xn), y = (y1, . . . , yn), and Y
2: (ip
3: (in
4: for a  [0, . . . , #pos] do
5:
6:

#pos)  sort {i : yi = 1} by wT xi
#neg)  sort {i : yi = 1} by wT xi

1, . . . , ip
1 , . . . , in
c  #pos  a
set y0
, . . . , y0
ip
ip
for d  [0, . . . , #neg] do
1
a

to 1 AND set y0
ip
a+1

, . . . , y0
ip
#pos

to 1

7:
8:
9:

10:
11:
12:
end if
13:
end for
14:
15: end for
16: return(y)

b  #neg  d
set y0
, . . . , y0

v  (a, b, c, d) + wTPn

to1 AND set y0
i=1 y0
if v is the largest so far then

in
b

in
1

in
b+1
ixi

y  (y0

1, ..., y0
n)

, . . . , y0

to1

in
#neg

classied as negative. The overall argmax can be com-
puted by maximizing over the stratied maxima plus
their constant loss.

By slightly rewriting the algorithm, it can be imple-
mented to run in time O(n2). Exploiting that many
loss functions are upper bounded, pruning can further
improve the runtime of the algorithm. We will now
give some examples of how this algorithm applies to
the loss functions we will later use in experiments.

F-Score: The F-Score is a measure typically used
to evaluate binary classiers in natural language appli-
cations like text classication. It is particularly prefer-
able over error rate for highly unbalanced classes. The
F-Score is a weighted harmonic average of Precision
and Recall. It can be computed from the contingency
table as

F(h) =

(1 + 2) a

(1 + 2) a + b + 2c

.

(11)

The most common choice for  is 1. For the corre-
(y0, y) = 100(1  F), Algorithm 2
sponding loss F1
directly applies.

Precision/Recall at k In Web search engines, most
users scan only the rst few links that are presented.
Therefore, a common way to evaluate such systems is
to measure precision only on these (e.g. ten) positive
predictions. Similarly, in an archival retrieval system
not precision, but recall might be the most indicative
measure. For example, what fraction of the total num-

ber of relevant documents did a user nd after scan-
ning the top 100 documents. Following this intuition,
Prec@k and Rec@k measure the precision and recall of
a classier that predicts exactly k documents to be
positive.

Prec@k(h) = a
a + b

Rec@k(h) = a
b + d

(12)

For these measures, the space of possible prediction
vectors Y is restricted to those that predict exactly k
examples to be positive. For this Y, the multivariate
discriminant rule hw(x) in Eq. (5) can be computed
by assigning label 1 to the k examples with highest
wT xi. Similarly, a restriction to this Y can easily be
incorporated into Algorithm 2 by excluding all y0 6= y
from the search for which a + b 6= k.

Precision/Recall Break-Even Point The Preci-
sion/Recall Break-Even Point (PRBEP) is a perfor-
mance measure that is often used to evaluate text
classiers. It requires that the classier makes a pre-
diction y so that precision and recall are equal, and
the value of the PRBEP is dened to be equal to
both. As is obvious from the denition of precision
and recall, this equality is achieved for contingency
tables with a + b = a + c and we restrict Y appro-
priately. Again, we dene the corresponding loss as
P RBEP (y0, y) = 100(1 P RBEP ) and it is straight-
forward to compute hw(x) and modify Algorithm 2 for
this Y.

4.2. ROC Area

ROCArea is a performance measure that cannot be
computed from the contingency table, but requires
predicting a ranking. However, both SVMorg and
SVM
multi naturally predict a ranking by ordering all
examples according to wT xi. From such a rank-
ing, ROCArea can be computed from the number of
swapped pairs
SwappedP airs = |{(i,j) : (yi> yj) and (wTxi<wTxj)}|,

i.e. the number of pairs of examples that are ranked
in the wrong order.

ROCArea = 1  SwappedP airs
#pos  #neg

(13)

We can adapt the SVM
multi to optimizing ROC-
Area by (implicitly) considering a classication prob-
lem of all #pos#neg pairs (i, j) of a positive example
(xi, 1) and a negative example (xj,1), forming a new
classication problem X and Y = {1, 1}#pos#neg as
follows. Each pos/neg pair (i, j) receives the target

A Support Vector Method for Multivariate Performance Measures

Algorithm 3 Algorithm for computing argmax with
ROCArea-loss.
1: Input: x = (x1, . . . , xn), y = (y1, . . . , yn)
2: for i  {i : yi = 1} do si  0.25 + wT xi
3: for i  {i : yi = 1} do si  0.25 + wT xi
4: (r1, . . . , rn)  sort {1, . . . , n} by si
5: sp = #pos, sn = 0
6: for i  {1, . . . , n} do
7:
8:
9:
10:
11:
12:
end if
13:
14: end for
15: return(c1, . . . , cn)

if yri > 0 then
cri  (#neg  2 sn)
sp  sp  1
cri  (#pos + 2 sp)
sn  sn + 1

else

0)(cid:9) corre-

(cid:8)wT (x, y

label yij = 1 and is described by the feature vector
xij = xi  xj.
In this representation, the discrim-
inant rule hw(x) = argmaxy0 Y
sponds to labeling a pair (i, j) as sign(wT xi  wT xj),
i.e. according to the ordering w.r.t wT xi as desired.
Note that the error between the prediction y0 and the
true pairwise labels y = (1, ..., 1)T is proportional to
1  ROCArea of the original data x and y. We call
this quantity the ROCArea-loss.
(1y0

0
ROCArea(y

ij) = SwappedP airs

nX

nX

, y) =

1
2

i=1

j=1

Actually representing all #pos  #neg pairs would be
rather inecient, but can be avoided using the fol-
lowing representation which is linear in the number of
examples n.

i=1

(x, y)=

cixi with ci =

j=1 yij,
j=1 yji,

0
Note that ROCArea(y
0
ROCArea(y
computes the argmax in this representation.
Lemma 2. For x and y of size n, Algorithm 3 com-
putes the solution c1, . . . , cn corresponding to

if(yi =1)
if(yi =1)
Pn
, y) can now be computed as
i=1 yi(ci  c0
i). Algorithm 3
(cid:8)ROCArea(y

, y) + wT (x, y

, y) = 1
2

0)(cid:9)

(14)

0

argmax

y0 Y

( P#neg
P#pos

nX

in time O(n log n).

Proof. The argmax can be written as follows in the
pairwise representation.

 = argmax
y
y0 Y

(1  y0

ij) + y0

ijwT (xi  xj)

1
2

#posX

#negX

i=1

j=1

Since the loss function decomposes linearly over the
pairwise representation, we can maximize each yij in-
dividually.
y
ij =

(1  y0

1
ij) + y0
2
yij[(wT xi  1
4

ijwT (xi  xj)
1
4

)  (wT xj +

)]

argmax
ij{1,+1}
y0

=

argmax
ij{1,+1}
y0

This means that a pair (i, j) should be labeled as
yij = 1, if the score wT xi of the positive example
4 is larger than the score wT xj of the
decremented by 1
negative example incremented by 1
4. This is precisely
how the algorithm assigns the labels and collects them
in the compressed representation. The runtime of the
algorithm is dominated by a single sort operation.

5. SVM

multi Generalizes SVMorg

The following theorem shows that the multivariate
SVM
multi is a direct generalization of the conventional
classication SVM. When using error rate as the loss
function, the conventional SVM arises as a special case
of SVM
Theorem 3. Using error as the loss function, in par-
ticular Err(y0, y) = 2 (b + c), SVMErr
multi with regu-
larization parameter Cmulti computes the same hyper-
plane w as SVMorg with Corg = 2 Cmulti.

multi.

Proof. We will show that both optimization problems
have the same objective value and an equivalent set
of constraints. In particular, for every w the smallest

i i are related as  = 2P

feasible  andP

i i.

For a given w, the i in SVMorg can be optimized
individually, and the optimum is achieved for i =
max{0, 1 yi(wT xi)}. For the SVMErr
multi, the optimal
 for a given w is

nX

iwT xi  nX

y0

i=1

i=1

)

yiwT xi

 = max
y0 Y

Err(y0, y) +

(

Since the function is linear in the y0
i, each y0
i can be
optimized independently. Denote with Err(y0
i, yi) the
univariate loss function that returns 2 if both argu-
ments dier, and 0 otherwise.

nX
nX

i=1

max

(cid:8)Err(y0
max(cid:8)0, 2  2yiwT xi

i{1,+1}
y0

 =

=

iwT xi  yiwT xi
i, yi) + y0
nX

(cid:9) = 2

i

(cid:9)

i=1

i=1

Therefore, if Corg = 2 Cmulti, the objective functions
of both optimization problems are equal for any w,
and consequently so are their optima w.r.t. w.

A Support Vector Method for Multivariate Performance Measures

Table 1. Comparing an SVM optimized for the performance measure to one that is trained with linear cost model.

PRBEP

Rec@2p

Dataset
Reuters (90 classes)

Examples: 9603/3299
Features: 27658
ArXiv (14 classes)

Examples: 1168/32487
Features: 13525

Optdigits (10 classes)
Examples: 3823/1797
Features: 64

Covertype (7 classes)
Examples: 1000/2000
Features: 54

ROCArea

68.2
65.7

58.4
57.9

F1
62.0
56.1

56.8
49.6

Method
SVM
SVMorg
improvement +5.9 (51/20)** +2.5 (16/8)** +1.1 (14/8) +0.5 (43/33)*
SVM
SVMorg
improvement
SVM
SVMorg
improvement
SVM
SVMorg
improvement

-1.1 (1/13)**

+7.2 (9/5)*

78.3
77.2

73.3
74.4

+1.0 (8/2)*

99.1
98.6

92.8
92.7

99.4
99.4

92.5
91.5

73.8
73.9

92.7
91.5

72.1
71.0

98.4
98.7

93.1
94.7

+1.2 (5/1)*

-0.3 (1/5)

+0.1 (8/6)

+0.5 (9/4)

-0.1 (3/4)

+1.1 (5/2)

-1.6 (2/5)

+0.5 (4/3)

0.0 (6/4)

multi

multi

multi

multi

94.6
94.1

6. Experiments

To evaluate the proposed SVM approach to optimizing
non-linear performance measures, we conducted exper-
iments on four dierent test collection. We compare
F1-score, PRBEP, Rec@k for k twice the number of
positive examples (Rec@2p), and ROCArea achieved
multi with the performance of
by the respective SVM
a classication SVM that includes a cost model. The
cost model is implemented by allowing dierent reg-
ularization constants for positive and negative exam-
ples (Morik et al., 1999). Using the parameter j of
SVMlight, the C parameter of positive examples is
multiplied by j to increase their inuence. This setup
is a strong baseline to compare against. For exam-
ple, David Lewis won the TREC-2001 Batch Filtering
Evaluation (Lewis, 2001) using SVMlight with such
cost models. Furthermore, Musicant et al.
(2003)
make a theoretical argument that such cost models
approximately optimize F1-score.
We compare performance on four test collections,
namely the ModApte Reuters-21578 text classication
benchmark4, a dataset of abstracts from the Physics
E-Print ArXiv, and the OPTDIGITS and COVER-
TYPE benchmarks 5. Train/test split and the number
of features are given in Table 1.
Initial experiments indicated that biased hyperplane
(i.e. adjustable threshold) outperform unbiased hy-
perplanes. We therefore add a constant feature with
value 1 to each training example for the SVM
multi and
use biased hyperplanes for the regular SVM as imple-
mented in SVMlight. To select the regularization para-
meter C for the SVM
multi, and C and j for the classi-
cation SVM, we used holdout testing with a random 2
3
/ 1
3 split of the training set for each class in a collection.
4http://www.daviddlewis.com/
5http://www.ics.uci.edu/mlearn/MLRepository.html

multi

is available at

We search within C  [26, ..., 26] and j  [20, ..., 27],
but extended the search space if the most frequently
selected parameter setting over all classes in the col-
lection was on a boundary.
Our implementation of SVM
http://svmlight.joachims.org.
Table 1 shows the macro-average of the performance
over all classes in a collection. Each improvement
line shows the amount by which the SVM
multi out-
performs (or underperforms) the regular SVM. Both
the dierence in performance, as well as the number
of classes on which the SVM
multi won/lost are shown.
Stars indicate the level of signicance according to a
two-tailed Wilcoxon test applied to pairs of results over
classes. One star indicates a signicance level of 0.9,
two stars a level of 0.95. Overall, 11 macroaverages
in Table 1 show an improvement (6 signicant), and
only 4 cases (1 signicant) show a decline in perfor-
mance. Comparing the results between datasets, the
improvements are largest for the two text classication
tasks, while especially for COVERTYPE there is no
signicant dierence between the two methods. With
respect to dierent performance measures, the largest
gains are observed for F1-score on the text classica-
tion tasks. PRBEP and ROCArea also show consis-
tent, but smaller gains. On Rec@2p, the regular SVM
appears to perform better on average.
Figure 1 further analyzes how the performance diers
between the individual binary tasks in the Reuters col-
lection. The 90 tasks were binned into 5 sets by their
ratio of positive to negative examples. Figure 1 plots
the average performance improvement in each bin from
the most popular classes on the left to the least popu-
lar classes on the right. For most measures, especially
F1-score, improvements are larger for the less popular
categories.

A Support Vector Method for Multivariate Performance Measures

Freund, Y., Iyer, R., Schapire, R., & Singer, Y. (1998).
An ecient boosting algorithm for combining pref-
erences. Proc. ICML.

Herbrich, R., Graepel, T., & Obermayer, K. (2000).
Large margin rank boundaries for ordinal regression.
In et A. S. al. (Ed.), Advances in large margin clas-
siers. MIT Press.

Herschtal, A., & Raskutti, B. (2004). Optimising area
under the roc curve using gradient descent. Proc.
ICML.

Langford, J., & Zadrozny, B. (2005). Estimating class
membership probabilities using classier learners.
Proc. AISTATS.

Lewis, D. (1995). Evaluating and optimizing au-
tonomous text classication systems. Proc. SIGIR.
Lewis, D. (2001). Applying support vector machines
to the trec-2001 batch ltering and routing tasks.
Proc. TREC.

Lin, Y., Lee, Y., & Wahba, G. (2002). Support vec-
tor machines for classication in nonstandard situ-
ations. Machine Learning, 46, 191  202.

Morik, K., Brockhausen, P., & Joachims, T. (1999).
Combining statistical learning with a knowledge-
based approach. Proc. ICML.

Musicant, D., Kumar, V., & Ozgur, A. (2003). Op-
timizing f-measure with support vector machines.
Proc. FLAIRS.

Platt, J. (2000). Probabilistic outputs for support vec-
tor machines and comparisons to regularized likeli-
hood methods.
In et A. S. al. (Ed.), Advances in
large margin classiers. MIT Press.

Rakotomamonjy, A. (2004). Svms and area under roc

curve (Technical Report). PSI-INSA de Rouen.

Taskar, B., Guestrin, C., & Koller, D. (2003).

Maximum-margin markov networks. Proc. NIPS.

Tsochantaridis, I., Hofmann, T., Joachims, T., & Al-
tun, Y. (2004). Support vector machine learning for
interdependent and structured output spaces. Proc.
ICML.

Vapnik, V. (1998). Statistical learning theory. Wiley.
Yan, L., Dodier, R., Mozer, M., & Wolniewicz, R.
(2003). Optimizing classier performance via ap-
proximation to the wilcoxon-mann-witney statistic.
Proc. ICML.

Yang, Y. (2001). A study of thresholding strategies for

text categorization. Proc. SIGIR.

in prediction performance on
Figure 1. Improvement
Reuters of SVM
multi over SVMorg depending on the bal-
ance between positive and negative examples. Results are
averaged by binning the 90 categories according to their
number of examples.

7. Conclusions
This paper generalized SVMs to optimizing large
classes of multivariate non-linear performance mea-
sures often encountered in practical applications. We
presented a training algorithm and showed that is it
computationally tractable. The new approach leads
to improved performance particularly for text classi-
cation problems with highly unbalanced classes. Fur-
thermore, it provides a principled approach to opti-
mizing such measures and avoids dicult to control
heuristics.
This work was funded in part under NSF awards IIS-
0412894 and IIS-0412930.

