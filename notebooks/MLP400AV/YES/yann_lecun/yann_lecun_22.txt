Abstract

We present a method for training a similarity metric from
data. The method can be used for recognition or verication
applications where the number of categories is very large
and not known during training, and where the number of
training samples for a single category is very small. The
idea is to learn a function that maps input patterns into a
target space such that the
norm in the target space ap-
proximates the semantic distance in the input space. The
method is applied to a face verication task. The learning
process minimizes a discriminative loss function that drives
the similarity metric to be small for pairs of faces from the
same person, and large for pairs from different persons. The
mapping from raw to the target space is a convolutional net-
work whose architecture is designed for robustness to geo-
metric distortions. The system is tested on the Purdue/AR
face database which has a very high degree of variability in
the pose, lighting, expression, position, and articial occlu-
sions such as dark glasses and obscuring scarves.



1. Introduction

Traditional approaches to classication using discrimi-
native methods, such as neural networks or support vec-
tor machines, generally require that all the categories be
known in advance. They also require that training exam-
ples be available for all the categories. Furthermore, these
methods are intrinsically limited to a fairly small number
of categories (on the order of 100). Those methods are un-
suitable for applications where the number of categories is
very large, where the number of samples per category is
small, and where only a subset of the categories is known at
the time of training. Such applications include face recog-
nition and face verication: the number of categories can
be in the hundreds or thousands, with only a few examples

per category. A common approach to this kind of problem
is distance-based methods, which consist in computing a
similarity metric between the pattern to be classied or ver-
ied and a library of stored prototypes. Another common
approach is to use non-discriminative (generative) proba-
bilistic methods in a reduced-dimension space, where the
model for one category can be trained without using exam-
ples from other categories. To apply discriminative learn-
ing techniques to this kind of application, we must devise
a method that can extract information about the problem
from the available data, without requiring specic informa-
tion about the categories.

The solution presented in this paper is to learn a similar-
ity metric from data. This similarity metric can later be used
to compare or match new samples from previously-unseen
categories (e.g. faces from people not seen during training).
We present a new type of discriminative training method
that is used to train the similarity metric. The method can
be applied to classication problems where the number of
categories is very large and/or where examples from all cat-
egories are not available at the time of training.

parameterized by

The main idea is to nd a function that maps input pat-
terns into a target space such that a simple distance in the
target space (say the Euclidean distance) approximates the
semantic distance in the input space. More precisely,
given a family of functions
,
such that the
we seek to nd a value of the parameter
similarity metric
	

	
!
is small if
belong to the same category, and large
and
if they belong to different categories. The system is trained
on pairs of patterns taken from a training set. The loss func-
tion minimized by training minimizes
when

&
are from the same category, and maximizes
and

"
when they belong to different categories. No
	


&(
'
assumption is made about the nature of
other than
differentiability with respect to
. Because the same func-
tion
with the same parameter
is used to process both

	





#$


%


$







"
















inputs, the similarity metric is symmetric. This is called a
siamese architecture [4].

To build a face verication system with this method,
we rst train the model to produce output vectors that are
nearby for pairs of images from the same person, and far
away for pairs of images from different persons. The model
can then be used as a similarity metric between face images
of new persons that were not seen during training.

An important aspect of the proposed method is that we
. In partic-
have complete freedom in the choice of
ular, we will use architectures which are designed to extract
representations that are robust to geometric distortions of
the input, such as convolutional networks [8]. The resulting
similarity metric will be robust to small differences of the
pose between the pairs of images.

	



Since the dimension of the target space is low and the
natural distance in that space is invariant to irrelevant dis-
tortions of the input, we can easily estimate probabilistic
models of each new category from a very small number of
samples.

1.1. Previous Work

The idea of mapping face images to low dimensional tar-
get spaces before comparison has a long history, starting
with the PCA-based Eigenface method [16] in which
&


is a linear projection trained non-discriminatively to maxi-
mize the variance. The LDA-based Fisherface method [3]
is also linear, but trained discriminatively so as to maxi-
mize the ratio of inter-class and intra-class variances. Non-
linear extensions based on Kernel-PCA and Kernel-LDA
have been discussed [5]. See [14] for a review of subspace
methods for face recognition. One major shortcoming of
all those approaches is that they are very sensitive to geo-
metric transformations of the input images (shift, scaling,
rotation) and to other variabilities (changes in facial expres-
sion, glasses, and obscuring scarves). Some authors have
described similarity metrics that are locally invariant to a
set of known transformations. One example is the Tangent
Distance method [19]. Another example, which has been
applied to face recognition, is elastic matching [6]. Oth-
ers have advocated warping-based normalization algorithms
to maximally reduce the variations of appearance due to
pose [10]. The invariance properties of all these models
are hand-designed in advance. In the method described in
this paper, the invariance properties do not come from prior
knowledge about the task, but they are learned from data.
When used with a convolutional network as the mapping
function, the proposed method can learn a wide range of
invariances present in the data.

Our approach is somewhat similar to that of [4], which
uses a siamese architecture for signature verication. The
main difference between their method and ours is the na-
ture of the loss function minimized by the training process.

Our loss function is derived from the discriminative learn-
ing framework for energy-based models (EBM).

Our method is very different from other dimensional-
ity reduction techniques such as Multi-Dimensional Scal-
ing (MDS) [13] and Local Linear Embedding (LLE) [15]
MDS computes a target vector from each input object in the
training set based on known pairwise dissimilarities, with-
out constructing a mapping. By contrast, our method pro-
duces a non-linear mapping that can map any input vector
to its corresponding low-dimensional version.

2. The General Framework

While probabilistic models assign a normalized proba-
bility to every possible conguration of the variables be-
ing modeled, energy-based models (EBM) assign an un-
normalized energy to those congurations [18, 9]. Predic-
tion in such systems is performed by searching for cong-
urations of the variables that minimize the energy. EBMs
are used in situations where the energies for various con-
gurations must be compared in order to make a decision
(classication, verication, etc). A trainable similarity met-
to
ric can be seen as associating an energy
pairs of input patterns. In the simplest face verication set-
ting, we simply set
to all the available images of the
claimed identity and compare the minimum
to a pre-determined threshold.

#






&




"

The advantage of EBMs over traditional probabilistic
models, particularly generative models, is that there is no
need for estimating normalized probability distributions
over the input space. The absence of normalization saves us
from computing partition functions that may be intractable.
It also gives us considerably more freedom in the choice of
architectures for the model [9].

'


&(

Learning is performed by nding the

that minimizes
a suitably designed loss function, evaluated over a training
set. At rst glance, we might think that simply minimizing
averaged over a set of pairs of inputs from
	

the same category would be sufcient. But this generally
leads to a catastrophic collapse: The energy and the loss can
be made zero by simply making
a constant func-
tion. Therefore our loss function needs a contrastive term
to ensure not only that the energy for a pair of inputs from
the same category is low, but also that the energy for a pair
from different categories is large. This problem does not oc-
cur with properly normalized probabilistic models because
making the probability of a particular pair high automati-
cally makes the probability of other pairs low.


"!

2.1. Face Verication with Learned Similarity Met-

rics

The task of face verication [12], is to accept or reject
the claimed identity of a subject in an image. Performance











is assessed using two measures: percentage of false accepts
and the percentage of false rejects. A good system should
minimize both measures simultaneously.

Our approach is to build a trainable system that non-
linearly maps the raw images of faces to points in a low di-
mensional space so that the distance between these points is
small if the images belong to the same person and large oth-
erwise. Learning the similarity metric is realized by train-
ing a network that consists of two identical convolutional
networks that share the same set of weights - a Siamese Ar-
chitecture [4] (see gure 1).

2.2. The energy function of the EBM

The architecture of our learning machine is given in g-
are given

ure 1. The details of the architecture of
in section 3.2.

	
$

Convolutional

Convolutional

	



#$!


"	











W

%






	
!


Figure 1. Siamese Architecture.

Let

and

and


"
the images

ing machine. Let&
uine pair) and&


"

be a pair of images shown to our learn-
if
belong to the same person (a gen-

be a binary label of the pair,&
('
*) otherwise (an impostor pair). Let

and


"(

be the shared parameter vector that is subject to learn-
be the two points in the

ing, and let
low-dimensional space that are generated by mapping
and
function
tween

"

. Then our system can be viewed as a scalar energy
that measures the compatibility be-


"
. It is dened as


"



Given a genuine pair from the training set

	
, and


an impostor pair from the training set
, the ma-
chine behaves in a desirable manner if the following condi-
tion holds:

(




(1)

!










,

Condition 1 -.

,+


"

,

/0' , such that










,+

21(.

To simplify notations

The positive number.
87

as




can be interpreted as a margin.

is written as

and

for the remainder of the paper.


"

54

2.3. Contrastive Loss Function used for Training

We assume that the loss function depends on the input
and the parameters only indirectly through the energy. Our
loss function is of the form:

<CB

$&
4A@

<CB




"






&

&

and


"


"


&

the par-
the number of

tial loss function for an impostor pair, andG


where
of a pair of images and a label (genuine or impostor),
is the partial loss function for a genuine pair,

>)?&
1D&
7E@
is theF -th sample, which is composed
7 should be designed in such a
4 monotonically in-
7 monotonically decreasing. However, there

,+

training samples.
way that the minimization of
will decrease the energy of
genuine pairs and increase the energy of impostor pairs. A
simple way to achieve that is to make
creasing, and
is a more general set of conditions under which minimizing
will make the machine approach condition 1. Our argu-
ments are similar to those given by LeCun et al in [9]. We
will consider a training set composed of one genuine pair

"
with energy

and one impostor pair

. Let us dene:

with energy

54






I1

 

(2)

.

and

87

J4

the half plane

for all values of

as the total loss function for the two pairs. We will assume
is convex in its two arguments (note: we do not as-
). We also assume that
sume convexity with respect to
there exists a
for single training sample such that condi-
tion 1 is satised. The following conditions must hold for

thatH
the loss functionH
Condition 2 The minima ofH
87
1K.L3
84
This condition clearly guarantees that when we minimizeH
ForH whose minima lie at innity (see gure 2), the
Condition 3 The negative of the gradient ofH
87

with respect to
the solution satises condition 1.

on the margin line
uct with the direction [-1, 1].

, the machine is driven to a region where

following condition is sufcient:

has a positive dot prod-

should be inside

 J4

 
.

54

1M.

87

To prove this, we state and prove the following theorem.

57

 






















































3



















6



9




:
;
<
=









<









<





















<

4

7

4
















H
4



7


4


4


7
7






4



7












and

and

and

and

over

87

54

57

J4

 54

be convex in

in its domain. Let

1K.
J4

would lead to nding a

that satises condition 1.

and have a minimum at innity. Assume that there exists
a
for a sample point such that condition 1 is satised.

Theorem 1 LetH
87
If condition 3 holds, then minimizingH with respect to
84
be denoted byH
1A.
andH

Proof. Consider the positive quadrant of the plane formed
(see gure 3). Let the two half planes
by
and

57
respectively. We minimizeH
57

intersects the half planeH

be the region
for all the values of
which correspond
inside the plane formed by
. In the most general
to all the values in the domain of
could be non-convex and could lie anywhere in
setting
the plane. However by our assumption that there exists at
such that condition 1 is satised, we can con-
least one
clude that a part of
. In order
to prove the theorem in the light of condition 3, we need to
show that there exists at least one point in the intersection
of
at this point is less than
the loss at all the points in the intersection of

andH
for whichH
4 be the point on the margin line

Since the negative of the gradient ofH
planeH
54





(condition 3), by convexity ofH we can con-
1A.
1K.

87
, and inside the half planeH
1


at all the points on
the margin line is in the direction which is inside the half

Using a rst-order Taylor expansion, we can write the above
as:

, such that the lossH

Now consider a point at a distance

andH
1,.

away from
. That is the

is minimum. That is,

 

clude that



54

87

when

point



.

,

Let

(3)

 

(4)

(5)



1

1 !
1%!

(6)
By condition 3, the second term on the right hand side of
equation 6 is negative. Thus for sufciently small

 $

,

Thus there exists a point in the intersection of the region

at which the loss function is less


and the half planeH

1



 

(7)

 

1A.

.


1

1"
1A.

andH

. Hence

than at any point in the intersection of
the claim follows.

is






"

is a monotonically increasing function, and

ever
a monotonically decreasing function.

Note that condition 3 clearly holds for any H when-
('

The exact loss function that we use for a single sample is



where

"
ture, the components of

)
)
bounded. The constant+
57

In our architec-
is also
.
One can clearly see that the above loss function is mono-
and monotonically decreasing
tonically increasing in
.
in
Hence by the above arguments we conclude that minimiz-
where
ing this loss function would lead the machine to a
it would behave in the desired manner.

, and it is convex with respect to both

232
46587(9)

+ ,.-/10

is set to the upper bound of

:9!

are bounded, hence

1
;9

J4

54

87

*)

 
 

and

&

(8)

 




.

s
s
o
L

14

12

10

8

6

4

2

0
3

2.5

2

1.5

1

0.5

1

0.5

I
EW

0

0

Figure 2. Graph of the loss function
3D.

against

3

2.5

2

1.5

G
EW

and

=?>

in

=BA

We make two further remarks concerning our loss func-
tions. First, the constants in the loss function are explained.
The optimization algorithm that we use to minimize our loss
function is based on the gradient. These constants are cho-
sen so as to make sure that the direction of the negative of
the gradient of the loss function on the margin line always
point inside the region
. This is required to avoid the situa-
tion where our algorithm is stuck at a point on the boundary
of the
. In such a
case a gradient based algorithm may identify that point as a
local minimum of the loss function and terminate.

with the gradient pointing outside

Second, we must emphasize that using the square norm

instead of the
priate. Indeed, if the energy were the square norm of the dif-
ference between the output vectors of the two patterns, the

E) norm for the energy would not be appro-













4

3

7


4



7

G

G











G


G


G






4
H


4



4

1
.
G

H

4



4
1
.
H


4



7



/


4

4

G

H

4



4
1
.
H



4



4


H



4



4
1
.


H


4


H


7




H



4



4
1
.

#

H


4


H


7
#

)
)
$


H



4



4
H

4



4
1
.


G


G

&


&






&


4

&

7


&
+



1

)



















<
@
@



of 40 subjects, with variations in lighting, facial expression,
accessories, and head position. Each image is 112x92 pix-
els, gray scale, and closely cropped to include the face only.
See gure 4.

and the

<

<

Figure 3. Plot showing the two half planes
feasible region.

and

gradient of the energy with respect to the parameter would
vanish as the energy approached zero. This would create
a dangerous plateau in the loss function. This could lead
to failure of the machine to learn in cases where the two
images are impostors and the corresponding energy is near
zero.

2.4. Convolutional Networks

In order to map the raw images to points in a low dimen-
sional space and hence to realize a learned similarity met-
ric, we use two identical convolutional networks [8] with a
common parameter vector (see gure 1). Convolutional net-
works are trainable, multi-layer, non-linear systems that can
operate at the pixel level and learn low-level features and
high-level representations in an integrated manner. Convo-
lutional nets are trained end-to-end to map pixel images to
outputs. Their main advantage is that they can learn optimal
shift-invariant local feature detectors and build representa-
tions that are robust to geometric distortions of the input
image. The exact specications of the network we use are
given in section 3.2.

3. Experiments

The model and architecture described in the previous
section was trained on 3 databases of face images, and
tested on 2 of those databases. We will discuss the databases
in detail and then explain the training protocol and architec-
ture.

3.1. Datasets and Data Processing

The rst round of training and testing was done with
a relatively small dataset of 400 images from the AT&T
Database of Faces [1]. The dataset contains 10 images each

Figure 4. Top: Images from AT&T dataset. Middle: Images from
the AR dataset. Bottom:
Images from FERET dataset. Each
graphic shows a genuine pair, an impostor pair and images from a
typical subject.

There was no need to pre-process the images for size or
lighting normalization, since one of the stated goals was to
train an architecture that would be resilient to such varia-
tions. However, we did reduce the resolution of the images
to 56x46 using 4x4 subsampling.

The second set of training and testing experiments was
performed by combining two datasets: the AR Database of
Faces, created at Purdue University and publicly available
[11], and a subset of the grayscale Feret Database [2]. Im-
age pairs from both of these datasets were used in training,
but only images from the AR dataset were used for testing.
The AR dataset comprises 3,536 images of 136 subjects
with 26 images per subject. Each 26-image set for a sub-
ject is made up of 2 sets of 13 images taken 14 days apart.
Within each set of 13 images, there are 4 images with ex-

pression variations, 3 images with lighting variations, 3 im-
ages with dark sunglasses and lighting variations, and 3
images with face-obscuring scarves and lighting variations.
This dataset is extremely challenging because of the wide
variation of appearance between images of a single sub-
ject. Examples can be seen in gure 4. Since the faces
were not well centered in the images, a simple correlation-
based centering algorithm was applied. The images were
then cropped and reduced to 56x46 pixels. Although the
centering was sufcient for the purposes of cropping, there
remained substantial variations in head position in many im-
ages.

The Feret Database, distributed by the National Institute
of Standards and Technology, comprises 14,051 images col-
lected from 1,209 subjects. We used a subset of the full
database solely for training. Our subset consists of 1122
images, that is, 6 images each of 187 subjects. The only
preprocessing was cropping and subsampling to 56x46 pix-
els.

Partitioning For the purpose of generating a test set con-
sisting of images of the subjects that are not seen by the
machine during training, we split the datasets into two dis-
joint sets, namely SET1 and SET2. Each image in each of
these sets was paired up with every other image in that set
to generate the maximum number of genuine pairs and im-
postor pairs.

For the AT&T data, SET1 consisted of 350 images of
rst 35 subjects and SET2 consisted of 50 images of last
5 subjects. This way a total of 3500 genuine and 119000
impostor pairs were generated from SET1 and 500 genuine
and 2000 impostor pairs were generated from SET2. Train-
ing was done using only the image pairs generated from
SET1. Testing (verication) was done using the image pairs
from SET2 and the unused image pairs from SET1.

For the AR/Feret data, SET1 contained all the Feret im-
ages and 2,496 images from 96 subjects in the AR database.
SET2 contained the 1,040 images from the remaining 40
subjects in the AR database. Taking all combinations of 2
images resulted in 71,628 genuine and 11,096,376 impos-
tor pairs. The actual training set that was used contained
140,000 image pairs that were evenly split between genuine
and impostor. The testing set was drawn from the 1,081,600
pairs in SET2. Thus, only subjects that had not been seen
in training were used for testing.

3.2. Training Protocol and Architecture

Siamese Architecture The Siamese framework com-
prises two identical networks and one cost module. The
input to the system is a pair of images and a label. The
images are passed through the sub-networks, yielding two
outputs which are passed to the cost module which pro-
duces the scalar energy as discussed in section 2.3. The loss

function combines the label with energy. The gradient of
the loss function with respect to the parameter vector con-
trolling both subnets is computed using back-propagation.
The parameter vector is updated with a stochastic gradient
method using the sum of the gradients contributed by the
two subnets.

The rst set of experiments, using the small AT&T
dataset, explored 6 different sub-net architectures: one 2-
layer fully-connected neural network and ve convolutional
networks that varied in number and size of layers and con-
volution kernel size. Based on those experiments, the sec-
ond set of experiments focused on a single convolutional
network architecture. We only describe the best-performing
denotes a con-
architecture in the following sections.
volutional layer,
denotes a fully connected layer, where
The basic architecture is



is the layer index.
	
	


Trainable parameters: 750; Connections: 1500000.
Fully Connected with the input.

. Feature maps: 15; Size 50x40; Kernel size: 7x7.

denotes a sub-sampling layer, and



,

. Feature maps: 15; Size: 25x20; Field of view:

2x2. Trainable parameters: 30; Connections: 37500.

. Feature maps: 45; Size: 20x15; Kernel size: 6x6.

Trainable parameters: 7128 ; Connections: 2139600.
Partially connected to
. The exact connections are
in a pattern similar to that used in [8]. The motivation
behind this was to break symmetry, thereby pushing
the feature maps to extract and learn different features.

. Feature maps: 45; Size: 5x5; Field of view: 4x3.



Trainable parameters: 100; Connections: 16250.

. Feature maps: 250; Size 1x1; Kernel size: 5x5.


Trainable connections: 312750.
Fully connected to

.




. Number of units: 50. Trainable parameters:


12550; Connections: 12550.

Training Protocol Training requires two sets of data: the
training set, for actually learning the weights of the system,
and the validation set, for testing the performance of the
system during training. Periodical performance evaluation
with the validation set allows us to control over-tting.

Training the network was done with pairs of images
taken from SET1. One half of the image pairs were genuine
and one half were impostor, produced by randomly pairing
images of different subjects. The validation set was com-
posed of 1500 image pairs, taken from the unused pairs of
SET1, and in the same 50% genuine, 50% impostor ratio as
the training set.

The performance of the network was measured by a cal-
culation of the percentage of impostor pairs accepted (FA),





















Number of Subjects

Images/Subject
Images/Model

No. Genuine Images
No. Impostor Images

AT&T

Val
35
10

500
500

Test

5
10
5
500
4500

AR/Purdue
Test
Val
40
96
26
26

13
500
750
750
4500

AT&T (Test)

AT&T (Validation)

AR (Test)

AR (Validation)

False Accept

10% 7.5% 5%
1.00
0.00
0.25
0.00
11
19
0.80
0.53

1.00
0.00
14.6
0.53

Table 1. Above: Details of the validation and test sets for the two
datasets. Below: False reject percentage for different false accept
percentages.

Figure 5. Internal state of the convolutional network for a particu-
lar example.

and the percentage of genuine pairs rejected (FR). This cal-
culation was made by measuring the norm of the difference
between the outputs of a pair, then picking a threshold value
that sets a given trade-off between the FA and FR percent-
ages.

4. Testing and Results

Figure 5 shows the internal state of the convolutional net-
work for a particular test image. The rst layer extracts
various types of local gradient features, as well as smooth
features.

The system was tested for a face verication scenario.
The system is given an image and asked to conrm the
claimed identity of the subject in that image. We perform
verication by comparing the test image with a gaussian
model of images of the claimed subject. The method is dis-
cussed below.

4.1. Verication

Testing (verication) was done on a test set of size 5000.
It consisted of 500 genuine and 4500 impostor pairs. For
the AT&T experiments the test images were from 5 sub-
jects unseen in training. For AR/Feret experiments the test
images were from 40 unseen subjects in the more difcult
AR database.

The output from one of the subnets of the Siamese net-
work is a feature vector of the input image of the subject.
We assume that the feature vectors of each subjects im-
age form a multivariate normal density. A model is con-
structed of each subject by calculating the mean feature
vector and the variance-covariance matrix using the feature
vectors generated from the rst ve images of each subject.
, is
found by evaluating the normal density of the test image on
the model of the concerned subject. The likelihood of a test
image being an impostor,
, is assumed to be a con-
stant whose value is estimated by calculating the average
value of all the impostor images of the concerned



subject. The probability that the given image is genuine is
given by

The likelihood that a test image is genuine,












;

!









"




1 !

The values of the percentage of falsely rejected images
and the falsely accepted images are plotted for all possible
values of the threshold probability. The optimal threshold
probability is the value that partitions the test set into gen-
uine and impostor pairs and minimizes FA and FR rates.

The verication rates obtained from testing the AT&T
database and the AR/Purdue database are strikingly differ-
ent (see table 1 and gures 6 and 7), underlining the differ-
ences in difculty in the two databases. The AT&T dataset
is relatively small, and our system required only 5000 train-
ing samples to achieve very high performance on the test
set. The AR/Purdue dataset is very large and diverse, with
huge variations in expression, lighting, and added occlu-
sions. Our higher error rates reect this level of difculty.

5. Conclusion and Outlook

We present a general discriminative method for learn-
ing complex similarity metrics. The method is best suited
for classication or verication scenarios where the num-
ber of classes is very large, and/or where examples of all
the classes are not available at the time of training. We il-
lustrate the method with a face verication application.

We propose a loss function and show that minimizing
this function causes the system to approach the desired be-
havior. Our loss function is discriminative in the sense that
it drives the system to make the right decision, but does not
cause it to produce probability estimates. The method is









ROC: False Reject vs. False Accept

FR
0

5

10

15

20

25

30
0

5

10

15

FA

20

25

30

Figure 6. AT&T dataset: percent false reject vs. false accept.

ROC: False Reject v/s False Accept

FR
0

5

10

15

20

25

30

35

40

45

50

55

60

65

70

75

80

85

90

95

100

0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100

FA

work. J. Cowan and G. Tesauro (eds) Advances in Neural
Information Processing Systems, 1993.

[5] M. Hsuan Yang, N. Ahuja, and D. Kriegman. Face recogni-
tion using kernel eigenfaces. In Proc. of the 2000 IEEE In-
ternational Conference on Image Processing (ICIP), 1:37
40, September 2000.

[6] M. Lades, J. C. Vorbruggen, J. Buhmann, J. Lange,
C. von der Malsburg, R. P. Wurtz, and W. Konen. Distortion-
invariant object recognition in the dynamic link architecture.
IEEE Trans. Computers, 42(3):300311, 1993.

[7] S. Lawrence, C. Lee Giles, A. Chung Tsoi, and A. D. Back.
Face recognition: A convolutional neural network approach.
IEEE Transactions on Neural Networks, Special Issue on
Neural Networks, 1997.

[8] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-
based learning applied to document recognition. Proceed-
ings of the IEEE, 86(11):22782324, 1998.

[9] Y. LeCun and F. Jie Huang. Loss functions for discrimina-

tive training of energy-based models. AI-stats, 2005.

[10] A. M. Martinez. Recognizing imprecisely localized, par-
tially occluded and expression variant faces from a single
sample per class. IEEE Trans. on Pattern Analysis and Ma-
chine Intelligence, 24(6):748763, 2002.
[11] A. M. Martinez and R. Benavente.

The ar

CVC Technical Report, 24,

face
database.
June 1998.
http://rvl1.ecn.purdue.edu/ aleix/aleix face DB.html.
The
for
recog-
Report NISTIR
Inst. Standards and Technology, 1998.

feret
nition
6,281, Natl
http://www.nist.gov/itl/div894/894.03/pubs.html#face.

and H. Moon.
protocol
Technical

J. Phillips,
testing

verication

algorithms.

[12] S. Rizvi, P.

face

Figure 7. AR/Purdue dataset: percent false reject vs. false accept.

different from probabilistic density models in that there is
no attempt to estimate a density for each class in the input
space. This gives us an additional amount of exibility in
the choice of
, because we do need to worry about
normalization. We chose to use a convolutional network ar-
chitecture which exhibits robustness to geometric variations
of the input, thereby reducing the need for accurate registra-
tion of the face images.





Trainable similarity metrics have numerous applications
beyond the one described in this paper. Among other things,
they can be used to build invariant kernel functions with
which to build Support Vector Machines and other kernel-
based models [17].

