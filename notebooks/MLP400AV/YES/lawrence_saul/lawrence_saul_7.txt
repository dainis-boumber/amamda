Abstract

This paper explores online learning approaches
for detecting malicious Web sites (those involved
in criminal scams) using lexical and host-based
features of the associated URLs. We show that
this application is particularly appropriate for on-
line algorithms as the size of the training data
is larger than can be efciently processed in
batch and because the distribution of features
that typify malicious URLs is changing contin-
uously. Using a real-time system we developed
for gathering URL features, combined with a
real-time source of labeled URLs from a large
Web mail provider, we demonstrate that recently-
developed online algorithms can be as accurate
as batch techniques, achieving classication ac-
curacies up to 99% over a balanced data set.

1. Introduction

As new communications technologies drive new opportu-
nities for commerce, they inevitably create new opportuni-
ties for criminal actors as well. The World Wide Web is
no exception to this pattern, and today millions of rogue
Web sites advance a wide variety of scams including mar-
keting counterfeit goods (e.g., pharmaceuticals or luxury
watches), perpetrating nancial fraud (e.g., phishing) and
propagating malware (e.g., via drive-by exploits or social
engineering). What all of these activities have in common
is the use of the Uniform Resource Locator (URL) as a vec-
tor to bring Internet users into their inuence. Thus, each
time a user decides whether to click on an unfamiliar URL
they must implicitly evaluate the associated risk.
Is that
URL safe to click on, or will it expose the user to poten-
tial exploitation? Not surprisingly, this can be a difcult
judgment for individual users to make.

As a result, security researchers have developed various

Appearing in Proceedings of the 26 th International Conference
on Machine Learning, Montreal, Canada, 2009. Copyright 2009
by the author(s)/owner(s).

systems to protect users from their uninformed choices.
By far the most common technique, deployed in browser
toolbars, Web ltering appliances and search engines, is
blacklisting. Using this approach, a third-party service
compiles the names of known bad Web sites (labeled by
combinations of user feedback, Web crawling and heuristic
analysis of site content) and distributes the list to its sub-
scribers. While such systems have minimal query overhead
(just searching for a URL within the list) they can only of-
fer modest accuracy since it is impractical for any blacklist
to be comprehensive and up-to-date (Sinha et al., 2008).
Thus, a user may click on a malicious URL before it ap-
pears on a blacklist (if it ever does). Alternatively, some
systems also intercept and analyze full Web site content as
it is downloaded. This approach can offer higher accuracy,
but requires far more run-time overhead, and may inadver-
tently expose users to the very threats they seek to avoid.

In this paper, we focus on a complementary technique 
lightweight real-time classication of the URL itself to pre-
dict whether the associated site is malicious. We use vari-
ous lexical and host-based features of the URL for classi-
cation, but exclude Web page content. We are motivated by
prior studies noting distinguishing commonalities in such
features for malicious URLs (Chou et al., 2004; McGrath
& Gupta, 2008). If properly automated, this technique can
afford the low classication overhead of blacklisting while
offering far greater accuracy (and may also be used as a
low-cost pre-lter for more expensive techniques).

To that end, our papers primary contribution is the success-
ful application of online learning algorithms to the problem
of predicting such malicious URLs. Our earlier work (Ma
et al., 2009) is among several previous systems for URL
classication that have relied on batch learning algorithms.
However, we argue that online methods are far better suited
to the practical nature of this problem for two reasons: (1)
Online methods can process large numbers of examples far
more efciently than batch methods. (2) We need to adapt
to changes in malicious URLs and their features over time.

To demonstrate this approach, we have built a URL classi-
cation system that uses a live feed of labeled URLs from
a large Web mail provider, and that collects features for the

Identifying Suspicious URLs: An Application of Large-Scale Online Learning

Table1.Feature breakdown on Day 100 of the experiments.

Lexical

Host-Based

Feature type
Hostname
Primary domain
Path tokens
Last path token
TLD
Lexical misc.
Lexical

Count

Feature type
835,764 WHOIS info
738,201
124,401
92,367
522
6
1,791,261

IP prex
AS number
Geographic
Conn. speed
Host misc.
Host-Based

Count
917,776
131,930
39,843
28,263
52
37
1,117,901

URLs in real time (see Figure 2). Using this data, we show
that online algorithms can be more accurate than batch al-
gorithms in practice because the amount of data batch algo-
rithms can train on is resource-limited. We compare clas-
sical and modern online learning algorithms and nd the
Condence-Weighted algorithm achieves accuracies up to
99% over a balanced data set. Finally, we show that contin-
uous retraining over newly-encountered features is critical
for adapting the classier to detect new, malicious URLs.

We begin the rest of the paper by providing more back-
ground on the application of detecting malicious URLs,
then describing the online algorithms we use for classi-
cation. Next, we describe our data collection methodology
and evaluate the models over our data set of labeled URLs.
Finally, we conclude with an overall discussion.

2. Application

Our goal is to detect malicious Web sites from the lexical
and host-based features of their URLs. This section pro-
vides background for our application with respect to the
features we use for URL classication, as well as placing
our work in context with related work.

2.1. Features

Like our previous study (Ma et al., 2009), we analyze lex-
ical and host-based features because they contain informa-
tion about the URL and host that is straightforward to col-
lect using automated crawling tools. Thus, the list of fea-
tures is extensive, but not necessarily exhaustive.

We do not include the content of the Web page or the con-
text of the URL (e.g., the page or email containing the
URL) as features for several reasons. (1) Avoiding page
content downloads is strictly safer. (2) Classifying a URL
with a trained model is a lightweight operation compared
to rst downloading the page contents and then analyzing
them. (3) We want to apply our methods on URLs regard-
less of the context in which they appear (pages, email, chat,
calendars, games, etc.), so we are not tied to a particular
application setting. And (4) reliably obtaining the content
of a page can become an issue due to content cloaking,
whereby a malicious site may serve benign versions of a
page to a honeypot IP address run by a security practitioner,
but serve malicious versions to other users. Nevertheless,
the evaluations in Section 5 show that classication with
just lexical and host-based features of URLs, without any
context, can still be highly accurate.

Table 1 lists the lexical and host-based feature types we
consider and the number contributed by each type. Overall,
lexical types account for 62% of features and host-based
types account for 38%. We next describe the feature types
and the motivation behind including them for classication.

Lexical features: These features allow us to capture
the property that malicious URLs tend to look dif-
ferent from benign URLs. For example,
the appear-
ance of the token .com in the URL www.ebay.com
is not unusual. However, the appearance of .com in
www.ebay.com.phishy.biz or phish.biz/www.ebay.com/
index.php could indicate an attempt by criminals to spoof
the domain name of a legitimate commercial Web site.
Similarly, we would like to capture the fact that there are
certain red ag keywords that tend to appear in malicious
URLs  e.g., ebayisapi would appear frequently in the
path of URLs attempting to spoof an eBay page.

To implement these features, we use a bag-of-words repre-
sentation of tokens in the URL, where /, ?, ., =, -,
and   are delimiters. We distinguish tokens that appear in
the hostname, path, the top-level domain (TLD), primary
domain name (the domain name given to a registrar), and
last token of the path (to capture le extensions). Thus,
com in the TLD position of a URL would be a different
token from com in other parts of the URL. We also use
the lengths of the hostname and the URL as features.

Host-based features: These features describe properties
of the Web site host as identied by the hostname portion
of the URL. They allow us to approximate where mali-
cious sites are hosted, who own them, and how they
are managed. We examine the following sets of properties
to construct host-based features:

WHOIS information  This includes domain name regis-
tration dates, registrars, and registrants. So if a set of ma-
licious domains are registered by the same individual, we
would like to treat such ownership as a malicious feature.

Location  This refers to the hosts geography, IP address
prex, and autonomous system (AS) number. So if mali-
cious URLs tend to be hosted in a specic IP prex of an
Internet service provider (ISP), then we want to account for
that disreputable ISP when classifying URLs.

Connection speed  If some malicious sites tend to reside
on compromised residential machines (connected via cable
or DSL), then we want to record the host connection speed.

Membership in blacklists  Over our experiments, 55% of
malicious URLs were present in blacklists. Thus, although
this feature is useful, it is still not comprehensive.

Identifying Suspicious URLs: An Application of Large-Scale Online Learning

s
e
r
u
a
e
F

t


f

o


r
e
b
m
u
N
e
v
i
t



l

a
u
m
u
C

2.5

2

1.5

1

0.5

0

x 106

New IP prefix

"209.172.192.0/19":
hosts 16 spam sites

from same direct

marketing company

New registrant token
"DualManagementMedia":
a direct marketing
company that registered
27 spam sites

New domain "cq.bz":
a prolific phishing site

10

20

30

40

50
Days

60

70

80

90

100

Figure1.Cumulative number of features observed over time for
our live URL feeds. We highlight a few examples of new features
at the time they were introduced by new malicious URLs.

Other DNS-related properties  These include time-to-
live (TTL), spam-related domain name heuristics (Rudd,
2007), and whether the DNS records share the same ISP.

Figure 1 shows the cumulative number of features for each
day of the evaluations. Each days total includes new fea-
tures introduced that day and all old features from previous
days (see Section 5 on our methodology for new features).
The dimensionality grows quickly because we assign a bi-
nary feature for every token we encounter among the URL
lexical tokens, as well as WHOIS and location properties.
As we will show in Section 5.3, accounting for new fea-
tures like the ones in Figure 1 is benecial for detecting
new malicious URLs.

2.2. Related Work

The most direct comparison to our work comes from Gar-
era et al. (2007), who classify phishing URLs using logistic
regression over 18 hand-selected features. The features in-
clude red-ag keywords, Google Page Rank and Web qual-
ity guidelines scores. Their classier achieves 97.3% ac-
curacy over a set of 2,500 URLs. Although similar in mo-
tivation and methodology, our study differs in scope (with
evaluations focused on detecting spamming and phishing
sites), scale (orders of magnitude more features and URLs),
and algorithmic approach (online vs. batch learning).

Provos et al. (2008) study drive-by exploit URLs, and use
a patented machine learning algorithm along with features
derived from Web page content. Fette et al. (2007) and
Bergholz et al. (2008) examine select properties of URLs
contained within an email to aid the machine learning clas-
sication of phishing emails (not the URLs themselves).

Several projects have also explored operating systems-level
techniques whereby the client visits the Web site using
an instrumented virtual machine (VM) (Moshchuk et al.,
2006; Wang et al., 2006; Provos et al., 2007). The VM
can emulate any client-side exploits that occur as a result
of visiting a malicious site, and the instrumentation can de-

tect whether an infection has occurred. In this way, the VM
serves as a protective buffer for the user.

Finally, many commercial efforts exist to protect users
from visiting malicious URLs such as McAfees SiteAd-
visor, IronPort Web Reputation, WebSense ThreatSeeker
Network, WOT Web of Trust, and Google Toolbar. These
approaches are based on blacklist construction, user feed-
back, and proprietary feature analysis.

3. Online Algorithms

This section briey describes the online learning algo-
rithms we use for our evaluations. Formally, the algorithms
are trying to solve an online classication problem over a
sequence of pairs {(x1, y1), (x2, y2), ..., (xT , yT )}, where
each xt is an examples feature vector and yt  {1, +1}
is its label. At each time step t during training, the al-
gorithm makes a label prediction ht(xt), which for linear
classiers is ht(x) = sign(wt  x).

After making a prediction, the algorithm receives the actual
label yt. (If ht(xt) 6= yt, we record an error for time t.)
Then, the algorithm constructs the hypothesis for the next
time step ht+1 using ht, xt and yt.
As practitioners, we have no vested interest in any partic-
ular strategy for online learning. We simply want to de-
termine the approach that scales well to problems of our
size and yields the best performance. To that end, the on-
line methods we evaluate are a mix of classical and recent
algorithms. We present the models in order of increasing
sophistication with respect to the objective functions and
the treatment of classication margin (which we can also
interpret as classication condence).

Perceptron: This classical algorithm is a linear classier
that makes the following update to the weight vector when-
ever it makes a mistake (Rosenblatt, 1958):

wt+1  wt + ytxt

(1)

The advantage of the Perceptron is its simple update rule.
However, because the update rate is xed, the Perceptron
cannot account for the severity of the misclassication. As
a result, the algorithm can overcompensate for mistakes in
some cases and undercompensate for mistakes in others.

Logistic Regression with Stochastic Gradient Descent:
Many batch algorithms use gradient descent to optimize an
objective function that is expressed as a sum of the exam-
ples individual objective functions. Stochastic gradient de-
scent (SGD) provides an online means for approximating
the gradient of the original objective, whereby the model
parameters are updated incrementally by the gradients of
individual objectives.
In this paper we evaluate SGD as
applied to logistic regression.

Identifying Suspicious URLs: An Application of Large-Scale Online Learning

Let P (yt = +1|xt) = (w  xt) be the likelihood that ex-
ample ts label is +1, where the sigmoid function is (z) =
[1 + ez]1. Moreover, let Lt(w) = log (yt(w  xt)) be
the log-likelihood for example t. Then the update for each
example in logistic regression with SGD is as follows:

wt+1  wt + 

Lt
w

= wt + txt

(2)

where t = yt+1
2  (wt  xt) and  is a constant training
rate. We do not decrease  over time so that the parameters
can continually adapt to new URLs. The update resembles
a Perceptron, except with a learning rate that is proportional
to t, the difference between the actual and predicted like-
lihood that the label is +1. This multiplier allows the model
to be updated (perhaps by a small factor) even when there
is no prediction mistake.

SGD has received renewed attention because of recent re-
sults on the convergence of SGD algorithms and the cast-
ing of classic algorithms as SGD approximations (Bottou,
1998; Bottou & LeCun, 2004). For example, the Percep-
tron can be viewed as an SGD minimization of the hinge-
loss function Loss(w) = Pt max{0, yt(w  xt)}.
Passive-Aggressive (PA) Algorithm: The goal of the
Passive-Aggressive algorithm is to change the model as
little as possible to correct for any mistakes and low-
condence predictions it encounters (Crammer et al.,
2006). Specically, with each example PA solves the fol-
lowing optimization:

wt+1  argmin

w

s.t.

1

2 kwt  wk2
yi(w  xt)  1

(3)

Updates occur when the inner product does not exceed a
xed condence margin  i.e., yt(wt  xt) < 1. The
closed-form update for all examples is as follows:

wt+1  wt + tytxt

(4)

where t = max{ 1yt(wtxt)
(The details of the
derivation are in Crammer et al., 2006.) The PA algorithm
has been successful in practice because the updates explic-
itly incorporate the notion of classication condence.

, 0}.

kxtk2

Condence-Weighted (CW) Algorithm: The idea behind
Condence-Weighted classication is to maintain a differ-
ent condence measure for each feature so that less con-
dent weights are updated more aggressively than more con-
dent weights. The Stdev update rule for CW is similar
in spirit to PA. However, instead of describing each feature
with a single coefcient, CW describes per-feature con-
dence by modeling uncertainty in weight wi with a Gaus-
sian distribution N (i, i) (Dredze et al., 2008; Crammer
et al., 2009). Let us denote  as the vector of feature means,

and  as the diagonal covariance matrix (i.e., the con-
dence) of the features. Then the decision rule becomes
ht(x) = sign(t  x)  which is the result of comput-
ing the average signed margin wt  x, where wt is drawn
from N (t, t), and then taking the sign.
The CW update rule adjusts the model as little as possi-
ble so that xt can be correctly classied with probability
. Specically, CW minimizes the KL divergence between
Gaussians subject to a condence constraint at time t:

(t+1, t+1)  argmin

,

DKL(N (, )kN (t, t))

s.t. yi(  xt)  1()px
t

xt

(5)
where  is the cumulative distribution function of the stan-
dard normal distribution. This optimization yields the fol-
lowing closed-form update:

t+1  t + tyttxt
 1
1
t

t+1  1

t + tu

2

diag2(xt)

(6)

where t, ut and  are dened in Crammer et al. (2009).
However, we can see that if the variance of a feature is
large, the update to the feature mean will be more aggres-
sive. As for performance, the run time of the update is
linear in the number of non-zero features in x.

Overall, because the CW algorithm makes a ne-grain dis-
tinction between each features weight condence, CW
can be especially well-suited to detecting malicious URLs
since our data feed continually introduces a dynamic mix
of new and recurring features.

Related Algorithms: We experimented with nonlinear
classication using online kernel-based algorithms such
as the Forgetron (Dekel et al., 2008) and the Projec-
tron (Orabona et al., 2008). To make computation tractable,
these algorithms budget (or at least try to reduce) the size
of the support set used for kernel calculations. Our pre-
liminary evaluations revealed no improvement over linear
classiers. However, we are continuing to evaluate budget
algorithms for long term use.

4. Data Collection

This section describes our live sources of labeled URLs
and the system we deploy to collect features in real time.
Figure 2 illustrates our data collection architecture, which
starts with two feeds of malicious and benign URLs.

We obtain examples of malicious URLs from a large Web
mail provider, whose live, real-time feed supplies 6,000-
7,500 examples of spam and phishing URLs per day. The
malicious URLs are extracted from email messages that
users manually label as spam, run through pre-lters to ex-
tract easily-detected false positives, and then veried man-
ually as malicious.

Identifying Suspicious URLs: An Application of Large-Scale Online Learning

By training regimen, we refer to (1) when the classier
is allowed to retrain itself after attempting to predict the
label of an incoming URL, and (2) how many features the
classier uses during training.

For (1), we compare continuous vs. interval-based
training. Under the continuous training regimen, the
classier may retrain its model after each incoming ex-
ample (the typical operating mode of online algorithms).
In the interval-based training regimen, the classier may
only retrain after a specied time interval has passed. In
our experiments, we set the interval to be one day. Batch
algorithms are restricted to interval-based training, since
continuous retraining would be computationally impracti-
cal. Unless otherwise specied, we use continuous retrain-
ing for all experiments with online algorithms (and then
evaluate the benet of doing so in Section 5.3).

For (2), we compare training using a variable vs. xed
number of features. Under the xed-feature regimen, we
train using a pre-determined set of features for all evalu-
ation days. For example, if we x the features to those
encountered up to Day 1, then we use those 150,000 fea-
tures for the whole experiment (see Figure 1). Under the
variable-feature regimen, we allow the dimensionality of
our models to grow with the number of new features en-
countered; on Day 8, for instance, we classify with up
to 500,000 features. Implicitly, examples that were intro-
duced before a feature i was rst encountered will have
value 0 for feature i. Unless otherwise specied, we use
the variable-feature training regimen for all algorithms (and
then evaluate the benet of doing so in Section 5.3).

As for the sizes of the training sets, online algorithms im-
plicitly train on a cumulative data set, since they can incre-
mentally update models from the previous day. For batch
algorithms, we vary the training set size to include day-long
and multi-day sets (details in Section 5.1).

5.1. Advantages of Online Learning

We start by evaluating the benet of using online over batch
algorithms for our application in terms of classication
accuracy  in particular, whether the benet of efcient
computation in online learning comes at the expense of ac-
curacy. Specically, we compare the online Condence-
Weighted (CW) algorithm against four different training
set congurations of a support vector machine. We use
the LIBLINEAR implementation of an SVM with a linear-
kernel as our canonical batch algorithm (Fan et al., 2008).
Evaluations with other batch algorithms such as logistic re-
gression yielded similar results.

Figure 3 shows the classication rates for CW and for SVM
using four types of training sets. We tuned all classier
parameters over one day of holdout data, setting C = 100

Figure2.Overview of real-time URL feed, feature collection, and
classication infrastructure.

We randomly draw our examples of benign URLs from
Yahoos directory listing.
A random sample from
this directory can be generated by visiting the link
http://random.yahoo.com/bin/ryl.

Combined, we collect a total of 20,000 URLs per day from
the two URL feeds, and the average ratio of benign-to-
malicious URLs is 2-to-1. We ran our experiments for 100
days, collecting nearly 2 million URLs (there were feed
outages during Days 3540). However, the feeds only pro-
vide URLs, not the accompanying features.

Thus, we deploy a system to gather features in real-time.
The real-time aspect is important because we want the val-
ues to reect the features a URL had when it was rst in-
troduced to the feed (which ideally reects values for when
it was introduced to the wild). For every incoming URL,
our feature collector immediately queries DNS, WHOIS,
blacklist and geographic information servers, as well as
processing IP address-related and lexical-related features.

Our live feed is notably different from data sets such as
the webspam set from the PASCAL Large Scale Learning
Challenge (Sonnenburg et al., 2008). Our application uses
URLs as a starting point, and it is our responsibility to fetch
lexical and host-based features in real-time to construct the
data set on an ongoing basis. By contrast, the webspam
set is a static representation of Web pages (using strings),
not URLs, and provides no notion of the passage of time.

Finally, our live feed provides a real-time snapshot of ma-
licious URLs that reect the evolving strategies of Internet
criminals. The freshness of this data suggests that good
classication results over the set will be a strong indicator
of future success in real-world deployments.

5. Evaluation

In this section, we evaluate the effectiveness of online
learning over the live URL feed. To demonstrate this ef-
fectiveness, we address the following questions: Do on-
line algorithms provide any benet over batch algorithms?
Which online algorithms are most appropriate for our ap-
plication? And is there a particular training regimen that
fully realizes the potential of these online classiers?

Identifying Suspicious URLs: An Application of Large-Scale Online Learning

SVMonce  x

SVMdaily  x

SVMmultionce  x

SVMmulti  x

CW



Fortunately, online algorithms do not have that limitation.
Moreover, they have the added benet that they can incre-
mentally adapt to new data. As we see in Figure 3, the
accuracy for CW beats SVM-multi. Since the online algo-
rithm is making a single pass over a cumulative training set,
it does not incur the overhead of loading the entire data set
in memory. Because its training is incremental, it is capa-
ble of adapting to new examples in real time, whereas batch
algorithms are restricted to retraining at the next available
interval (more on interval-based training in Section 5.3).
These advantages allow the online classier to have the best
accuracy in our experiments.

5.2. Comparison of Online Algorithms

Given the demonstrated benets of online learning over
batch learning, we next evaluate which of the online al-
gorithms from Section 3 are best suited to malicious URL
detection. The main issue that these experiments address is
whether recent developments in online algorithms, which
include optimizing different objective functions, adjusting
for classication condence, and treating features differ-
ently, can benet the classiers in our application.

Figure 4(a) shows the cumulative error rates for the online
algorithms. All algorithms in this experiment adopt the
continuous training regimen. We also note that the error
rates improve steadily over time for all classiers, reafrm-
ing that training on cumulative data is benecial.

The Perceptron is the simplest of the algorithms, but it also
has the highest error rates across all of the days at around 2
3%. This result suggests that because the Perceptron treats
mistakes equally (and ignores all correct classications), its
updates are too coarse to accurately keep up with new ex-
amples. There needs to be a more ne-grain distinction be-
tween misclassied and correctly-classied examples with
respect to their impact on model updates.

Both logistic regression with stochastic gradient de-
scent (LRsgd) and the Passive-Aggressive (PA) algorithm
achieve a cumulative error approaching 1.6%, improving
over the Perceptron results.
(Here we tuned the LRsgd
learning rate to  = 0.01 over one day of holdout data.)
Presumably, this improvement occurs because LRsgd and
PA account for classication condence.
Specically,
LRsgd updates are proportional to t, and PA updates
are proportional to the normalized classication margin t.
These results are comparable to SVM-multi.

The CW results suggest that the nal leap comes from
treating features differently  both in terms of how they af-
fect classication condence, and how quickly they should
be updated. With an error approaching 1%, CW clearly
outperforms the other algorithms. Most of the gap between
CW and the other online methods comes from CWs lower

)

%

(

e

t

a
r

r
o
r
r
e



e
v
i
t

l

a
u
m
u
C

4

3.5

3

2.5

2

1.5

1



10

20

30

40

50
Days

60

70

80

90

100

Figure3.Cumulative error rates for CW and for batch algorithms
under different training sets. Note the y-axis starts at 1%.

for SVM, and  = 0.90 for CW. The x-axis shows the
number of days in the experiment, and the y-axis shows
the cumulative error rate: the percentage of misclassied
examples for all URLs encountered up to that date.

The SVM-once curve represents training once on Day 0s
data and using that model for testing on all other days. The
cumulative error steadily worsens to 3.5%, and the per-day
false negative rate gets as high as 1015%. These high er-
ror rates suggests that, to achieve better accuracy, the model
must train on fresh data to account for new features of ma-
licious and benign URLs encountered over time.

SVM-daily retrains only on data collected the previous day
 e.g., Day 6 results reect training on the URLs collected
on Day 5, and testing on Day 6 URLs. The only exception
is that we do not retrain during the feed outages on Days
3540. As a result, the cumulative error is just under 3%,
most of which is due to high per-day false negatives (5
15% on some days), whereas per-day false positives are
around 1.5%. Although fresh data eventually helps SVM-
daily improve over SVM-once, one days training data is
still insufcient.

We use multi-day training sets to address this issue by train-
ing on as much data as our evaluation machine with 4 GB
RAM can handle (which is 1417 days worth, or 280,000
340,000 examples). SVM-multi-once is the multi-day ana-
logue to SVM-once. Here, SVM-multi-once trains on data
from Days 0 to 16, and from Day 17 on it uses that xed
model for testing on subsequent days. The improvement
over SVM-once shows the benet of more training data, but
the steadily worsening error again demonstrates the nonsta-
tionarity of the URL data set.

SVM-multi is the multi-day analogue of SVM-daily. Here,
SVM-multi trains on the previous 1417 days worth of data
(depending on what can t in memory). The resulting cu-
mulative error reaches 1.8%. SVM-multis improvement
over SVM-multi-once suggests the URL feature distribu-
tion evolves over time, thus requiring us to use as much
fresh data as possible to succeed. Overall, these results sug-
gest that more training data yields better accuracy. How-
ever, this accuracy is fundamentally limited by the amount
of computing resources available.

Identifying Suspicious URLs: An Application of Large-Scale Online Learning

Perceptron  x

LRsgd  x

PA  x

CW

Percep. (int.)  x

Perceptron  x

CW (int.)  x

CW

Percep. (fixed)  x

Percep.  x

CW (fixed)  x

CW

)

%

(

e
t
a
r

r
o
r
r
e

e
v
i
t
a
u
m
u
C

l

4

3.5

3

2.5

2

1.5

1





10

20

30

40

50
Days

60

70

80

90

100

)

%

(

e
t
a
r

r
o
r
r
e

e
v
i
t
a
u
m
u
C

l

4

3.5

3

2.5

2

1.5

1





10

20

30

40

50
Days

60

70

80

90

100

)

%

(

e
t
a
r

r
o
r
r
e

e
v
i
t
a
u
m
u
C

l

4

3.5

3

2.5

2

1.5

1





10

20

30

40

50
Days

60

70

80

90

100

(a) Error rates for online algorithms. All
use continuous/variable-feature training.

(b) Benets of using continuous training
over interval-based training.

(c) Benets of using variable-feature sets
over xed-feature sets.

Figure4.Comparing the effectiveness of various online algorithms, their use of continuous vs. interval training, and their use of xed
vs. variable feature sets.

false negatives  CW has 12% false negatives per day,
whereas others have 24%. We hypothesize the gap oc-
curs because CW can update select portions of its model
very aggressively to account for new malicious features, all
without perturbing more established features.

Overall, we nd that the more recent online algorithms out-
perform the simpler ones. Because the live combined URL
feed contains a dynamic mix of new and recurring fea-
tures, CWs per-feature condence weighting can exploit
that structure to achieve the best accuracy.

5.3. Training Regimen

In this section, we show that there is a signicant advan-
tage to continuous training vs. interval-based training. We
also demonstrate that there is signicant benet to adding
newly-encountered features as opposed to using a xed fea-
ture set. The aforementioned training regimens can help
online algorithms stay abreast of changing trends in URL
features. Thus, choosing the right training regimen can be
just as important as choosing the right algorithm.

Figure 4(b) shows the value of using continuous training
over interval training with the CW and Perceptron algo-
rithms. The higher error rates for interval training show that
there is enough variation between days that a model can
become stale if it is not retrained soon enough. In particu-
lar, the higher number of false negatives for interval-trained
CW is responsible for the persistent gap with continuously-
trained CW. Notwithstanding the aforementioned feed out-
ages on Days 3540, the 1% error difference between con-
tinuous and interval-based Perceptron is due to spikes in
the false positive/negative rates for the interval-trained Per-
ceptron. Thus, continuous retraining yields as much im-
provement for the simpler Perceptron as it does for CW.

In addition to continuous retraining, accounting for new
features is critical to an algorithms success. Figure 4(c)
shows the value of using variable-feature training over
xed-feature training. In this graph, xed features means
that we restrict the model to using the features encountered
on Day 1 only (150,000 features total). We see that the

performance for xed-feature CW degrades to a point that
it is no better than a Perceptron.
Interestingly, variable-
feature Perceptron only achieves a marginal improvement
over xed-feature Perceptron. One explanation is that, even
though variable-feature Perceptron can occasionally bene-
t from adding new features, it does not update the new
feature weights aggressively enough to correct for future
errors. By contrast, the CW algorithm updates new fea-
tures aggressively by design, and hence can reap the full
benets of variable-feature training.

Overall, continuous retraining with a variable feature set
allows a model to successfully adapt to new data and new
features on a sub-day granularity. And this adaptiveness is
critical to the full benets of online algorithms.

6. Conclusion

Malicious Web sites are a prominent and undesirable In-
ternet scourge. To protect end users from visiting those
sites, the identication of suspicious URLs using lexical
and host-based features is an important part of a suite of de-
fenses. However, URL classication is a challenging task
because new features are introduced daily  as such, the
distribution of features that characterize malicious URLs
evolves continually. With an eye toward ultimately con-
structing a real-time malicious URL detection system, we
evaluated batch and online learning algorithms for our ap-
plication to study their benets and tradeoffs.

Experiments over a live URL feed revealed the limitations
of batch algorithms in this setting, where we were forced to
make a tradeoff between accuracy and coping with resource
limitations (e.g., running out of memory). We demon-
strated that recently-developed online algorithms such as
CW can be highly accurate classiers, capable of achiev-
ing classication accuracies up to 99%. Furthermore, we
showed that retraining algorithms continuously with new
features is crucial for adapting successfully to the ever-
evolving stream of URLs and their features.

Identifying Suspicious URLs: An Application of Large-Scale Online Learning

Acknowledgments

We thank Koby Crammer, Mark Dredze, Fernando Pereira
and Boris Babenko for many useful discussions. We also
thank the anonymous reviewers for their valuable feed-
back. This work was supported by National Science
Foundation grants NSF-0238323, NSF-0433668 and NSF-
0829469 and by generous research, operational and in-kind
support from Cisco, Google, Microsoft, Yahoo and the
UCSD Center for Networked Systems.

